{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "![680f8e44a23b3.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "2GK_w4ZGw_tk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will develop a Visual Object Tracking system for recognizing and tracking a target within a video.\n",
        "\n",
        "Specifically, the following components will be used:\n",
        "- [YOLOv11](https://docs.ultralytics.com/it/models/yolo11/) nano for detecting objects of interest in the input video\n",
        "- [Openai CLIP](https://openai.com/index/clip/) for recognizing the target through image-image and text-image similarity\n",
        "- [ByteTrack](https://github.com/ifzhang/ByteTrack) for tracking the target throughout the input video\n",
        "\n",
        "**INSTRUCTIONS FOR USE**\n",
        "\n",
        "1. Set up a GPU-enabled [Runtime](https://www.youtube.com/watch?v=6H381fUOolU)\n",
        "2. Upload the resources (video and target image) directly to the server provided by Google Colaboratory or connect your own Google Drive (recommended)\n",
        "3. Add a description of your target to the variable *target_description*"
      ],
      "metadata": {
        "id": "mg5H02HRxbt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Configuration"
      ],
      "metadata": {
        "id": "So1ma3mWxPo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installation of Required Packages**"
      ],
      "metadata": {
        "id": "CUYNlDMX35d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRG1aYPWwQDv",
        "outputId": "e315521d-0f18-47ea-f264-c564daf0d0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.128-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting lap==0.5.12\n",
            "  Downloading lap-0.5.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from lap==0.5.12) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading lap-0.5.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.128-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lap, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lap-0.5.12 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.128 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python ultralytics lap==0.5.12 transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openai/CLIP.git && cd CLIP\n",
        "!pip install -r /content/CLIP/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pji7SzPmxJTc",
        "outputId": "6c3d7b11-2d14-4ed5-9ec3-ce6a4d81bbbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Counting objects: 100% (154/154), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 256 (delta 126), reused 110 (delta 110), pack-reused 102 (from 1)\u001b[K\n",
            "Receiving objects: 100% (256/256), 8.86 MiB | 34.25 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n",
            "Collecting ftfy (from -r /content/CLIP/requirements.txt (line 1))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r /content/CLIP/requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from -r /content/CLIP/requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r /content/CLIP/requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r /content/CLIP/requirements.txt (line 5)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r /content/CLIP/requirements.txt (line 6)) (0.21.0+cu124)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r /content/CLIP/requirements.txt (line 1)) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r /content/CLIP/requirements.txt (line 5)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r /content/CLIP/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->-r /content/CLIP/requirements.txt (line 6)) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->-r /content/CLIP/requirements.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->-r /content/CLIP/requirements.txt (line 5)) (3.0.2)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Core Libraries**"
      ],
      "metadata": {
        "id": "8pgsJUoZ4QnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict\n",
        "\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "import torch\n",
        "import CLIP.clip as clip\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "emZS9czZxOW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96b1a26-db48-40a6-f6ef-56db3a104a92"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Pretrained Models"
      ],
      "metadata": {
        "id": "0ivxJbm4xYjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "j6ELBCugxrec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50162a49-75e9-4836-ad13-45ece2364b73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO11 model\n",
        "model = YOLO(\"yolo11n.pt\")\n",
        "print(model.model.names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qSrlhZTxd9f",
        "outputId": "6806afac-2d66-49c0-f5a6-b1d87c9f7640"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 97.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CLIP\n",
        "clip_model, clip_preprocess = clip.load(\"ViT-B/32\", device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjbunbLzxjSg",
        "outputId": "7fbfd28d-d9f7-4243-a65a-bdc17c15781b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 136MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Input Preparation"
      ],
      "metadata": {
        "id": "t4AOhoZIx3Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's mount your own Google Drive and link the video input"
      ],
      "metadata": {
        "id": "TSj-5nki4tmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFzmnOCNyE1g",
        "outputId": "89c1d71a-9703-428d-bdb3-4b3ae698299a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_input_path = \"/content/drive/MyDrive/WholeLottaTracking/joker_chase_long.mp4\"  # Change video path\n",
        "video_output_path_multitrack = \"video_output_multitrack.mp4\""
      ],
      "metadata": {
        "id": "GICfl_H7yIvU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Target Object Identification and Tracking"
      ],
      "metadata": {
        "id": "zwLBCETIyMJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline Configuration**"
      ],
      "metadata": {
        "id": "s86S8g8PLqAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_bgr_colors(objects):\n",
        "  \"\"\"Generates unique BGR colors for a list of objects.\n",
        "\n",
        "  Args:\n",
        "    objects: A list of objects.\n",
        "\n",
        "  Returns:\n",
        "    A dictionary mapping each object to a unique BGR color.\n",
        "  \"\"\"\n",
        "  bgr_colors = {}\n",
        "  for object in objects:\n",
        "    # Generate a random BGR color\n",
        "    b = random.randint(0, 255)\n",
        "    g = random.randint(0, 255)\n",
        "    r = random.randint(0, 255)\n",
        "    bgr_colors[object] = (b, g, r)\n",
        "  return bgr_colors"
      ],
      "metadata": {
        "id": "zANdo8TlYITC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a short description about target object\n",
        "target_description = \"a person with long hair, dressed as a clown, with a white painted face and wearing a red suit with a yellow waistcoat\"\n",
        "# path of an example image of target object\n",
        "target_image_path = \"/content/drive/MyDrive/WholeLottaTracking/target.jpg\"\n",
        "# yolo class about target\n",
        "target_category = \"person\"\n",
        "\n",
        "# object types to detect\n",
        "objects_to_monitor = [\"person\",\"car\"]\n",
        "# monitored object colors\n",
        "color_map = generate_bgr_colors(objects_to_monitor)\n",
        "# if True, detected objects will be displayed in the output video\n",
        "multi_obj = True"
      ],
      "metadata": {
        "id": "dqIGemqn0Wdk"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Supporting Functions for Processing**"
      ],
      "metadata": {
        "id": "vKXJ8tboSy0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Create a new directory if it does not exist.\n",
        "\n",
        "  Args:\n",
        "      dir_path (str): The path of the directory to create.\n",
        "  \"\"\"\n",
        "  if os.path.exists(dir_path):\n",
        "      shutil.rmtree(dir_path)\n",
        "      print(f\"Deleted '{dir_path}'\")\n",
        "\n",
        "  os.makedirs(dir_path)\n",
        "  print(f\"Created new directory: '{dir_path}'\")"
      ],
      "metadata": {
        "id": "fKDH_rN1z2YV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_target(track_id_image_paths, target_description, target_image_path, model, preprocess, device, debug=True):\n",
        "  \"\"\"Identifies the target object among tracked objects using CLIP similarity.\n",
        "\n",
        "  This function compares tracked objects with a target description and image\n",
        "  using CLIP (Contrastive Language–Image Pre-training) to determine the\n",
        "  most likely target object.\n",
        "\n",
        "  Args:\n",
        "      track_id_image_paths (dict): A dictionary mapping track IDs to image paths\n",
        "                                   of the tracked objects.\n",
        "      target_description (str): A textual description of the target object.\n",
        "      target_image_path (str): The path to an image of the target object.\n",
        "      model (CLIPModel): The CLIP model used for embedding generation.\n",
        "      preprocess (CLIPProcessor): The CLIP processor used for image preprocessing.\n",
        "      device (str): The device to run the computations on (e.g., \"cuda\" or \"cpu\").\n",
        "      debug (bool, optional): Whether to print debugging information.\n",
        "                              Defaults to True.\n",
        "\n",
        "  Returns:\n",
        "      int or None: The track ID of the identified target object, or None if no\n",
        "                   suitable match is found.\n",
        "  \"\"\"\n",
        "  image_path_list = list(track_id_image_paths.values())\n",
        "  predicted_target = None\n",
        "\n",
        "  images = []\n",
        "  for image_path in image_path_list:\n",
        "    images.append(preprocess(Image.open(image_path)).unsqueeze(0).to(device))\n",
        "\n",
        "  target_image = preprocess(Image.open(target_image_path)).unsqueeze(0).to(device)\n",
        "\n",
        "  images = torch.cat(images, dim=0)\n",
        "  text = clip.tokenize([target_description]).to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # image_features: shape (N, D) – una riga per immagine\n",
        "    # text_features : shape (1, D) – descrizione testuale\n",
        "    target_embedding = model.encode_image(target_image)\n",
        "    image_embeddings = model.encode_image(images)\n",
        "    text_embedding = model.encode_text(text)\n",
        "\n",
        "  # normalization\n",
        "  target_embedding = target_embedding / target_embedding.norm(dim=-1, keepdim=True)\n",
        "  image_embeddings = image_embeddings / image_embeddings.norm(dim=-1, keepdim=True)\n",
        "  text_embedding  = text_embedding  / text_embedding.norm(dim=-1, keepdim=True)\n",
        "\n",
        "  # Calculate cosine similarity\n",
        "  text_image_cos_sim = (image_embeddings @ text_embedding.T).squeeze()\n",
        "  text_image_sim_01 = torch.clamp(text_image_cos_sim, min=0.0)   # valori ∈ [0, 1]\n",
        "\n",
        "  target_image_cos_sim = (target_embedding @ image_embeddings.T).squeeze()\n",
        "  target_image_sim_01 = torch.clamp(target_image_cos_sim, min=0.0) # valori ∈ [0, 1]\n",
        "\n",
        "  cos_sim_01 = 0.3*text_image_sim_01.detach().cpu() + 0.7*target_image_sim_01.detach().cpu()\n",
        "\n",
        "  df_score = pd.DataFrame({\"track_id\":track_id_image_paths.keys(), \"image_path\":image_path_list, \"text_image_cos_sim\":text_image_sim_01.detach().cpu().tolist(), \"target_image_cos_sim\":target_image_sim_01.detach().cpu().tolist(), \"cos_sim\": cos_sim_01})\n",
        "  df_score = df_score.sort_values(by=\"cos_sim\", ascending=False)\n",
        "\n",
        "  if debug:\n",
        "    print(df_score)\n",
        "\n",
        "  # Find best match\n",
        "  best_match = df_score.iloc[0]\n",
        "  if best_match[\"cos_sim\"]>0.5 and best_match[\"target_image_cos_sim\"]>=0.65:\n",
        "    print(\"Best matching track_id is {}\".format(best_match[\"track_id\"]))\n",
        "    print(\"Best matching image path is {}\".format(best_match[\"image_path\"]))\n",
        "    print(\"Best matching cosine similarity is {}\".format(best_match[\"cos_sim\"]))\n",
        "    return best_match[\"track_id\"]\n",
        "  else:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "WsMIBU8hgUlj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_object_from_frame(frame, bboxes_data, target_category, frame_cnt):\n",
        "    \"\"\"Saves images of detected objects from a frame.\n",
        "\n",
        "    This function extracts the regions of interest (ROIs) containing the detected\n",
        "    objects specified in `objects_to_monitor` and saves them as individual images\n",
        "    in a directory structure organized by frame number.\n",
        "\n",
        "    Args:\n",
        "        frame (numpy.ndarray): The input frame as a NumPy array.\n",
        "        bboxes_data (list): A list of tuples, where each tuple contains the bounding\n",
        "                              box coordinates, track ID, and object class for a\n",
        "                              detected object.\n",
        "        target_category (str): The category of the target object.\n",
        "        frame_cnt (int): The current frame number.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary mapping track IDs to the paths of the saved object images.\n",
        "    \"\"\"\n",
        "    tracked_objs = {}\n",
        "    for box, track_id, obj_class in bboxes_data:\n",
        "        if obj_class.upper() == target_category.upper():\n",
        "            # for each frame we create new dir\n",
        "            dir_path = os.path.join(\"frames\", str(frame_cnt))\n",
        "            if not os.path.exists(dir_path):\n",
        "              create_dir(dir_path)\n",
        "\n",
        "            # The YOLO model returns the (x, y) coordinates of the center\n",
        "            # of the bounding box, along with its height and width.\n",
        "            x_center, y_center, w_box, h_box = box\n",
        "\n",
        "            # Compute the coordinates of the top-left and bottom-right corners\n",
        "            # of the bounding box.\n",
        "            x1 = int(x_center - w_box / 2)\n",
        "            y1 = int(y_center - h_box / 2)\n",
        "            x2 = int(x_center + w_box / 2)\n",
        "            y2 = int(y_center + h_box / 2)\n",
        "\n",
        "            # Extract the region of interest (ROI) containing the object of interest.\n",
        "            obj_image = frame[y1:y2, x1:x2]\n",
        "\n",
        "            # Save the image of tacked object\n",
        "            output_path = os.path.join(dir_path, f\"{obj_class}_{track_id}.jpg\")\n",
        "            cv2.imwrite(output_path, obj_image)\n",
        "            tracked_objs[track_id] = output_path\n",
        "    return tracked_objs"
      ],
      "metadata": {
        "id": "rVmoKIXO4c_k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frame-by-Frame Analysis Execution**"
      ],
      "metadata": {
        "id": "mdHDedMvS4gH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_dir(\"frames\")\n",
        "\n",
        "# extract video input information\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_multitrack = cv2.VideoWriter(video_output_path_multitrack, fourcc, fps, (width, height))\n",
        "\n",
        "# Store the track history\n",
        "target_id = None\n",
        "track_history = defaultdict(lambda: [])\n",
        "frame_cnt = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "    print(\"--\"*25 + \"Frame {}\".format(frame_cnt))\n",
        "    if success:\n",
        "\n",
        "        # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
        "        result = model.track(frame, tracker=\"bytetrack.yaml\", persist=True)[0]\n",
        "\n",
        "        # Get the boxes and track IDs\n",
        "        if result.boxes and result.boxes.id is not None:\n",
        "            boxes = result.boxes.xywh.cpu()\n",
        "            track_ids = result.boxes.id.int().cpu().tolist()\n",
        "            num_classes = result.boxes.cls.cpu().tolist()\n",
        "            categorical_classes = [result.names[int(obj_class)] for obj_class in num_classes]\n",
        "\n",
        "            # Check if target_id is set. If it is None, use the CLIP model to recognize the target and assign its ID\n",
        "            if target_id == None or target_id not in track_ids:\n",
        "              tracked_objs = save_object_from_frame(frame, zip(boxes, track_ids, categorical_classes), target_category, frame_cnt)\n",
        "              if tracked_objs:\n",
        "                target_id = find_target(tracked_objs, target_description, target_image_path, clip_model, clip_preprocess, device)\n",
        "\n",
        "            # Plot the tracks\n",
        "            for box, track_id, obj_class in zip(boxes, track_ids, categorical_classes):\n",
        "                #if target_id:\n",
        "                    if obj_class in objects_to_monitor:\n",
        "\n",
        "                        # The YOLO model returns the (x, y) coordinates of the center\n",
        "                        # of the bounding box, along with its height and width.\n",
        "                        x_center, y_center, w_box, h_box = box\n",
        "\n",
        "                        # Compute the coordinates of the top-left and bottom-right corners\n",
        "                        # of the bounding box.\n",
        "                        x1 = int(x_center - w_box / 2)\n",
        "                        y1 = int(y_center - h_box / 2)\n",
        "                        x2 = int(x_center + w_box / 2)\n",
        "                        y2 = int(y_center + h_box / 2)\n",
        "\n",
        "                        if track_id == target_id: #Target Object\n",
        "\n",
        "                          track = track_history[track_id]\n",
        "                          track.append((float(x_center), float(y_center)))\n",
        "\n",
        "                          if len(track) > 2*fps:\n",
        "                              track.pop(0)\n",
        "\n",
        "                          # Draw the target bbox\n",
        "                          cv2.rectangle(frame, (x1, y1), (x2, y2), (251, 9, 251), 2)\n",
        "\n",
        "                          # Target Condition\n",
        "                          label_text = \"TARGET: {}\".format(target_id)\n",
        "                          label_pos = (x1, max(y1 - 5, 0))\n",
        "                          cv2.putText(frame,\n",
        "                              label_text,\n",
        "                              label_pos,\n",
        "                              cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                              0.8,        # font size\n",
        "                              (251, 9, 251),# color font (B, G, R)\n",
        "                              2,          # font thickness\n",
        "                              cv2.LINE_AA)\n",
        "\n",
        "                          #points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "                          #cv2.polylines(frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
        "\n",
        "                        elif track_id!=target_id and multi_obj: #No Target Objects\n",
        "\n",
        "                          # Draw the tracking lines\n",
        "                          cv2.rectangle(frame, (x1, y1), (x2, y2), color_map[obj_class], 2)\n",
        "\n",
        "                          label_text = \"{}\".format(obj_class.upper())\n",
        "                          label_pos = (x1, max(y1 - 5, 0))\n",
        "                          cv2.putText(frame,\n",
        "                                      label_text,\n",
        "                                      label_pos,\n",
        "                                      cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                      0.8, # font size\n",
        "                                      color_map[obj_class], # color font (B, G, R)\n",
        "                                      2,   # font thickness\n",
        "                                      cv2.LINE_AA)\n",
        "\n",
        "\n",
        "            # Write frame into output video\n",
        "            font_size = 1.2\n",
        "            color_font = (249, 94, 5)\n",
        "            font_thickness = 2\n",
        "            font_type = cv2.FONT_HERSHEY_SIMPLEX\n",
        "            font_y = 0\n",
        "            decrease_height_value = 30\n",
        "            font_y+=decrease_height_value\n",
        "\n",
        "            cv2.putText(frame, \"FRAME {}\".format(frame_cnt), (0, font_y),\n",
        "                        font_type, font_size, color_font, font_thickness,\n",
        "                        cv2.LINE_AA)\n",
        "\n",
        "            font_y+=decrease_height_value\n",
        "\n",
        "            if target_id:\n",
        "                cv2.putText(frame, \"TARGET MATCHED\", (0, font_y),\n",
        "                          font_type, font_size, (5, 27, 249), font_thickness,\n",
        "                          cv2.LINE_AA)\n",
        "            else:\n",
        "                cv2.putText(frame, \"TARGET NOT MATCHED\".format(frame_cnt), (0, font_y),\n",
        "                font_type, font_size, color_font, font_thickness,\n",
        "                cv2.LINE_AA)\n",
        "\n",
        "            for i, obj_tm_class in enumerate(objects_to_monitor):\n",
        "                cv2.putText(frame, \"{} {}\".format(obj_tm_class.upper(),\n",
        "                        categorical_classes.count(obj_tm_class)), (0, font_y+(i+1)*decrease_height_value),\n",
        "                        font_type, font_size, color_map[obj_tm_class], font_thickness,\n",
        "                        cv2.LINE_AA)\n",
        "\n",
        "\n",
        "            out_multitrack.write(frame)\n",
        "\n",
        "\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "    frame_cnt += 1\n",
        "\n",
        "cap.release()\n",
        "out_multitrack.release()\n",
        "\n",
        "print(\"Target Tracking completed. Processed video has been saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYmb6p2gz9Jv",
        "outputId": "a4c0a617-8dd4-4b0e-d4cc-5e6100c169fd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted 'frames'\n",
            "Created new directory: 'frames'\n",
            "--------------------------------------------------Frame 0\n",
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 2.5ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/0'\n",
            "   track_id                image_path  text_image_cos_sim  \\\n",
            "0      6727  frames/0/person_6727.jpg            0.317871   \n",
            "1      6700  frames/0/person_6700.jpg            0.176880   \n",
            "2      6712  frames/0/person_6712.jpg            0.165771   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.684082  0.574219  \n",
            "1              0.646484  0.505859  \n",
            "2              0.605469  0.473633  \n",
            "Best matching track_id is 6727\n",
            "Best matching image path is frames/0/person_6727.jpg\n",
            "Best matching cosine similarity is 0.57421875\n",
            "--------------------------------------------------Frame 1\n",
            "\n",
            "0: 384x640 10 persons, 1 truck, 1 backpack, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 2\n",
            "\n",
            "0: 384x640 9 persons, 1 truck, 1 handbag, 10.4ms\n",
            "Speed: 3.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 3\n",
            "\n",
            "0: 384x640 9 persons, 1 truck, 1 handbag, 11.1ms\n",
            "Speed: 2.4ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 4\n",
            "\n",
            "0: 384x640 9 persons, 1 truck, 1 handbag, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 5\n",
            "\n",
            "0: 384x640 10 persons, 1 truck, 1 handbag, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 6\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 1 handbag, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 7\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 1 handbag, 11.2ms\n",
            "Speed: 3.0ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 8\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 1 handbag, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 9\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 1 handbag, 12.1ms\n",
            "Speed: 2.7ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 10\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 truck, 1 handbag, 16.2ms\n",
            "Speed: 2.5ms preprocess, 16.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 11\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 1 handbag, 8.9ms\n",
            "Speed: 1.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 12\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 13\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 1 backpack, 1 handbag, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 14\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 backpack, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 15\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 backpack, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 16\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 backpack, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 17\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 backpack, 9.2ms\n",
            "Speed: 2.9ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 18\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 backpack, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 19\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 backpack, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 20\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 motorcycle, 1 backpack, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 21\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 backpack, 8.8ms\n",
            "Speed: 2.3ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/21'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "3      6700  frames/21/person_6700.jpg            0.196045   \n",
            "2      6734  frames/21/person_6734.jpg            0.173584   \n",
            "4      6784  frames/21/person_6784.jpg            0.213989   \n",
            "0      6732  frames/21/person_6732.jpg            0.181274   \n",
            "1      6733  frames/21/person_6733.jpg            0.190552   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.608398  0.484619  \n",
            "2              0.617676  0.484375  \n",
            "4              0.598145  0.482910  \n",
            "0              0.602051  0.475830  \n",
            "1              0.585938  0.467285  \n",
            "--------------------------------------------------Frame 22\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 backpack, 13.5ms\n",
            "Speed: 4.0ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/22'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "3      6700  frames/22/person_6700.jpg            0.181274   \n",
            "2      6734  frames/22/person_6734.jpg            0.168213   \n",
            "0      6732  frames/22/person_6732.jpg            0.183838   \n",
            "4      6784  frames/22/person_6784.jpg            0.211670   \n",
            "1      6733  frames/22/person_6733.jpg            0.209229   \n",
            "5      6795  frames/22/person_6795.jpg            0.180054   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.620117  0.488525  \n",
            "2              0.617676  0.482910  \n",
            "0              0.606445  0.479736  \n",
            "4              0.593750  0.479004  \n",
            "1              0.591309  0.476562  \n",
            "5              0.603027  0.476074  \n",
            "--------------------------------------------------Frame 23\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 backpack, 11.0ms\n",
            "Speed: 1.9ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/23'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "2      6734  frames/23/person_6734.jpg            0.181030   \n",
            "0      6732  frames/23/person_6732.jpg            0.182983   \n",
            "3      6795  frames/23/person_6795.jpg            0.211914   \n",
            "1      6733  frames/23/person_6733.jpg            0.158936   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.619629  0.488281  \n",
            "0              0.612793  0.483887  \n",
            "3              0.588867  0.475586  \n",
            "1              0.585449  0.457520  \n",
            "--------------------------------------------------Frame 24\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 1 backpack, 10.2ms\n",
            "Speed: 2.3ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/24'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6732  frames/24/person_6732.jpg            0.189453   \n",
            "1      6733  frames/24/person_6733.jpg            0.183594   \n",
            "2      6734  frames/24/person_6734.jpg            0.172119   \n",
            "3      6795  frames/24/person_6795.jpg            0.220581   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.612305  0.485596  \n",
            "1              0.611816  0.483398  \n",
            "2              0.614746  0.481934  \n",
            "3              0.572754  0.467041  \n",
            "--------------------------------------------------Frame 25\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 1 backpack, 10.3ms\n",
            "Speed: 2.5ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/25'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "2      6734  frames/25/person_6734.jpg            0.173706   \n",
            "0      6732  frames/25/person_6732.jpg            0.188721   \n",
            "3      6795  frames/25/person_6795.jpg            0.224487   \n",
            "1      6733  frames/25/person_6733.jpg            0.160278   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.619141  0.485352  \n",
            "0              0.610840  0.484131  \n",
            "3              0.581055  0.474121  \n",
            "1              0.582031  0.455566  \n",
            "--------------------------------------------------Frame 26\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 13.7ms\n",
            "Speed: 2.0ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/26'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "1      6795  frames/26/person_6795.jpg            0.207397   \n",
            "0      6732  frames/26/person_6732.jpg            0.169922   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.600586  0.482666  \n",
            "0              0.594238  0.467041  \n",
            "--------------------------------------------------Frame 27\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/27'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6732  frames/27/person_6732.jpg            0.184204   \n",
            "1      6795  frames/27/person_6795.jpg            0.191650   \n",
            "2      6811  frames/27/person_6811.jpg            0.193481   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.612793  0.484131  \n",
            "1              0.608398  0.483398  \n",
            "2              0.584473  0.467285  \n",
            "--------------------------------------------------Frame 28\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/28'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6732  frames/28/person_6732.jpg            0.198486   \n",
            "1      6795  frames/28/person_6795.jpg            0.200195   \n",
            "2      6811  frames/28/person_6811.jpg            0.175903   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.607422  0.484863  \n",
            "1              0.602539  0.481934  \n",
            "2              0.565430  0.448486  \n",
            "--------------------------------------------------Frame 29\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/29'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "1      6795  frames/29/person_6795.jpg            0.201782   \n",
            "0      6732  frames/29/person_6732.jpg            0.179932   \n",
            "2      6811  frames/29/person_6811.jpg            0.187866   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.606934  0.485352  \n",
            "0              0.606934  0.478760  \n",
            "2              0.584473  0.465576  \n",
            "--------------------------------------------------Frame 30\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/30'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "2      6811  frames/30/person_6811.jpg            0.191650   \n",
            "0      6732  frames/30/person_6732.jpg            0.184326   \n",
            "1      6795  frames/30/person_6795.jpg            0.181763   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.601562  0.478516  \n",
            "0              0.598633  0.474121  \n",
            "1              0.581543  0.461426  \n",
            "--------------------------------------------------Frame 31\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 9.0ms\n",
            "Speed: 2.4ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/31'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6732  frames/31/person_6732.jpg            0.174683   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0               0.60791  tensor(0.4780, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 32\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/32'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6732  frames/32/person_6732.jpg            0.185181   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.627441  tensor(0.4946, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 33\n",
            "\n",
            "0: 384x640 4 cars, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 34\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 11.0ms\n",
            "Speed: 2.5ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 35\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 11.6ms\n",
            "Speed: 2.0ms preprocess, 11.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 36\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 37\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 38\n",
            "\n",
            "0: 384x640 1 car, 1 truck, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 39\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 9.4ms\n",
            "Speed: 1.8ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 40\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 9.0ms\n",
            "Speed: 1.6ms preprocess, 9.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 41\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 10.1ms\n",
            "Speed: 1.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 42\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 43\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 8.9ms\n",
            "Speed: 2.8ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 44\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 11.0ms\n",
            "Speed: 2.8ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 45\n",
            "\n",
            "0: 384x640 2 cars, 1 truck, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 46\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 10.4ms\n",
            "Speed: 2.8ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 47\n",
            "\n",
            "0: 384x640 3 cars, 1 truck, 8.5ms\n",
            "Speed: 2.6ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 48\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 49\n",
            "\n",
            "0: 384x640 4 cars, 1 truck, 10.4ms\n",
            "Speed: 3.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 50\n",
            "\n",
            "0: 384x640 4 cars, 10.7ms\n",
            "Speed: 3.3ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 51\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/51'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/51/person_6831.jpg            0.191040   \n",
            "1      6833  frames/51/person_6833.jpg            0.178711   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.632812  0.500000  \n",
            "1              0.604980  0.477295  \n",
            "--------------------------------------------------Frame 52\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/52'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/52/person_6831.jpg            0.191040   \n",
            "1      6833  frames/52/person_6833.jpg            0.178223   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.631836  0.499756  \n",
            "1              0.604004  0.476318  \n",
            "--------------------------------------------------Frame 53\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/53'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/53/person_6831.jpg            0.191040   \n",
            "1      6833  frames/53/person_6833.jpg            0.177002   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.631836  0.499756  \n",
            "1              0.599609  0.472656  \n",
            "--------------------------------------------------Frame 54\n",
            "\n",
            "0: 384x640 2 persons, 5 cars, 1 truck, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/54'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/54/person_6831.jpg            0.191040   \n",
            "1      6833  frames/54/person_6833.jpg            0.176392   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.631836  0.499756  \n",
            "1              0.599121  0.472412  \n",
            "--------------------------------------------------Frame 55\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 truck, 1 chair, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/55'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/55/person_6831.jpg             0.17334   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.637695  tensor(0.4983, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 56\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 truck, 1 chair, 20.5ms\n",
            "Speed: 4.8ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/56'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "1      6835  frames/56/person_6835.jpg            0.205688   \n",
            "0      6831  frames/56/person_6831.jpg            0.174683   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.620605  0.496094  \n",
            "0              0.633301  0.495850  \n",
            "--------------------------------------------------Frame 57\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 truck, 8.9ms\n",
            "Speed: 2.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/57'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "1      6835  frames/57/person_6835.jpg            0.205933   \n",
            "0      6831  frames/57/person_6831.jpg            0.176392   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.618652  0.494873  \n",
            "0              0.626953  0.491943  \n",
            "--------------------------------------------------Frame 58\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 motorcycle, 1 truck, 9.1ms\n",
            "Speed: 1.9ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/58'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/58/person_6831.jpg            0.184204   \n",
            "1      6835  frames/58/person_6835.jpg            0.200439   \n",
            "2      6836  frames/58/person_6836.jpg            0.179443   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.632324  0.497803  \n",
            "1              0.614258  0.489990  \n",
            "2              0.614746  0.484375  \n",
            "--------------------------------------------------Frame 59\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 motorcycle, 1 truck, 12.6ms\n",
            "Speed: 3.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/59'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/59/person_6831.jpg            0.172974   \n",
            "2      6836  frames/59/person_6836.jpg            0.179688   \n",
            "1      6835  frames/59/person_6835.jpg            0.194946   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.625488  0.489746  \n",
            "2              0.615723  0.484863  \n",
            "1              0.600586  0.479004  \n",
            "--------------------------------------------------Frame 60\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 motorcycle, 1 truck, 11.5ms\n",
            "Speed: 3.7ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/60'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/60/person_6831.jpg            0.180664   \n",
            "1      6835  frames/60/person_6835.jpg            0.199463   \n",
            "2      6836  frames/60/person_6836.jpg            0.183350   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.635254  0.498779  \n",
            "1              0.614746  0.490234  \n",
            "2              0.613281  0.484131  \n",
            "--------------------------------------------------Frame 61\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 motorcycle, 1 truck, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/61'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "0      6831  frames/61/person_6831.jpg            0.179932   \n",
            "1      6835  frames/61/person_6835.jpg            0.198730   \n",
            "2      6836  frames/61/person_6836.jpg            0.179565   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.630371  0.495117  \n",
            "1              0.611816  0.487793  \n",
            "2              0.613770  0.483643  \n",
            "--------------------------------------------------Frame 62\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 bus, 1 train, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/62'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "3      6795  frames/62/person_6795.jpg            0.274170   \n",
            "0      6831  frames/62/person_6831.jpg            0.177368   \n",
            "2      6836  frames/62/person_6836.jpg            0.192261   \n",
            "1      6835  frames/62/person_6835.jpg            0.187744   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.654785  0.540527  \n",
            "0              0.641113  0.501953  \n",
            "2              0.592285  0.472168  \n",
            "1              0.572266  0.457031  \n",
            "Best matching track_id is 6795\n",
            "Best matching image path is frames/62/person_6795.jpg\n",
            "Best matching cosine similarity is 0.54052734375\n",
            "--------------------------------------------------Frame 63\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 bus, 1 train, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 64\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 train, 1 truck, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 65\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 train, 1 truck, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 66\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 train, 1 truck, 11.9ms\n",
            "Speed: 2.5ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 67\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 bus, 9.6ms\n",
            "Speed: 2.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 68\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 1 bus, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 69\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 bus, 1 backpack, 20.6ms\n",
            "Speed: 2.8ms preprocess, 20.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 70\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 bus, 1 backpack, 1 umbrella, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 71\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 backpack, 8.7ms\n",
            "Speed: 2.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 72\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 8.7ms\n",
            "Speed: 2.8ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 73\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 74\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 75\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 76\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 77\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 78\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 79\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 10.6ms\n",
            "Speed: 1.9ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 80\n",
            "\n",
            "0: 384x640 9 persons, 1 car, 1 backpack, 13.3ms\n",
            "Speed: 2.0ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 81\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 truck, 1 backpack, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 82\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 truck, 1 backpack, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 83\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 truck, 1 backpack, 10.8ms\n",
            "Speed: 2.6ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 84\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 9.0ms\n",
            "Speed: 2.1ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 85\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 truck, 1 traffic light, 1 backpack, 12.0ms\n",
            "Speed: 2.0ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 86\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 truck, 1 backpack, 9.1ms\n",
            "Speed: 2.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 87\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 trucks, 1 traffic light, 1 backpack, 12.0ms\n",
            "Speed: 1.9ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 88\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 trucks, 1 traffic light, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 89\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 trucks, 1 traffic light, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 90\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 trucks, 1 traffic light, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 91\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 2 trucks, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 92\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 2 trucks, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 93\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 9.7ms\n",
            "Speed: 2.5ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/93'\n",
            "   track_id                 image_path  text_image_cos_sim  \\\n",
            "7      6868  frames/93/person_6868.jpg            0.262695   \n",
            "5      6847  frames/93/person_6847.jpg            0.189087   \n",
            "3      6843  frames/93/person_6843.jpg            0.181030   \n",
            "4      6845  frames/93/person_6845.jpg            0.196289   \n",
            "8      6838  frames/93/person_6838.jpg            0.210938   \n",
            "2      6836  frames/93/person_6836.jpg            0.201904   \n",
            "6      6850  frames/93/person_6850.jpg            0.193359   \n",
            "0      6831  frames/93/person_6831.jpg            0.187744   \n",
            "1      6835  frames/93/person_6835.jpg            0.182251   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "7              0.664062  0.543457  \n",
            "5              0.628418  0.496582  \n",
            "3              0.618652  0.487305  \n",
            "4              0.609375  0.485352  \n",
            "8              0.603027  0.485352  \n",
            "2              0.604004  0.483398  \n",
            "6              0.601562  0.479248  \n",
            "0              0.600098  0.476562  \n",
            "1              0.577637  0.458984  \n",
            "Best matching track_id is 6868\n",
            "Best matching image path is frames/93/person_6868.jpg\n",
            "Best matching cosine similarity is 0.54345703125\n",
            "--------------------------------------------------Frame 94\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 1 truck, 10.5ms\n",
            "Speed: 2.4ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 95\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 96\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 97\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 98\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 2 trucks, 1 traffic light, 9.2ms\n",
            "Speed: 2.0ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 99\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 2 trucks, 1 traffic light, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 100\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 trucks, 1 traffic light, 10.7ms\n",
            "Speed: 2.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 101\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 trucks, 1 traffic light, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 102\n",
            "\n",
            "0: 384x640 10 persons, 4 cars, 2 trucks, 1 traffic light, 13.9ms\n",
            "Speed: 3.1ms preprocess, 13.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 103\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 2 trucks, 9.0ms\n",
            "Speed: 2.3ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 104\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 2 trucks, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 105\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 1 truck, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 106\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 1 truck, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 107\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 108\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 traffic light, 8.8ms\n",
            "Speed: 2.0ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 109\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 traffic light, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 110\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 traffic light, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 111\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 1 traffic light, 8.7ms\n",
            "Speed: 2.1ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 112\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 1 traffic light, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 113\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 1 traffic light, 17.4ms\n",
            "Speed: 2.1ms preprocess, 17.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 114\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 1 traffic light, 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 115\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 traffic light, 13.7ms\n",
            "Speed: 1.8ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 116\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 traffic light, 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 117\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/117'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "8      6896  frames/117/person_6896.jpg            0.269043   \n",
            "7      6838  frames/117/person_6838.jpg            0.217285   \n",
            "0      6831  frames/117/person_6831.jpg            0.191528   \n",
            "6      6850  frames/117/person_6850.jpg            0.196411   \n",
            "5      6847  frames/117/person_6847.jpg            0.194702   \n",
            "4      6845  frames/117/person_6845.jpg            0.209106   \n",
            "2      6836  frames/117/person_6836.jpg            0.205811   \n",
            "1      6835  frames/117/person_6835.jpg            0.203369   \n",
            "3      6843  frames/117/person_6843.jpg            0.164062   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "8              0.680664  0.557129  \n",
            "7              0.647461  0.518555  \n",
            "0              0.634277  0.501465  \n",
            "6              0.625000  0.496338  \n",
            "5              0.625488  0.496094  \n",
            "4              0.605957  0.486816  \n",
            "2              0.605957  0.485840  \n",
            "1              0.601074  0.481689  \n",
            "3              0.596191  0.466553  \n",
            "Best matching track_id is 6896\n",
            "Best matching image path is frames/117/person_6896.jpg\n",
            "Best matching cosine similarity is 0.55712890625\n",
            "--------------------------------------------------Frame 118\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 1 truck, 20.3ms\n",
            "Speed: 2.2ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 119\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 24.9ms\n",
            "Speed: 4.6ms preprocess, 24.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 120\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 12.0ms\n",
            "Speed: 2.9ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 121\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 122\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 123\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 12.1ms\n",
            "Speed: 4.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 124\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 11.6ms\n",
            "Speed: 2.1ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 125\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 126\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 127\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 17.7ms\n",
            "Speed: 2.2ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 128\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 1 handbag, 23.2ms\n",
            "Speed: 2.2ms preprocess, 23.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 129\n",
            "\n",
            "0: 384x640 8 persons, 3 cars, 1 truck, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/129'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "7      6868  frames/129/person_6868.jpg            0.297852   \n",
            "6      6850  frames/129/person_6850.jpg            0.181396   \n",
            "3      6843  frames/129/person_6843.jpg            0.185181   \n",
            "2      6836  frames/129/person_6836.jpg            0.207886   \n",
            "0      6831  frames/129/person_6831.jpg            0.201416   \n",
            "5      6847  frames/129/person_6847.jpg            0.179688   \n",
            "4      6845  frames/129/person_6845.jpg            0.197998   \n",
            "1      6835  frames/129/person_6835.jpg            0.176392   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "7              0.688965  0.571289  \n",
            "6              0.622559  0.490234  \n",
            "3              0.619141  0.488770  \n",
            "2              0.600098  0.482422  \n",
            "0              0.601562  0.481445  \n",
            "5              0.609375  0.480469  \n",
            "4              0.601074  0.479980  \n",
            "1              0.562500  0.446777  \n",
            "Best matching track_id is 6868\n",
            "Best matching image path is frames/129/person_6868.jpg\n",
            "Best matching cosine similarity is 0.5712890625\n",
            "--------------------------------------------------Frame 130\n",
            "\n",
            "0: 384x640 8 persons, 3 cars, 1 motorcycle, 1 truck, 17.7ms\n",
            "Speed: 6.5ms preprocess, 17.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 131\n",
            "\n",
            "0: 384x640 8 persons, 3 cars, 1 motorcycle, 1 truck, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 132\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 133\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 134\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 1 truck, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 135\n",
            "\n",
            "0: 384x640 7 persons, 5 cars, 1 truck, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 136\n",
            "\n",
            "0: 384x640 7 persons, 5 cars, 1 truck, 15.5ms\n",
            "Speed: 6.6ms preprocess, 15.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 137\n",
            "\n",
            "0: 384x640 7 persons, 5 cars, 1 truck, 15.8ms\n",
            "Speed: 2.4ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 138\n",
            "\n",
            "0: 384x640 7 persons, 5 cars, 1 truck, 13.6ms\n",
            "Speed: 2.3ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 139\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 1 truck, 1 handbag, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 140\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 1 truck, 1 handbag, 17.1ms\n",
            "Speed: 2.2ms preprocess, 17.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 141\n",
            "\n",
            "0: 384x640 8 persons, 3 cars, 1 truck, 12.2ms\n",
            "Speed: 2.9ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 142\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 12.3ms\n",
            "Speed: 2.9ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 143\n",
            "\n",
            "0: 384x640 9 persons, 3 cars, 1 truck, 11.5ms\n",
            "Speed: 2.9ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 144\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 145\n",
            "\n",
            "0: 384x640 12 persons, 3 cars, 1 truck, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 146\n",
            "\n",
            "0: 384x640 9 persons, 4 cars, 1 truck, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 147\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 truck, 11.7ms\n",
            "Speed: 2.5ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 148\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 truck, 11.4ms\n",
            "Speed: 2.9ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 149\n",
            "\n",
            "0: 384x640 11 persons, 4 cars, 1 truck, 22.5ms\n",
            "Speed: 2.2ms preprocess, 22.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 150\n",
            "\n",
            "0: 384x640 11 persons, 3 cars, 1 truck, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 151\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 1 traffic light, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 152\n",
            "\n",
            "0: 384x640 10 persons, 3 cars, 1 truck, 1 traffic light, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 153\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 truck, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 154\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 18.0ms\n",
            "Speed: 2.2ms preprocess, 18.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 155\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 156\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 1 handbag, 20.0ms\n",
            "Speed: 2.3ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 157\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 1 handbag, 17.5ms\n",
            "Speed: 4.5ms preprocess, 17.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 158\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 truck, 1 backpack, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 159\n",
            "\n",
            "0: 384x640 10 persons, 2 cars, 1 truck, 1 backpack, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 160\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 17.5ms\n",
            "Speed: 2.2ms preprocess, 17.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 161\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 18.6ms\n",
            "Speed: 2.3ms preprocess, 18.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 162\n",
            "\n",
            "0: 384x640 11 persons, 2 cars, 1 truck, 1 backpack, 16.5ms\n",
            "Speed: 2.4ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 163\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 bus, 1 backpack, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 164\n",
            "\n",
            "0: 384x640 12 persons, 2 cars, 1 bus, 1 truck, 1 backpack, 17.7ms\n",
            "Speed: 2.3ms preprocess, 17.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 165\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 bus, 1 truck, 1 backpack, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 166\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 bus, 1 truck, 1 backpack, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 167\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 trucks, 1 backpack, 18.0ms\n",
            "Speed: 2.2ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 168\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 trucks, 1 backpack, 17.0ms\n",
            "Speed: 2.6ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 169\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 2 trucks, 1 backpack, 18.3ms\n",
            "Speed: 2.2ms preprocess, 18.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 170\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 bus, 1 truck, 1 backpack, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 171\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 2 trucks, 1 backpack, 18.0ms\n",
            "Speed: 2.2ms preprocess, 18.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 172\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 2 trucks, 1 backpack, 18.5ms\n",
            "Speed: 2.1ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 173\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 2 trucks, 1 backpack, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 174\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 1 truck, 1 backpack, 18.5ms\n",
            "Speed: 2.2ms preprocess, 18.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 175\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 1 truck, 1 backpack, 16.7ms\n",
            "Speed: 2.9ms preprocess, 16.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 176\n",
            "\n",
            "0: 384x640 13 persons, 1 car, 1 bus, 1 truck, 1 backpack, 18.3ms\n",
            "Speed: 3.4ms preprocess, 18.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 177\n",
            "\n",
            "0: 384x640 13 persons, 1 bus, 1 truck, 1 backpack, 9.9ms\n",
            "Speed: 2.4ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 178\n",
            "\n",
            "0: 384x640 13 persons, 1 bus, 1 truck, 1 backpack, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 179\n",
            "\n",
            "0: 384x640 11 persons, 1 bus, 1 truck, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 180\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 1 truck, 9.1ms\n",
            "Speed: 2.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 181\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 bus, 1 truck, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 182\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 truck, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 183\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 truck, 11.5ms\n",
            "Speed: 2.4ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 184\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 9.5ms\n",
            "Speed: 1.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 185\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 186\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 1 truck, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 187\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 188\n",
            "\n",
            "0: 384x640 10 persons, 1 car, 1 truck, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 189\n",
            "\n",
            "0: 384x640 8 persons, 1 truck, 9.3ms\n",
            "Speed: 2.4ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 190\n",
            "\n",
            "0: 384x640 10 persons, 1 truck, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 191\n",
            "\n",
            "0: 384x640 10 persons, 1 bus, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 192\n",
            "\n",
            "0: 384x640 10 persons, 1 bus, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 193\n",
            "\n",
            "0: 384x640 10 persons, 1 bus, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 194\n",
            "\n",
            "0: 384x640 7 persons, 10.0ms\n",
            "Speed: 2.4ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 195\n",
            "\n",
            "0: 384x640 8 persons, 9.3ms\n",
            "Speed: 2.3ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 196\n",
            "\n",
            "0: 384x640 8 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 197\n",
            "\n",
            "0: 384x640 9 persons, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 198\n",
            "\n",
            "0: 384x640 9 persons, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 199\n",
            "\n",
            "0: 384x640 9 persons, 10.8ms\n",
            "Speed: 2.3ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 200\n",
            "\n",
            "0: 384x640 10 persons, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 201\n",
            "\n",
            "0: 384x640 8 persons, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 202\n",
            "\n",
            "0: 384x640 9 persons, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 203\n",
            "\n",
            "0: 384x640 9 persons, 9.2ms\n",
            "Speed: 3.2ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 204\n",
            "\n",
            "0: 384x640 12 persons, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 205\n",
            "\n",
            "0: 384x640 12 persons, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 206\n",
            "\n",
            "0: 384x640 11 persons, 18.4ms\n",
            "Speed: 2.2ms preprocess, 18.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 207\n",
            "\n",
            "0: 384x640 11 persons, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 208\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 209\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 motorcycle, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 210\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 motorcycle, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 211\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 motorcycle, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 212\n",
            "\n",
            "0: 384x640 12 persons, 1 car, 1 motorcycle, 15.0ms\n",
            "Speed: 4.4ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 213\n",
            "\n",
            "0: 384x640 6 persons, 9.5ms\n",
            "Speed: 2.4ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 214\n",
            "\n",
            "0: 384x640 7 persons, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 215\n",
            "\n",
            "0: 384x640 7 persons, 10.3ms\n",
            "Speed: 2.4ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 216\n",
            "\n",
            "0: 384x640 7 persons, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 217\n",
            "\n",
            "0: 384x640 7 persons, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 218\n",
            "\n",
            "0: 384x640 7 persons, 8.4ms\n",
            "Speed: 2.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 219\n",
            "\n",
            "0: 384x640 8 persons, 8.6ms\n",
            "Speed: 2.3ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 220\n",
            "\n",
            "0: 384x640 7 persons, 9.1ms\n",
            "Speed: 3.1ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 221\n",
            "\n",
            "0: 384x640 7 persons, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 222\n",
            "\n",
            "0: 384x640 7 persons, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 223\n",
            "\n",
            "0: 384x640 6 persons, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 224\n",
            "\n",
            "0: 384x640 7 persons, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 225\n",
            "\n",
            "0: 384x640 8 persons, 9.4ms\n",
            "Speed: 2.0ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 226\n",
            "\n",
            "0: 384x640 9 persons, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 227\n",
            "\n",
            "0: 384x640 8 persons, 8.8ms\n",
            "Speed: 2.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 228\n",
            "\n",
            "0: 384x640 8 persons, 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 229\n",
            "\n",
            "0: 384x640 8 persons, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 230\n",
            "\n",
            "0: 384x640 8 persons, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 231\n",
            "\n",
            "0: 384x640 9 persons, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 232\n",
            "\n",
            "0: 384x640 10 persons, 8.8ms\n",
            "Speed: 1.6ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 233\n",
            "\n",
            "0: 384x640 10 persons, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 234\n",
            "\n",
            "0: 384x640 10 persons, 11.8ms\n",
            "Speed: 2.5ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 235\n",
            "\n",
            "0: 384x640 10 persons, 10.2ms\n",
            "Speed: 4.4ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 236\n",
            "\n",
            "0: 384x640 10 persons, 19.8ms\n",
            "Speed: 4.1ms preprocess, 19.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 237\n",
            "\n",
            "0: 384x640 10 persons, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 238\n",
            "\n",
            "0: 384x640 11 persons, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 239\n",
            "\n",
            "0: 384x640 11 persons, 12.1ms\n",
            "Speed: 2.5ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 240\n",
            "\n",
            "0: 384x640 11 persons, 1 suitcase, 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 241\n",
            "\n",
            "0: 384x640 11 persons, 1 suitcase, 11.7ms\n",
            "Speed: 2.9ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 242\n",
            "\n",
            "0: 384x640 11 persons, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 243\n",
            "\n",
            "0: 384x640 11 persons, 8.7ms\n",
            "Speed: 1.9ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 244\n",
            "\n",
            "0: 384x640 11 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 245\n",
            "\n",
            "0: 384x640 11 persons, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 246\n",
            "\n",
            "0: 384x640 11 persons, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 247\n",
            "\n",
            "0: 384x640 11 persons, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 248\n",
            "\n",
            "0: 384x640 11 persons, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 249\n",
            "\n",
            "0: 384x640 11 persons, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 250\n",
            "\n",
            "0: 384x640 12 persons, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 251\n",
            "\n",
            "0: 384x640 12 persons, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 252\n",
            "\n",
            "0: 384x640 12 persons, 8.8ms\n",
            "Speed: 3.2ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 253\n",
            "\n",
            "0: 384x640 12 persons, 11.8ms\n",
            "Speed: 3.9ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 254\n",
            "\n",
            "0: 384x640 10 persons, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 255\n",
            "\n",
            "0: 384x640 11 persons, 11.9ms\n",
            "Speed: 2.0ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 256\n",
            "\n",
            "0: 384x640 11 persons, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 257\n",
            "\n",
            "0: 384x640 12 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 258\n",
            "\n",
            "0: 384x640 12 persons, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 259\n",
            "\n",
            "0: 384x640 12 persons, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 260\n",
            "\n",
            "0: 384x640 12 persons, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 261\n",
            "\n",
            "0: 384x640 11 persons, 10.2ms\n",
            "Speed: 2.4ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 262\n",
            "\n",
            "0: 384x640 11 persons, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 263\n",
            "\n",
            "0: 384x640 10 persons, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 264\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 265\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 21.0ms\n",
            "Speed: 2.0ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 266\n",
            "\n",
            "0: 384x640 9 persons, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 267\n",
            "\n",
            "0: 384x640 9 persons, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 268\n",
            "\n",
            "0: 384x640 9 persons, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 269\n",
            "\n",
            "0: 384x640 9 persons, 13.1ms\n",
            "Speed: 2.4ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 270\n",
            "\n",
            "0: 384x640 9 persons, 12.3ms\n",
            "Speed: 3.9ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 271\n",
            "\n",
            "0: 384x640 9 persons, 11.5ms\n",
            "Speed: 2.5ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 272\n",
            "\n",
            "0: 384x640 9 persons, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 273\n",
            "\n",
            "0: 384x640 10 persons, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 274\n",
            "\n",
            "0: 384x640 11 persons, 11.3ms\n",
            "Speed: 2.3ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 275\n",
            "\n",
            "0: 384x640 11 persons, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 276\n",
            "\n",
            "0: 384x640 11 persons, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 277\n",
            "\n",
            "0: 384x640 11 persons, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 278\n",
            "\n",
            "0: 384x640 10 persons, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 279\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 8.8ms\n",
            "Speed: 1.8ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 280\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 281\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 282\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 283\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 284\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 12.5ms\n",
            "Speed: 4.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 285\n",
            "\n",
            "0: 384x640 9 persons, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 286\n",
            "\n",
            "0: 384x640 10 persons, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 287\n",
            "\n",
            "0: 384x640 10 persons, 9.2ms\n",
            "Speed: 2.6ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 288\n",
            "\n",
            "0: 384x640 10 persons, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 289\n",
            "\n",
            "0: 384x640 10 persons, 11.6ms\n",
            "Speed: 2.3ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 290\n",
            "\n",
            "0: 384x640 10 persons, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 291\n",
            "\n",
            "0: 384x640 10 persons, 10.7ms\n",
            "Speed: 2.3ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 292\n",
            "\n",
            "0: 384x640 10 persons, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 293\n",
            "\n",
            "0: 384x640 10 persons, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 294\n",
            "\n",
            "0: 384x640 10 persons, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 295\n",
            "\n",
            "0: 384x640 10 persons, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 296\n",
            "\n",
            "0: 384x640 11 persons, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 297\n",
            "\n",
            "0: 384x640 10 persons, 9.2ms\n",
            "Speed: 2.7ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 298\n",
            "\n",
            "0: 384x640 10 persons, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 299\n",
            "\n",
            "0: 384x640 10 persons, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 300\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 11.4ms\n",
            "Speed: 2.4ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 301\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 302\n",
            "\n",
            "0: 384x640 9 persons, 1 backpack, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 303\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 304\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 10.0ms\n",
            "Speed: 2.6ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 305\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 9.3ms\n",
            "Speed: 2.2ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 306\n",
            "\n",
            "0: 384x640 12 persons, 1 backpack, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 307\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 308\n",
            "\n",
            "0: 384x640 10 persons, 1 backpack, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 309\n",
            "\n",
            "0: 384x640 11 persons, 9.1ms\n",
            "Speed: 2.3ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 310\n",
            "\n",
            "0: 384x640 11 persons, 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 311\n",
            "\n",
            "0: 384x640 10 persons, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 312\n",
            "\n",
            "0: 384x640 11 persons, 10.0ms\n",
            "Speed: 1.9ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 313\n",
            "\n",
            "0: 384x640 11 persons, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 314\n",
            "\n",
            "0: 384x640 10 persons, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 315\n",
            "\n",
            "0: 384x640 10 persons, 9.2ms\n",
            "Speed: 2.4ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 316\n",
            "\n",
            "0: 384x640 10 persons, 11.1ms\n",
            "Speed: 2.2ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 317\n",
            "\n",
            "0: 384x640 10 persons, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 318\n",
            "\n",
            "0: 384x640 10 persons, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 319\n",
            "\n",
            "0: 384x640 11 persons, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 320\n",
            "\n",
            "0: 384x640 11 persons, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 321\n",
            "\n",
            "0: 384x640 11 persons, 9.0ms\n",
            "Speed: 2.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 322\n",
            "\n",
            "0: 384x640 11 persons, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 323\n",
            "\n",
            "0: 384x640 11 persons, 9.7ms\n",
            "Speed: 2.3ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 324\n",
            "\n",
            "0: 384x640 11 persons, 14.7ms\n",
            "Speed: 2.1ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 325\n",
            "\n",
            "0: 384x640 11 persons, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 326\n",
            "\n",
            "0: 384x640 9 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 327\n",
            "\n",
            "0: 384x640 9 persons, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 328\n",
            "\n",
            "0: 384x640 9 persons, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 329\n",
            "\n",
            "0: 384x640 9 persons, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 330\n",
            "\n",
            "0: 384x640 8 persons, 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 331\n",
            "\n",
            "0: 384x640 9 persons, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 332\n",
            "\n",
            "0: 384x640 9 persons, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 333\n",
            "\n",
            "0: 384x640 9 persons, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 334\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 335\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 336\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 337\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 338\n",
            "\n",
            "0: 384x640 10 persons, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 339\n",
            "\n",
            "0: 384x640 10 persons, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 340\n",
            "\n",
            "0: 384x640 10 persons, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 341\n",
            "\n",
            "0: 384x640 10 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 342\n",
            "\n",
            "0: 384x640 10 persons, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 343\n",
            "\n",
            "0: 384x640 9 persons, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 344\n",
            "\n",
            "0: 384x640 10 persons, 13.8ms\n",
            "Speed: 2.5ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 345\n",
            "\n",
            "0: 384x640 8 persons, 9.2ms\n",
            "Speed: 2.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 346\n",
            "\n",
            "0: 384x640 9 persons, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 347\n",
            "\n",
            "0: 384x640 9 persons, 9.3ms\n",
            "Speed: 2.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 348\n",
            "\n",
            "0: 384x640 9 persons, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 349\n",
            "\n",
            "0: 384x640 9 persons, 11.8ms\n",
            "Speed: 1.9ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 350\n",
            "\n",
            "0: 384x640 9 persons, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 351\n",
            "\n",
            "0: 384x640 9 persons, 15.7ms\n",
            "Speed: 2.1ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 352\n",
            "\n",
            "0: 384x640 9 persons, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 353\n",
            "\n",
            "0: 384x640 9 persons, 10.0ms\n",
            "Speed: 2.0ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 354\n",
            "\n",
            "0: 384x640 9 persons, 16.5ms\n",
            "Speed: 2.2ms preprocess, 16.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 355\n",
            "\n",
            "0: 384x640 9 persons, 17.0ms\n",
            "Speed: 2.2ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 356\n",
            "\n",
            "0: 384x640 9 persons, 15.3ms\n",
            "Speed: 2.4ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 357\n",
            "\n",
            "0: 384x640 9 persons, 14.7ms\n",
            "Speed: 2.5ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 358\n",
            "\n",
            "0: 384x640 10 persons, 18.6ms\n",
            "Speed: 2.6ms preprocess, 18.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 359\n",
            "\n",
            "0: 384x640 9 persons, 12.5ms\n",
            "Speed: 2.3ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 360\n",
            "\n",
            "0: 384x640 9 persons, 9.5ms\n",
            "Speed: 2.1ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 361\n",
            "\n",
            "0: 384x640 9 persons, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 362\n",
            "\n",
            "0: 384x640 10 persons, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 363\n",
            "\n",
            "0: 384x640 10 persons, 11.7ms\n",
            "Speed: 2.3ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 364\n",
            "\n",
            "0: 384x640 11 persons, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 365\n",
            "\n",
            "0: 384x640 11 persons, 8.7ms\n",
            "Speed: 1.7ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 366\n",
            "\n",
            "0: 384x640 11 persons, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 367\n",
            "\n",
            "0: 384x640 9 persons, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 368\n",
            "\n",
            "0: 384x640 10 persons, 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 369\n",
            "\n",
            "0: 384x640 9 persons, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 370\n",
            "\n",
            "0: 384x640 11 persons, 11.8ms\n",
            "Speed: 2.4ms preprocess, 11.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 371\n",
            "\n",
            "0: 384x640 11 persons, 10.2ms\n",
            "Speed: 2.1ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 372\n",
            "\n",
            "0: 384x640 11 persons, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 373\n",
            "\n",
            "0: 384x640 11 persons, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 374\n",
            "\n",
            "0: 384x640 11 persons, 9.8ms\n",
            "Speed: 2.4ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 375\n",
            "\n",
            "0: 384x640 11 persons, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 376\n",
            "\n",
            "0: 384x640 8 persons, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 377\n",
            "\n",
            "0: 384x640 9 persons, 9.8ms\n",
            "Speed: 2.3ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 378\n",
            "\n",
            "0: 384x640 9 persons, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 379\n",
            "\n",
            "0: 384x640 9 persons, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 380\n",
            "\n",
            "0: 384x640 10 persons, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 381\n",
            "\n",
            "0: 384x640 10 persons, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 382\n",
            "\n",
            "0: 384x640 10 persons, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 383\n",
            "\n",
            "0: 384x640 10 persons, 15.4ms\n",
            "Speed: 2.4ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 384\n",
            "\n",
            "0: 384x640 10 persons, 11.8ms\n",
            "Speed: 2.6ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 385\n",
            "\n",
            "0: 384x640 10 persons, 11.6ms\n",
            "Speed: 2.6ms preprocess, 11.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 386\n",
            "\n",
            "0: 384x640 10 persons, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 387\n",
            "\n",
            "0: 384x640 10 persons, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 388\n",
            "\n",
            "0: 384x640 10 persons, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 389\n",
            "\n",
            "0: 384x640 10 persons, 12.0ms\n",
            "Speed: 2.7ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 390\n",
            "\n",
            "0: 384x640 10 persons, 13.7ms\n",
            "Speed: 2.9ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 391\n",
            "\n",
            "0: 384x640 10 persons, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 392\n",
            "\n",
            "0: 384x640 10 persons, 1 handbag, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 393\n",
            "\n",
            "0: 384x640 10 persons, 1 handbag, 8.9ms\n",
            "Speed: 1.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 394\n",
            "\n",
            "0: 384x640 12 persons, 1 handbag, 15.7ms\n",
            "Speed: 2.1ms preprocess, 15.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 395\n",
            "\n",
            "0: 384x640 11 persons, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 396\n",
            "\n",
            "0: 384x640 12 persons, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 397\n",
            "\n",
            "0: 384x640 12 persons, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 398\n",
            "\n",
            "0: 384x640 12 persons, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 399\n",
            "\n",
            "0: 384x640 12 persons, 1 bus, 14.6ms\n",
            "Speed: 2.7ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 400\n",
            "\n",
            "0: 384x640 12 persons, 1 bus, 9.5ms\n",
            "Speed: 2.2ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 401\n",
            "\n",
            "0: 384x640 12 persons, 1 bus, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 402\n",
            "\n",
            "0: 384x640 12 persons, 1 bus, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 403\n",
            "\n",
            "0: 384x640 12 persons, 1 bus, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 404\n",
            "\n",
            "0: 384x640 13 persons, 1 bus, 15.6ms\n",
            "Speed: 2.1ms preprocess, 15.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 405\n",
            "\n",
            "0: 384x640 11 persons, 1 bus, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 406\n",
            "\n",
            "0: 384x640 11 persons, 1 bus, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 407\n",
            "\n",
            "0: 384x640 9 persons, 10.5ms\n",
            "Speed: 2.6ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 408\n",
            "\n",
            "0: 384x640 8 persons, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 409\n",
            "\n",
            "0: 384x640 9 persons, 9.8ms\n",
            "Speed: 3.0ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 410\n",
            "\n",
            "0: 384x640 9 persons, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 411\n",
            "\n",
            "0: 384x640 9 persons, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 412\n",
            "\n",
            "0: 384x640 9 persons, 20.2ms\n",
            "Speed: 2.3ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 413\n",
            "\n",
            "0: 384x640 10 persons, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 414\n",
            "\n",
            "0: 384x640 10 persons, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 415\n",
            "\n",
            "0: 384x640 10 persons, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 416\n",
            "\n",
            "0: 384x640 10 persons, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 417\n",
            "\n",
            "0: 384x640 10 persons, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 418\n",
            "\n",
            "0: 384x640 10 persons, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 419\n",
            "\n",
            "0: 384x640 10 persons, 12.8ms\n",
            "Speed: 2.0ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 420\n",
            "\n",
            "0: 384x640 10 persons, 8.6ms\n",
            "Speed: 2.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 421\n",
            "\n",
            "0: 384x640 10 persons, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 422\n",
            "\n",
            "0: 384x640 10 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 423\n",
            "\n",
            "0: 384x640 10 persons, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 424\n",
            "\n",
            "0: 384x640 10 persons, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 425\n",
            "\n",
            "0: 384x640 11 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 426\n",
            "\n",
            "0: 384x640 11 persons, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 427\n",
            "\n",
            "0: 384x640 12 persons, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 428\n",
            "\n",
            "0: 384x640 13 persons, 12.5ms\n",
            "Speed: 2.8ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 429\n",
            "\n",
            "0: 384x640 11 persons, 9.2ms\n",
            "Speed: 2.2ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 430\n",
            "\n",
            "0: 384x640 11 persons, 2 motorcycles, 10.1ms\n",
            "Speed: 2.8ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 431\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 432\n",
            "\n",
            "0: 384x640 11 persons, 2 motorcycles, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 433\n",
            "\n",
            "0: 384x640 11 persons, 2 motorcycles, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 434\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 435\n",
            "\n",
            "0: 384x640 10 persons, 2 motorcycles, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 436\n",
            "\n",
            "0: 384x640 10 persons, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 437\n",
            "\n",
            "0: 384x640 10 persons, 9.7ms\n",
            "Speed: 4.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 438\n",
            "\n",
            "0: 384x640 10 persons, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 439\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 440\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 441\n",
            "\n",
            "0: 384x640 10 persons, 16.1ms\n",
            "Speed: 2.2ms preprocess, 16.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 442\n",
            "\n",
            "0: 384x640 10 persons, 12.8ms\n",
            "Speed: 2.1ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 443\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 12.0ms\n",
            "Speed: 2.1ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 444\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 445\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 446\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 9.9ms\n",
            "Speed: 2.1ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 447\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 448\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 9.8ms\n",
            "Speed: 2.8ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 449\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 450\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 451\n",
            "\n",
            "0: 384x640 12 persons, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 452\n",
            "\n",
            "0: 384x640 12 persons, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 453\n",
            "\n",
            "0: 384x640 11 persons, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 454\n",
            "\n",
            "0: 384x640 12 persons, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 455\n",
            "\n",
            "0: 384x640 11 persons, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 456\n",
            "\n",
            "0: 384x640 11 persons, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 457\n",
            "\n",
            "0: 384x640 11 persons, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 458\n",
            "\n",
            "0: 384x640 10 persons, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 459\n",
            "\n",
            "0: 384x640 11 persons, 2 backpacks, 15.5ms\n",
            "Speed: 1.9ms preprocess, 15.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 460\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 461\n",
            "\n",
            "0: 384x640 12 persons, 2 backpacks, 15.1ms\n",
            "Speed: 2.3ms preprocess, 15.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 462\n",
            "\n",
            "0: 384x640 13 persons, 2 backpacks, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 463\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 22.8ms\n",
            "Speed: 2.2ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 464\n",
            "\n",
            "0: 384x640 13 persons, 1 backpack, 17.7ms\n",
            "Speed: 2.3ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 465\n",
            "\n",
            "0: 384x640 10 persons, 15.7ms\n",
            "Speed: 2.0ms preprocess, 15.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 466\n",
            "\n",
            "0: 384x640 11 persons, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 467\n",
            "\n",
            "0: 384x640 10 persons, 21.7ms\n",
            "Speed: 2.1ms preprocess, 21.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 468\n",
            "\n",
            "0: 384x640 10 persons, 12.3ms\n",
            "Speed: 2.5ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 469\n",
            "\n",
            "0: 384x640 10 persons, 15.5ms\n",
            "Speed: 2.2ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 470\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 11.8ms\n",
            "Speed: 5.3ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 471\n",
            "\n",
            "0: 384x640 11 persons, 1 car, 17.5ms\n",
            "Speed: 2.3ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 472\n",
            "\n",
            "0: 384x640 10 persons, 12.0ms\n",
            "Speed: 2.2ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 473\n",
            "\n",
            "0: 384x640 12 persons, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 474\n",
            "\n",
            "0: 384x640 12 persons, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 475\n",
            "\n",
            "0: 384x640 10 persons, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 476\n",
            "\n",
            "0: 384x640 9 persons, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 477\n",
            "\n",
            "0: 384x640 9 persons, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 478\n",
            "\n",
            "0: 384x640 10 persons, 12.3ms\n",
            "Speed: 4.1ms preprocess, 12.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 479\n",
            "\n",
            "0: 384x640 9 persons, 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 480\n",
            "\n",
            "0: 384x640 9 persons, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 481\n",
            "\n",
            "0: 384x640 9 persons, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 482\n",
            "\n",
            "0: 384x640 9 persons, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 483\n",
            "\n",
            "0: 384x640 9 persons, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 484\n",
            "\n",
            "0: 384x640 9 persons, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 485\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 486\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 487\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 13.5ms\n",
            "Speed: 5.4ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 488\n",
            "\n",
            "0: 384x640 12 persons, 1 motorcycle, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 489\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 15.5ms\n",
            "Speed: 4.8ms preprocess, 15.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/489'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "8      7368  frames/489/person_7368.jpg            0.336914   \n",
            "5      7361  frames/489/person_7361.jpg            0.262695   \n",
            "9      7301  frames/489/person_7301.jpg            0.210571   \n",
            "3      7328  frames/489/person_7328.jpg            0.211914   \n",
            "6      7362  frames/489/person_7362.jpg            0.203857   \n",
            "0      7034  frames/489/person_7034.jpg            0.220215   \n",
            "4      7168  frames/489/person_7168.jpg            0.226318   \n",
            "1      7276  frames/489/person_7276.jpg            0.209106   \n",
            "2      7288  frames/489/person_7288.jpg            0.188843   \n",
            "7      7366  frames/489/person_7366.jpg            0.204834   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "8              0.742676  0.621094  \n",
            "5              0.707520  0.574219  \n",
            "9              0.630859  0.504883  \n",
            "3              0.625977  0.501953  \n",
            "6              0.621094  0.496094  \n",
            "0              0.613281  0.495117  \n",
            "4              0.608398  0.493652  \n",
            "1              0.613770  0.492432  \n",
            "2              0.616699  0.488281  \n",
            "7              0.595215  0.478271  \n",
            "Best matching track_id is 7368\n",
            "Best matching image path is frames/489/person_7368.jpg\n",
            "Best matching cosine similarity is 0.62109375\n",
            "--------------------------------------------------Frame 490\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 1 backpack, 18.1ms\n",
            "Speed: 2.2ms preprocess, 18.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 491\n",
            "\n",
            "0: 384x640 7 persons, 17.3ms\n",
            "Speed: 2.2ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/491'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      6868  frames/491/person_6868.jpg            0.317871   \n",
            "3      7301  frames/491/person_7301.jpg            0.218262   \n",
            "1      7276  frames/491/person_7276.jpg            0.205933   \n",
            "2      7328  frames/491/person_7328.jpg            0.209717   \n",
            "0      7034  frames/491/person_7034.jpg            0.209351   \n",
            "5      7048  frames/491/person_7048.jpg            0.204590   \n",
            "6      7367  frames/491/person_7367.jpg            0.202637   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.758789  0.626465  \n",
            "3              0.641602  0.514648  \n",
            "1              0.636230  0.506836  \n",
            "2              0.631348  0.504883  \n",
            "0              0.618164  0.495361  \n",
            "5              0.610352  0.488525  \n",
            "6              0.592773  0.475830  \n",
            "Best matching track_id is 6868\n",
            "Best matching image path is frames/491/person_6868.jpg\n",
            "Best matching cosine similarity is 0.62646484375\n",
            "--------------------------------------------------Frame 492\n",
            "\n",
            "0: 384x640 9 persons, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 493\n",
            "\n",
            "0: 384x640 9 persons, 12.1ms\n",
            "Speed: 5.3ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 494\n",
            "\n",
            "0: 384x640 9 persons, 16.5ms\n",
            "Speed: 6.3ms preprocess, 16.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 495\n",
            "\n",
            "0: 384x640 9 persons, 15.5ms\n",
            "Speed: 2.3ms preprocess, 15.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 496\n",
            "\n",
            "0: 384x640 9 persons, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 497\n",
            "\n",
            "0: 384x640 10 persons, 15.5ms\n",
            "Speed: 2.2ms preprocess, 15.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 498\n",
            "\n",
            "0: 384x640 10 persons, 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 499\n",
            "\n",
            "0: 384x640 9 persons, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 500\n",
            "\n",
            "0: 384x640 9 persons, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 501\n",
            "\n",
            "0: 384x640 7 persons, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 502\n",
            "\n",
            "0: 384x640 7 persons, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 503\n",
            "\n",
            "0: 384x640 9 persons, 16.8ms\n",
            "Speed: 4.2ms preprocess, 16.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 504\n",
            "\n",
            "0: 384x640 9 persons, 16.2ms\n",
            "Speed: 2.2ms preprocess, 16.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 505\n",
            "\n",
            "0: 384x640 9 persons, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 506\n",
            "\n",
            "0: 384x640 9 persons, 15.2ms\n",
            "Speed: 4.1ms preprocess, 15.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 507\n",
            "\n",
            "0: 384x640 9 persons, 12.1ms\n",
            "Speed: 2.8ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 508\n",
            "\n",
            "0: 384x640 9 persons, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 509\n",
            "\n",
            "0: 384x640 9 persons, 16.0ms\n",
            "Speed: 2.8ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 510\n",
            "\n",
            "0: 384x640 9 persons, 18.6ms\n",
            "Speed: 2.4ms preprocess, 18.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 511\n",
            "\n",
            "0: 384x640 9 persons, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 512\n",
            "\n",
            "0: 384x640 9 persons, 14.4ms\n",
            "Speed: 2.2ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 513\n",
            "\n",
            "0: 384x640 10 persons, 22.1ms\n",
            "Speed: 3.4ms preprocess, 22.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 514\n",
            "\n",
            "0: 384x640 10 persons, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 515\n",
            "\n",
            "0: 384x640 8 persons, 15.7ms\n",
            "Speed: 2.2ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 516\n",
            "\n",
            "0: 384x640 8 persons, 20.0ms\n",
            "Speed: 2.2ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 517\n",
            "\n",
            "0: 384x640 8 persons, 18.9ms\n",
            "Speed: 2.1ms preprocess, 18.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 518\n",
            "\n",
            "0: 384x640 8 persons, 15.6ms\n",
            "Speed: 2.3ms preprocess, 15.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 519\n",
            "\n",
            "0: 384x640 8 persons, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 520\n",
            "\n",
            "0: 384x640 8 persons, 18.1ms\n",
            "Speed: 5.9ms preprocess, 18.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 521\n",
            "\n",
            "0: 384x640 9 persons, 18.4ms\n",
            "Speed: 3.6ms preprocess, 18.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 522\n",
            "\n",
            "0: 384x640 9 persons, 19.0ms\n",
            "Speed: 2.3ms preprocess, 19.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 523\n",
            "\n",
            "0: 384x640 9 persons, 1 handbag, 17.4ms\n",
            "Speed: 2.2ms preprocess, 17.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 524\n",
            "\n",
            "0: 384x640 9 persons, 1 handbag, 14.5ms\n",
            "Speed: 6.5ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 525\n",
            "\n",
            "0: 384x640 10 persons, 1 handbag, 19.4ms\n",
            "Speed: 2.3ms preprocess, 19.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 526\n",
            "\n",
            "0: 384x640 10 persons, 1 handbag, 17.7ms\n",
            "Speed: 2.2ms preprocess, 17.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 527\n",
            "\n",
            "0: 384x640 9 persons, 15.9ms\n",
            "Speed: 2.3ms preprocess, 15.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 528\n",
            "\n",
            "0: 384x640 9 persons, 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 529\n",
            "\n",
            "0: 384x640 9 persons, 22.1ms\n",
            "Speed: 2.1ms preprocess, 22.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 530\n",
            "\n",
            "0: 384x640 9 persons, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 531\n",
            "\n",
            "0: 384x640 10 persons, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 532\n",
            "\n",
            "0: 384x640 9 persons, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 533\n",
            "\n",
            "0: 384x640 10 persons, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 534\n",
            "\n",
            "0: 384x640 10 persons, 12.6ms\n",
            "Speed: 2.4ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 535\n",
            "\n",
            "0: 384x640 8 persons, 9.8ms\n",
            "Speed: 2.1ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 536\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 9.6ms\n",
            "Speed: 2.2ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 537\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 538\n",
            "\n",
            "0: 384x640 10 persons, 1 motorcycle, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 539\n",
            "\n",
            "0: 384x640 7 persons, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 540\n",
            "\n",
            "0: 384x640 8 persons, 9.6ms\n",
            "Speed: 2.0ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 541\n",
            "\n",
            "0: 384x640 8 persons, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 542\n",
            "\n",
            "0: 384x640 8 persons, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 543\n",
            "\n",
            "0: 384x640 8 persons, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 544\n",
            "\n",
            "0: 384x640 7 persons, 10.0ms\n",
            "Speed: 2.3ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 545\n",
            "\n",
            "0: 384x640 7 persons, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 546\n",
            "\n",
            "0: 384x640 7 persons, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 547\n",
            "\n",
            "0: 384x640 8 persons, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 548\n",
            "\n",
            "0: 384x640 8 persons, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 549\n",
            "\n",
            "0: 384x640 9 persons, 9.8ms\n",
            "Speed: 2.9ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 550\n",
            "\n",
            "0: 384x640 9 persons, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 551\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 552\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 16.4ms\n",
            "Speed: 2.2ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 553\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 554\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 10.4ms\n",
            "Speed: 2.6ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 555\n",
            "\n",
            "0: 384x640 8 persons, 2 motorcycles, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 556\n",
            "\n",
            "0: 384x640 7 persons, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 557\n",
            "\n",
            "0: 384x640 7 persons, 1 bus, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 558\n",
            "\n",
            "0: 384x640 7 persons, 1 bus, 15.1ms\n",
            "Speed: 2.1ms preprocess, 15.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 559\n",
            "\n",
            "0: 384x640 8 persons, 1 bus, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 560\n",
            "\n",
            "0: 384x640 8 persons, 1 bus, 1 handbag, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 561\n",
            "\n",
            "0: 384x640 8 persons, 1 bus, 1 handbag, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 562\n",
            "\n",
            "0: 384x640 8 persons, 1 bus, 1 handbag, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 563\n",
            "\n",
            "0: 384x640 9 persons, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 564\n",
            "\n",
            "0: 384x640 9 persons, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 565\n",
            "\n",
            "0: 384x640 9 persons, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 566\n",
            "\n",
            "0: 384x640 9 persons, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 567\n",
            "\n",
            "0: 384x640 9 persons, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 568\n",
            "\n",
            "0: 384x640 9 persons, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 569\n",
            "\n",
            "0: 384x640 9 persons, 19.3ms\n",
            "Speed: 2.6ms preprocess, 19.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 570\n",
            "\n",
            "0: 384x640 9 persons, 14.4ms\n",
            "Speed: 2.9ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 571\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 8.9ms\n",
            "Speed: 2.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 572\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 573\n",
            "\n",
            "0: 384x640 7 persons, 1 motorcycle, 10.3ms\n",
            "Speed: 2.3ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 574\n",
            "\n",
            "0: 384x640 9 persons, 1 motorcycle, 1 dog, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 575\n",
            "\n",
            "0: 384x640 6 persons, 1 motorcycle, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 576\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 10.0ms\n",
            "Speed: 2.1ms preprocess, 10.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 577\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 10.4ms\n",
            "Speed: 2.3ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 578\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 579\n",
            "\n",
            "0: 384x640 8 persons, 1 motorcycle, 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 580\n",
            "\n",
            "0: 384x640 7 persons, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 581\n",
            "\n",
            "0: 384x640 7 persons, 8.9ms\n",
            "Speed: 2.1ms preprocess, 8.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 582\n",
            "\n",
            "0: 384x640 7 persons, 20.2ms\n",
            "Speed: 2.2ms preprocess, 20.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 583\n",
            "\n",
            "0: 384x640 7 persons, 9.6ms\n",
            "Speed: 2.5ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 584\n",
            "\n",
            "0: 384x640 7 persons, 1 backpack, 1 tie, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 585\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 tie, 10.1ms\n",
            "Speed: 2.1ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 586\n",
            "\n",
            "0: 384x640 6 persons, 1 backpack, 1 tie, 11.5ms\n",
            "Speed: 2.2ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 587\n",
            "\n",
            "0: 384x640 7 persons, 8.9ms\n",
            "Speed: 2.6ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 588\n",
            "\n",
            "0: 384x640 6 persons, 9.8ms\n",
            "Speed: 2.0ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 589\n",
            "\n",
            "0: 384x640 7 persons, 11.2ms\n",
            "Speed: 2.1ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 590\n",
            "\n",
            "0: 384x640 7 persons, 11.3ms\n",
            "Speed: 2.1ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 591\n",
            "\n",
            "0: 384x640 7 persons, 12.4ms\n",
            "Speed: 2.5ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 592\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 593\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 11.2ms\n",
            "Speed: 2.2ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 594\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 12.8ms\n",
            "Speed: 5.9ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 595\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 9.7ms\n",
            "Speed: 2.0ms preprocess, 9.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 596\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 12.3ms\n",
            "Speed: 2.1ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 597\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 598\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 599\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 13.3ms\n",
            "Speed: 2.6ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 600\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 9.3ms\n",
            "Speed: 2.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 601\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 602\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 9.4ms\n",
            "Speed: 2.1ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 603\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 604\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 605\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 606\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 14.6ms\n",
            "Speed: 2.1ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 607\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 tie, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 608\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 13.0ms\n",
            "Speed: 2.5ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 609\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 610\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 11.7ms\n",
            "Speed: 3.5ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 611\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 15.4ms\n",
            "Speed: 2.3ms preprocess, 15.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 612\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 9.7ms\n",
            "Speed: 2.2ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 613\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 614\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 615\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 616\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 617\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tie, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 618\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 17.0ms\n",
            "Speed: 3.2ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 619\n",
            "\n",
            "0: 384x640 7 persons, 21.8ms\n",
            "Speed: 1.7ms preprocess, 21.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 620\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 621\n",
            "\n",
            "0: 384x640 7 persons, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 622\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 623\n",
            "\n",
            "0: 384x640 7 persons, 10.1ms\n",
            "Speed: 2.2ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 624\n",
            "\n",
            "0: 384x640 7 persons, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 625\n",
            "\n",
            "0: 384x640 7 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 626\n",
            "\n",
            "0: 384x640 7 persons, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 627\n",
            "\n",
            "0: 384x640 7 persons, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 628\n",
            "\n",
            "0: 384x640 6 persons, 11.4ms\n",
            "Speed: 1.9ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 629\n",
            "\n",
            "0: 384x640 6 persons, 1 tie, 12.9ms\n",
            "Speed: 3.9ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 630\n",
            "\n",
            "0: 384x640 6 persons, 1 tie, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 631\n",
            "\n",
            "0: 384x640 7 persons, 9.9ms\n",
            "Speed: 2.5ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 632\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 633\n",
            "\n",
            "0: 384x640 6 persons, 10.6ms\n",
            "Speed: 2.0ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 634\n",
            "\n",
            "0: 384x640 9 persons, 1 handbag, 1 tie, 11.7ms\n",
            "Speed: 3.3ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 635\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 636\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 10.8ms\n",
            "Speed: 2.1ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 637\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 638\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 639\n",
            "\n",
            "0: 384x640 7 persons, 1 handbag, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 640\n",
            "\n",
            "0: 384x640 8 persons, 16.7ms\n",
            "Speed: 2.3ms preprocess, 16.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 641\n",
            "\n",
            "0: 384x640 9 persons, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 642\n",
            "\n",
            "0: 384x640 10 persons, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 643\n",
            "\n",
            "0: 384x640 9 persons, 1 tie, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 644\n",
            "\n",
            "0: 384x640 9 persons, 1 tie, 9.7ms\n",
            "Speed: 2.1ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 645\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 9.2ms\n",
            "Speed: 2.1ms preprocess, 9.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 646\n",
            "\n",
            "0: 384x640 8 persons, 1 tie, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 647\n",
            "\n",
            "0: 384x640 7 persons, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 648\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 649\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 650\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 651\n",
            "\n",
            "0: 384x640 7 persons, 1 tie, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 652\n",
            "\n",
            "0: 384x640 8 persons, 1 tie, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 653\n",
            "\n",
            "0: 384x640 8 persons, 1 tie, 11.5ms\n",
            "Speed: 3.9ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 654\n",
            "\n",
            "0: 384x640 8 persons, 1 tie, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 655\n",
            "\n",
            "0: 384x640 8 persons, 1 tie, 10.3ms\n",
            "Speed: 2.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 656\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 1 tie, 12.7ms\n",
            "Speed: 2.4ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 657\n",
            "\n",
            "0: 384x640 8 persons, 1 handbag, 10.4ms\n",
            "Speed: 2.5ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 658\n",
            "\n",
            "0: 384x640 10 persons, 1 handbag, 1 tie, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 659\n",
            "\n",
            "0: 384x640 7 persons, 15.0ms\n",
            "Speed: 2.2ms preprocess, 15.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 660\n",
            "\n",
            "0: 384x640 9 persons, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 661\n",
            "\n",
            "0: 384x640 9 persons, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 662\n",
            "\n",
            "0: 384x640 9 persons, 9.8ms\n",
            "Speed: 2.2ms preprocess, 9.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 663\n",
            "\n",
            "0: 384x640 9 persons, 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 664\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/664'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/664/person_7545.jpg            0.178345   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.621094  tensor(0.4883, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 665\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 traffic light, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/665'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/665/person_7545.jpg            0.184326   \n",
            "1      7548  frames/665/person_7548.jpg            0.188110   \n",
            "2      7552  frames/665/person_7552.jpg            0.195801   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.617188  0.487305  \n",
            "1              0.599609  0.476074  \n",
            "2              0.594727  0.475098  \n",
            "--------------------------------------------------Frame 666\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 traffic lights, 12.7ms\n",
            "Speed: 2.0ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/666'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/666/person_7545.jpg            0.192505   \n",
            "2      7552  frames/666/person_7552.jpg            0.203735   \n",
            "1      7548  frames/666/person_7548.jpg            0.187622   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.620605  0.492188  \n",
            "2              0.594238  0.477051  \n",
            "1              0.594727  0.472656  \n",
            "--------------------------------------------------Frame 667\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 traffic lights, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/667'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/667/person_7545.jpg            0.193115   \n",
            "1      7548  frames/667/person_7548.jpg            0.186768   \n",
            "2      7552  frames/667/person_7552.jpg            0.202026   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.619629  0.491699  \n",
            "1              0.592285  0.470703  \n",
            "2              0.582031  0.468018  \n",
            "--------------------------------------------------Frame 668\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 traffic lights, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/668'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/668/person_7545.jpg            0.192505   \n",
            "1      7548  frames/668/person_7548.jpg            0.186401   \n",
            "2      7552  frames/668/person_7552.jpg            0.202026   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.623535  0.494141  \n",
            "1              0.611816  0.484131  \n",
            "2              0.582031  0.468018  \n",
            "--------------------------------------------------Frame 669\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 2 traffic lights, 9.8ms\n",
            "Speed: 2.7ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/669'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7548  frames/669/person_7548.jpg            0.195923   \n",
            "0      7545  frames/669/person_7545.jpg            0.189819   \n",
            "2      7552  frames/669/person_7552.jpg            0.187134   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.621094  0.493652  \n",
            "0              0.616699  0.488525  \n",
            "2              0.605957  0.480225  \n",
            "--------------------------------------------------Frame 670\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 truck, 2 traffic lights, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/670'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7548  frames/670/person_7548.jpg            0.195190   \n",
            "0      7545  frames/670/person_7545.jpg            0.187134   \n",
            "2      7552  frames/670/person_7552.jpg            0.193848   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.625488  0.496338  \n",
            "0              0.610352  0.483398  \n",
            "2              0.601074  0.478760  \n",
            "--------------------------------------------------Frame 671\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 2.3ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/671'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/671/person_7545.jpg            0.214966   \n",
            "1      7548  frames/671/person_7548.jpg            0.203491   \n",
            "2      7552  frames/671/person_7552.jpg            0.174805   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.610840  0.491943  \n",
            "1              0.615234  0.491699  \n",
            "2              0.590332  0.465820  \n",
            "--------------------------------------------------Frame 672\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 traffic light, 10.2ms\n",
            "Speed: 2.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/672'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7548  frames/672/person_7548.jpg            0.203491   \n",
            "3      7564  frames/672/person_7564.jpg            0.247681   \n",
            "0      7545  frames/672/person_7545.jpg            0.198364   \n",
            "2      7552  frames/672/person_7552.jpg            0.182739   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.634277  0.504883  \n",
            "3              0.610840  0.501953  \n",
            "0              0.605957  0.483643  \n",
            "2              0.591309  0.468750  \n",
            "--------------------------------------------------Frame 673\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 traffic light, 9.5ms\n",
            "Speed: 2.3ms preprocess, 9.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/673'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7564  frames/673/person_7564.jpg            0.248535   \n",
            "1      7548  frames/673/person_7548.jpg            0.209106   \n",
            "0      7545  frames/673/person_7545.jpg            0.196289   \n",
            "2      7552  frames/673/person_7552.jpg            0.185913   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.616699  0.506348  \n",
            "1              0.611816  0.490967  \n",
            "0              0.611328  0.486816  \n",
            "2              0.588379  0.467773  \n",
            "--------------------------------------------------Frame 674\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 traffic light, 10.9ms\n",
            "Speed: 2.8ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/674'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7564  frames/674/person_7564.jpg            0.234741   \n",
            "1      7548  frames/674/person_7548.jpg            0.210815   \n",
            "0      7545  frames/674/person_7545.jpg            0.197021   \n",
            "2      7552  frames/674/person_7552.jpg            0.186523   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.610352  0.497559  \n",
            "1              0.611816  0.491455  \n",
            "0              0.611328  0.487061  \n",
            "2              0.584473  0.465088  \n",
            "--------------------------------------------------Frame 675\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 1 traffic light, 11.3ms\n",
            "Speed: 2.5ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/675'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7564  frames/675/person_7564.jpg            0.232178   \n",
            "1      7548  frames/675/person_7548.jpg            0.216553   \n",
            "0      7545  frames/675/person_7545.jpg            0.190552   \n",
            "2      7552  frames/675/person_7552.jpg            0.181396   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.606934  0.494385  \n",
            "1              0.613281  0.494141  \n",
            "0              0.608887  0.483398  \n",
            "2              0.586914  0.465332  \n",
            "--------------------------------------------------Frame 676\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 2 traffic lights, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/676'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7548  frames/676/person_7548.jpg            0.217407   \n",
            "0      7545  frames/676/person_7545.jpg            0.204468   \n",
            "3      7564  frames/676/person_7564.jpg            0.228027   \n",
            "2      7552  frames/676/person_7552.jpg            0.174805   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.609375  0.491699  \n",
            "0              0.609863  0.488281  \n",
            "3              0.586914  0.479248  \n",
            "2              0.580566  0.458984  \n",
            "--------------------------------------------------Frame 677\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 truck, 3 traffic lights, 9.6ms\n",
            "Speed: 2.6ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/677'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7564  frames/677/person_7564.jpg            0.248535   \n",
            "1      7548  frames/677/person_7548.jpg            0.214844   \n",
            "0      7545  frames/677/person_7545.jpg            0.201416   \n",
            "2      7552  frames/677/person_7552.jpg            0.186157   \n",
            "4      7576  frames/677/person_7576.jpg            0.127075   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.594727  0.490723  \n",
            "1              0.605469  0.488281  \n",
            "0              0.609863  0.487305  \n",
            "2              0.594727  0.472168  \n",
            "4              0.550781  0.423584  \n",
            "--------------------------------------------------Frame 678\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 truck, 3 traffic lights, 12.3ms\n",
            "Speed: 4.2ms preprocess, 12.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/678'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7564  frames/678/person_7564.jpg            0.254395   \n",
            "0      7545  frames/678/person_7545.jpg            0.203247   \n",
            "1      7548  frames/678/person_7548.jpg            0.217163   \n",
            "2      7552  frames/678/person_7552.jpg            0.185669   \n",
            "4      7576  frames/678/person_7576.jpg            0.127563   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.604492  0.499512  \n",
            "0              0.612793  0.489990  \n",
            "1              0.604492  0.488281  \n",
            "2              0.594238  0.471680  \n",
            "4              0.551758  0.424561  \n",
            "--------------------------------------------------Frame 679\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 3 traffic lights, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/679'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7548  frames/679/person_7548.jpg            0.222534   \n",
            "0      7545  frames/679/person_7545.jpg            0.213379   \n",
            "2      7552  frames/679/person_7552.jpg            0.197754   \n",
            "3      7564  frames/679/person_7564.jpg            0.228394   \n",
            "4      7576  frames/679/person_7576.jpg            0.130493   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.615723  0.497559  \n",
            "0              0.618652  0.497070  \n",
            "2              0.603027  0.481445  \n",
            "3              0.582520  0.476318  \n",
            "4              0.544922  0.420410  \n",
            "--------------------------------------------------Frame 680\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 3 traffic lights, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/680'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/680/person_7545.jpg            0.210327   \n",
            "1      7548  frames/680/person_7548.jpg            0.224365   \n",
            "2      7552  frames/680/person_7552.jpg            0.186035   \n",
            "3      7564  frames/680/person_7564.jpg            0.217529   \n",
            "4      7576  frames/680/person_7576.jpg            0.132568   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.623535  0.499512  \n",
            "1              0.606445  0.491943  \n",
            "2              0.594727  0.472168  \n",
            "3              0.560547  0.457520  \n",
            "4              0.545898  0.421875  \n",
            "--------------------------------------------------Frame 681\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 3 traffic lights, 12.1ms\n",
            "Speed: 3.3ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/681'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/681/person_7545.jpg            0.215942   \n",
            "3      7564  frames/681/person_7564.jpg            0.224976   \n",
            "1      7548  frames/681/person_7548.jpg            0.206787   \n",
            "2      7552  frames/681/person_7552.jpg            0.191772   \n",
            "4      7576  frames/681/person_7576.jpg            0.134521   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.633789  0.508301  \n",
            "3              0.600586  0.487793  \n",
            "1              0.604004  0.484863  \n",
            "2              0.573730  0.459229  \n",
            "4              0.550781  0.425781  \n",
            "--------------------------------------------------Frame 682\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 3 traffic lights, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/682'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/682/person_7545.jpg            0.218262   \n",
            "3      7564  frames/682/person_7564.jpg            0.237061   \n",
            "1      7548  frames/682/person_7548.jpg            0.199829   \n",
            "2      7552  frames/682/person_7552.jpg            0.181396   \n",
            "4      7576  frames/682/person_7576.jpg            0.143433   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.626465  0.503906  \n",
            "3              0.609863  0.498047  \n",
            "1              0.597168  0.478027  \n",
            "2              0.573242  0.455811  \n",
            "4              0.554199  0.430908  \n",
            "--------------------------------------------------Frame 683\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 2 traffic lights, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/683'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/683/person_7564.jpg            0.221069   \n",
            "1      7548  frames/683/person_7548.jpg            0.221191   \n",
            "0      7545  frames/683/person_7545.jpg            0.185303   \n",
            "3      7576  frames/683/person_7576.jpg            0.132202   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.624023  0.502930  \n",
            "1              0.620117  0.500488  \n",
            "0              0.606445  0.480225  \n",
            "3              0.551270  0.425781  \n",
            "--------------------------------------------------Frame 684\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/684'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/684/person_7564.jpg            0.220459   \n",
            "1      7548  frames/684/person_7548.jpg            0.209961   \n",
            "0      7545  frames/684/person_7545.jpg            0.187134   \n",
            "4      7586  frames/684/person_7586.jpg            0.135010   \n",
            "3      7576  frames/684/person_7576.jpg            0.142334   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.625000  0.503906  \n",
            "1              0.604492  0.486084  \n",
            "0              0.604004  0.479004  \n",
            "4              0.561035  0.433350  \n",
            "3              0.557617  0.433105  \n",
            "--------------------------------------------------Frame 685\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/685'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/685/person_7564.jpg            0.225220   \n",
            "1      7548  frames/685/person_7548.jpg            0.197510   \n",
            "0      7545  frames/685/person_7545.jpg            0.195312   \n",
            "3      7576  frames/685/person_7576.jpg            0.140869   \n",
            "4      7586  frames/685/person_7586.jpg            0.133057   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.631348  0.509277  \n",
            "1              0.598145  0.478027  \n",
            "0              0.596680  0.476318  \n",
            "3              0.559082  0.433594  \n",
            "4              0.557617  0.430176  \n",
            "--------------------------------------------------Frame 686\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/686'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/686/person_7564.jpg            0.224243   \n",
            "1      7548  frames/686/person_7548.jpg            0.212280   \n",
            "0      7545  frames/686/person_7545.jpg            0.189819   \n",
            "3      7576  frames/686/person_7576.jpg            0.142700   \n",
            "4      7586  frames/686/person_7586.jpg            0.125610   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.622070  0.502930  \n",
            "1              0.610352  0.490967  \n",
            "0              0.599609  0.476562  \n",
            "3              0.559570  0.434326  \n",
            "4              0.547852  0.421143  \n",
            "--------------------------------------------------Frame 687\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 14.8ms\n",
            "Speed: 2.7ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/687'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/687/person_7564.jpg            0.220093   \n",
            "0      7545  frames/687/person_7545.jpg            0.193359   \n",
            "1      7548  frames/687/person_7548.jpg            0.212036   \n",
            "3      7576  frames/687/person_7576.jpg            0.141357   \n",
            "4      7586  frames/687/person_7586.jpg            0.129028   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.618652  0.499023  \n",
            "0              0.622070  0.493652  \n",
            "1              0.587891  0.475098  \n",
            "3              0.559570  0.434082  \n",
            "4              0.550781  0.424316  \n",
            "--------------------------------------------------Frame 688\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 9.4ms\n",
            "Speed: 2.2ms preprocess, 9.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/688'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/688/person_7564.jpg            0.212280   \n",
            "1      7548  frames/688/person_7548.jpg            0.217529   \n",
            "0      7545  frames/688/person_7545.jpg            0.184082   \n",
            "3      7576  frames/688/person_7576.jpg            0.136353   \n",
            "4      7586  frames/688/person_7586.jpg            0.134399   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.620605  0.498047  \n",
            "1              0.608887  0.491455  \n",
            "0              0.610352  0.482422  \n",
            "3              0.565918  0.437012  \n",
            "4              0.554688  0.428467  \n",
            "--------------------------------------------------Frame 689\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 14.1ms\n",
            "Speed: 2.2ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/689'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/689/person_7564.jpg            0.214844   \n",
            "1      7548  frames/689/person_7548.jpg            0.215942   \n",
            "0      7545  frames/689/person_7545.jpg            0.170410   \n",
            "4      7586  frames/689/person_7586.jpg            0.138550   \n",
            "3      7576  frames/689/person_7576.jpg            0.131958   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.614258  0.494385  \n",
            "1              0.599609  0.484375  \n",
            "0              0.599609  0.470703  \n",
            "4              0.560059  0.433594  \n",
            "3              0.550293  0.424805  \n",
            "--------------------------------------------------Frame 690\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 2 traffic lights, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/690'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/690/person_7564.jpg            0.220215   \n",
            "0      7545  frames/690/person_7545.jpg            0.178345   \n",
            "1      7548  frames/690/person_7548.jpg            0.201538   \n",
            "4      7586  frames/690/person_7586.jpg            0.139771   \n",
            "3      7576  frames/690/person_7576.jpg            0.135620   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.622070  0.501465  \n",
            "0              0.610840  0.480957  \n",
            "1              0.585938  0.470703  \n",
            "4              0.564941  0.437500  \n",
            "3              0.555664  0.429688  \n",
            "--------------------------------------------------Frame 691\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 truck, 1 traffic light, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/691'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/691/person_7564.jpg            0.226562   \n",
            "0      7545  frames/691/person_7545.jpg            0.198242   \n",
            "1      7548  frames/691/person_7548.jpg            0.200073   \n",
            "4      7586  frames/691/person_7586.jpg            0.138428   \n",
            "3      7576  frames/691/person_7576.jpg            0.146851   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.613281  0.497070  \n",
            "0              0.613770  0.489258  \n",
            "1              0.598145  0.478760  \n",
            "4              0.568848  0.439697  \n",
            "3              0.552246  0.430664  \n",
            "--------------------------------------------------Frame 692\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 1 traffic light, 9.2ms\n",
            "Speed: 3.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/692'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/692/person_7564.jpg            0.215088   \n",
            "0      7545  frames/692/person_7545.jpg            0.204712   \n",
            "5      7593  frames/692/person_7593.jpg            0.207642   \n",
            "1      7548  frames/692/person_7548.jpg            0.197754   \n",
            "4      7586  frames/692/person_7586.jpg            0.137085   \n",
            "3      7576  frames/692/person_7576.jpg            0.131836   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.616211  0.495850  \n",
            "0              0.615234  0.492188  \n",
            "5              0.591309  0.476074  \n",
            "1              0.587891  0.470947  \n",
            "4              0.570801  0.440918  \n",
            "3              0.535645  0.414551  \n",
            "--------------------------------------------------Frame 693\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 1 traffic light, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/693'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/693/person_7564.jpg            0.224121   \n",
            "0      7545  frames/693/person_7545.jpg            0.203125   \n",
            "1      7548  frames/693/person_7548.jpg            0.218018   \n",
            "3      7593  frames/693/person_7593.jpg            0.228149   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.613770  0.497070  \n",
            "0              0.614746  0.491455  \n",
            "1              0.603027  0.487549  \n",
            "3              0.596680  0.486084  \n",
            "--------------------------------------------------Frame 694\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 1 traffic light, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/694'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/694/person_7564.jpg            0.223022   \n",
            "0      7545  frames/694/person_7545.jpg            0.204834   \n",
            "3      7593  frames/694/person_7593.jpg            0.226929   \n",
            "1      7548  frames/694/person_7548.jpg            0.213989   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.613770  0.496582  \n",
            "0              0.614258  0.491455  \n",
            "3              0.595703  0.485107  \n",
            "1              0.590332  0.477539  \n",
            "--------------------------------------------------Frame 695\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 11.2ms\n",
            "Speed: 2.3ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/695'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/695/person_7545.jpg            0.220581   \n",
            "1      7548  frames/695/person_7548.jpg            0.216675   \n",
            "2      7564  frames/695/person_7564.jpg            0.206055   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.620605  0.500488  \n",
            "1              0.620117  0.499023  \n",
            "2              0.611816  0.489990  \n",
            "--------------------------------------------------Frame 696\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 4.2ms preprocess, 9.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/696'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/696/person_7564.jpg            0.222168   \n",
            "0      7545  frames/696/person_7545.jpg            0.224121   \n",
            "1      7548  frames/696/person_7548.jpg            0.231445   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.621094  0.501465  \n",
            "0              0.616699  0.499023  \n",
            "1              0.611328  0.497559  \n",
            "--------------------------------------------------Frame 697\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/697'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/697/person_7545.jpg            0.227539   \n",
            "2      7564  frames/697/person_7564.jpg            0.208618   \n",
            "1      7548  frames/697/person_7548.jpg            0.235474   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.618652  0.501465  \n",
            "2              0.621094  0.497314  \n",
            "1              0.599121  0.489990  \n",
            "--------------------------------------------------Frame 698\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/698'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/698/person_7545.jpg            0.223511   \n",
            "2      7564  frames/698/person_7564.jpg            0.206055   \n",
            "1      7548  frames/698/person_7548.jpg            0.234009   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.619629  0.500977  \n",
            "2              0.621094  0.496582  \n",
            "1              0.599609  0.489746  \n",
            "--------------------------------------------------Frame 699\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/699'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/699/person_7545.jpg            0.217773   \n",
            "2      7564  frames/699/person_7564.jpg            0.203491   \n",
            "1      7548  frames/699/person_7548.jpg            0.232178   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.626465  0.503906  \n",
            "2              0.618164  0.493652  \n",
            "1              0.604980  0.493164  \n",
            "--------------------------------------------------Frame 700\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 11.6ms\n",
            "Speed: 2.4ms preprocess, 11.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/700'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/700/person_7564.jpg            0.214722   \n",
            "0      7545  frames/700/person_7545.jpg            0.205811   \n",
            "1      7548  frames/700/person_7548.jpg            0.226685   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.636719  0.510254  \n",
            "0              0.613770  0.491455  \n",
            "1              0.589844  0.480957  \n",
            "--------------------------------------------------Frame 701\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 9.6ms\n",
            "Speed: 2.3ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/701'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/701/person_7564.jpg            0.222900   \n",
            "0      7545  frames/701/person_7545.jpg            0.193359   \n",
            "1      7548  frames/701/person_7548.jpg            0.230103   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.629883  0.507812  \n",
            "0              0.614746  0.488525  \n",
            "1              0.596191  0.486328  \n",
            "--------------------------------------------------Frame 702\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 1 traffic light, 13.8ms\n",
            "Speed: 3.0ms preprocess, 13.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/702'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7548  frames/702/person_7548.jpg            0.236206   \n",
            "2      7564  frames/702/person_7564.jpg            0.220337   \n",
            "0      7545  frames/702/person_7545.jpg            0.201416   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.614258  0.500977  \n",
            "2              0.621582  0.500977  \n",
            "0              0.619629  0.494141  \n",
            "--------------------------------------------------Frame 703\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 traffic light, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/703'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/703/person_7545.jpg            0.221680   \n",
            "2      7564  frames/703/person_7564.jpg            0.215332   \n",
            "1      7548  frames/703/person_7548.jpg            0.226440   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.629883  0.507324  \n",
            "2              0.619629  0.498535  \n",
            "1              0.598145  0.486572  \n",
            "--------------------------------------------------Frame 704\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 traffic light, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/704'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/704/person_7545.jpg            0.227051   \n",
            "2      7564  frames/704/person_7564.jpg            0.214600   \n",
            "1      7548  frames/704/person_7548.jpg            0.223755   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.636230  0.513672  \n",
            "2              0.614746  0.494873  \n",
            "1              0.596680  0.484863  \n",
            "--------------------------------------------------Frame 705\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 traffic light, 12.1ms\n",
            "Speed: 3.0ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/705'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/705/person_7545.jpg            0.219727   \n",
            "2      7564  frames/705/person_7564.jpg            0.207886   \n",
            "1      7548  frames/705/person_7548.jpg            0.206177   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.622559  0.501953  \n",
            "2              0.617188  0.494629  \n",
            "1              0.593750  0.477295  \n",
            "--------------------------------------------------Frame 706\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 traffic light, 16.1ms\n",
            "Speed: 2.3ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/706'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/706/person_7545.jpg            0.213135   \n",
            "2      7564  frames/706/person_7564.jpg            0.210693   \n",
            "1      7548  frames/706/person_7548.jpg            0.211914   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.618652  0.497070  \n",
            "2              0.611816  0.491455  \n",
            "1              0.580078  0.469727  \n",
            "--------------------------------------------------Frame 707\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 16.2ms\n",
            "Speed: 2.3ms preprocess, 16.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/707'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/707/person_7545.jpg            0.210693   \n",
            "1      7548  frames/707/person_7548.jpg            0.207031   \n",
            "2      7564  frames/707/person_7564.jpg            0.191162   \n",
            "4      7586  frames/707/person_7586.jpg            0.147461   \n",
            "3      7576  frames/707/person_7576.jpg            0.157593   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.625977  0.501465  \n",
            "1              0.598145  0.480713  \n",
            "2              0.588379  0.469238  \n",
            "4              0.559082  0.435547  \n",
            "3              0.552734  0.434326  \n",
            "--------------------------------------------------Frame 708\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 2 traffic lights, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/708'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/708/person_7545.jpg            0.215332   \n",
            "1      7548  frames/708/person_7548.jpg            0.231323   \n",
            "2      7564  frames/708/person_7564.jpg            0.204102   \n",
            "4      7586  frames/708/person_7586.jpg            0.153320   \n",
            "3      7576  frames/708/person_7576.jpg            0.157227   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.617676  0.497070  \n",
            "1              0.603027  0.491455  \n",
            "2              0.592773  0.476318  \n",
            "4              0.556641  0.435547  \n",
            "3              0.552246  0.433594  \n",
            "--------------------------------------------------Frame 709\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 2 traffic lights, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/709'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/709/person_7545.jpg            0.217896   \n",
            "1      7548  frames/709/person_7548.jpg            0.226196   \n",
            "2      7564  frames/709/person_7564.jpg            0.212280   \n",
            "4      7586  frames/709/person_7586.jpg            0.151855   \n",
            "3      7576  frames/709/person_7576.jpg            0.155273   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.620117  0.499512  \n",
            "1              0.594727  0.484131  \n",
            "2              0.595215  0.480469  \n",
            "4              0.554199  0.433594  \n",
            "3              0.550293  0.431885  \n",
            "--------------------------------------------------Frame 710\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 2 traffic lights, 16.8ms\n",
            "Speed: 6.6ms preprocess, 16.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/710'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/710/person_7545.jpg            0.198120   \n",
            "1      7548  frames/710/person_7548.jpg            0.212036   \n",
            "2      7564  frames/710/person_7564.jpg            0.197876   \n",
            "4      7586  frames/710/person_7586.jpg            0.148071   \n",
            "3      7576  frames/710/person_7576.jpg            0.141602   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.609863  0.486328  \n",
            "1              0.594727  0.479980  \n",
            "2              0.583984  0.468018  \n",
            "4              0.552246  0.430908  \n",
            "3              0.541016  0.421143  \n",
            "--------------------------------------------------Frame 711\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 2 traffic lights, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/711'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/711/person_7545.jpg            0.212769   \n",
            "1      7548  frames/711/person_7548.jpg            0.211548   \n",
            "2      7564  frames/711/person_7564.jpg            0.206909   \n",
            "4      7586  frames/711/person_7586.jpg            0.143799   \n",
            "3      7576  frames/711/person_7576.jpg            0.140503   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.617676  0.496094  \n",
            "1              0.595215  0.480225  \n",
            "2              0.590332  0.475342  \n",
            "4              0.550293  0.428467  \n",
            "3              0.540039  0.420166  \n",
            "--------------------------------------------------Frame 712\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/712'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/712/person_7545.jpg            0.219727   \n",
            "2      7564  frames/712/person_7564.jpg            0.228027   \n",
            "1      7548  frames/712/person_7548.jpg            0.207031   \n",
            "3      7576  frames/712/person_7576.jpg            0.152588   \n",
            "4      7586  frames/712/person_7586.jpg            0.148315   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.622559  0.501953  \n",
            "2              0.614746  0.498779  \n",
            "1              0.592773  0.477051  \n",
            "3              0.558594  0.437012  \n",
            "4              0.558105  0.435059  \n",
            "--------------------------------------------------Frame 713\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 4 traffic lights, 20.9ms\n",
            "Speed: 2.2ms preprocess, 20.9ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/713'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/713/person_7545.jpg            0.212402   \n",
            "2      7564  frames/713/person_7564.jpg            0.230591   \n",
            "1      7548  frames/713/person_7548.jpg            0.204956   \n",
            "3      7576  frames/713/person_7576.jpg            0.152588   \n",
            "4      7586  frames/713/person_7586.jpg            0.151001   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.623535  0.500000  \n",
            "2              0.615234  0.499756  \n",
            "1              0.584473  0.470703  \n",
            "3              0.566895  0.442383  \n",
            "4              0.557617  0.435547  \n",
            "--------------------------------------------------Frame 714\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 4 traffic lights, 13.5ms\n",
            "Speed: 2.2ms preprocess, 13.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/714'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/714/person_7564.jpg            0.231445   \n",
            "0      7545  frames/714/person_7545.jpg            0.213623   \n",
            "1      7548  frames/714/person_7548.jpg            0.204224   \n",
            "3      7576  frames/714/person_7576.jpg            0.152344   \n",
            "4      7586  frames/714/person_7586.jpg            0.152100   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.617676  0.501953  \n",
            "0              0.624023  0.500977  \n",
            "1              0.584473  0.470459  \n",
            "3              0.566895  0.442383  \n",
            "4              0.559082  0.437012  \n",
            "--------------------------------------------------Frame 715\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 4 traffic lights, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/715'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/715/person_7564.jpg            0.230469   \n",
            "0      7545  frames/715/person_7545.jpg            0.203491   \n",
            "1      7548  frames/715/person_7548.jpg            0.205811   \n",
            "3      7576  frames/715/person_7576.jpg            0.151855   \n",
            "4      7586  frames/715/person_7586.jpg            0.157959   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.617676  0.501465  \n",
            "0              0.610840  0.488525  \n",
            "1              0.605957  0.485840  \n",
            "3              0.564453  0.440674  \n",
            "4              0.548828  0.431641  \n",
            "--------------------------------------------------Frame 716\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 5 persons, 3 cars, 4 traffic lights, 15.4ms\n",
            "Speed: 3.0ms preprocess, 15.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/716'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/716/person_7564.jpg            0.238770   \n",
            "0      7545  frames/716/person_7545.jpg            0.194458   \n",
            "1      7548  frames/716/person_7548.jpg            0.194458   \n",
            "3      7576  frames/716/person_7576.jpg            0.156494   \n",
            "4      7586  frames/716/person_7586.jpg            0.147339   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.633301  0.515137  \n",
            "0              0.612305  0.487061  \n",
            "1              0.603027  0.480469  \n",
            "3              0.563965  0.441650  \n",
            "4              0.556152  0.433594  \n",
            "--------------------------------------------------Frame 717\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 3 traffic lights, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/717'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/717/person_7564.jpg            0.243896   \n",
            "0      7545  frames/717/person_7545.jpg            0.195190   \n",
            "1      7548  frames/717/person_7548.jpg            0.205200   \n",
            "3      7576  frames/717/person_7576.jpg            0.157104   \n",
            "4      7586  frames/717/person_7586.jpg            0.150391   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.625977  0.511230  \n",
            "0              0.607422  0.483887  \n",
            "1              0.587402  0.472656  \n",
            "3              0.563965  0.441895  \n",
            "4              0.548340  0.428955  \n",
            "--------------------------------------------------Frame 718\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 3 traffic lights, 20.9ms\n",
            "Speed: 2.3ms preprocess, 20.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/718'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/718/person_7564.jpg            0.254883   \n",
            "0      7545  frames/718/person_7545.jpg            0.208496   \n",
            "1      7548  frames/718/person_7548.jpg            0.205078   \n",
            "3      7576  frames/718/person_7576.jpg            0.157959   \n",
            "4      7586  frames/718/person_7586.jpg            0.149414   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.639160  0.523926  \n",
            "0              0.616211  0.493896  \n",
            "1              0.586426  0.471924  \n",
            "3              0.564453  0.442383  \n",
            "4              0.556152  0.434326  \n",
            "--------------------------------------------------Frame 719\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 3 traffic lights, 18.4ms\n",
            "Speed: 2.3ms preprocess, 18.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/719'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7564  frames/719/person_7564.jpg            0.260010   \n",
            "0      7545  frames/719/person_7545.jpg            0.200928   \n",
            "1      7548  frames/719/person_7548.jpg            0.200195   \n",
            "3      7586  frames/719/person_7586.jpg            0.147949   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.652344  0.534668  \n",
            "0              0.620605  0.494629  \n",
            "1              0.583008  0.468262  \n",
            "3              0.540527  0.422852  \n",
            "Best matching track_id is 7564\n",
            "Best matching image path is frames/719/person_7564.jpg\n",
            "Best matching cosine similarity is 0.53466796875\n",
            "--------------------------------------------------Frame 720\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 3 traffic lights, 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 721\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 3 traffic lights, 22.6ms\n",
            "Speed: 2.2ms preprocess, 22.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 722\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 3 traffic lights, 16.8ms\n",
            "Speed: 2.2ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 723\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 3 traffic lights, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 724\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 2 traffic lights, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 725\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 truck, 2 traffic lights, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 726\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 truck, 2 traffic lights, 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 727\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 truck, 2 traffic lights, 16.5ms\n",
            "Speed: 2.3ms preprocess, 16.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 728\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 truck, 2 traffic lights, 25.1ms\n",
            "Speed: 2.2ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 729\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 2 traffic lights, 20.0ms\n",
            "Speed: 2.3ms preprocess, 20.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 730\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 2 traffic lights, 16.8ms\n",
            "Speed: 2.1ms preprocess, 16.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 731\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 2 traffic lights, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 732\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 20.7ms\n",
            "Speed: 2.1ms preprocess, 20.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 733\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 10.1ms\n",
            "Speed: 2.0ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 734\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 10.0ms\n",
            "Speed: 2.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 735\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 9.9ms\n",
            "Speed: 2.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 736\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 10.9ms\n",
            "Speed: 2.1ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 737\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 10.7ms\n",
            "Speed: 2.2ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 738\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 13.6ms\n",
            "Speed: 3.0ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 739\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 740\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 traffic light, 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 741\n",
            "\n",
            "0: 384x640 3 persons, 1 bicycle, 2 cars, 1 truck, 1 traffic light, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 742\n",
            "\n",
            "0: 384x640 4 persons, 1 bicycle, 2 cars, 1 truck, 1 traffic light, 10.1ms\n",
            "Speed: 2.3ms preprocess, 10.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 743\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 traffic light, 10.3ms\n",
            "Speed: 2.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 744\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 745\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 traffic light, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 746\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 traffic light, 11.3ms\n",
            "Speed: 2.0ms preprocess, 11.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 747\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 748\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 traffic light, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 749\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 traffic light, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 750\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 751\n",
            "\n",
            "0: 384x640 1 person, 4 cars, 1 traffic light, 11.1ms\n",
            "Speed: 2.0ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/751'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/751/person_7545.jpg            0.193237   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.630371  tensor(0.4990, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 752\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 traffic light, 16.7ms\n",
            "Speed: 1.9ms preprocess, 16.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/752'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/752/person_7545.jpg            0.203613   \n",
            "1      7564  frames/752/person_7564.jpg            0.206177   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0               0.63623  0.506348  \n",
            "1               0.59668  0.479492  \n",
            "--------------------------------------------------Frame 753\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/753'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7564  frames/753/person_7564.jpg            0.220703   \n",
            "0      7545  frames/753/person_7545.jpg            0.202148   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.631836  0.508789  \n",
            "0              0.630371  0.501953  \n",
            "--------------------------------------------------Frame 754\n",
            "\n",
            "0: 384x640 2 persons, 4 cars, 1 traffic light, 12.4ms\n",
            "Speed: 3.5ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/754'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7564  frames/754/person_7564.jpg            0.227295   \n",
            "0      7545  frames/754/person_7545.jpg            0.192993   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1               0.63623  0.513672  \n",
            "0               0.62793  0.497314  \n",
            "--------------------------------------------------Frame 755\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 9.9ms\n",
            "Speed: 2.3ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/755'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/755/person_7545.jpg            0.188721   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.603027  tensor(0.4788, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 756\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/756'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/756/person_7545.jpg            0.205444   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0               0.63916  tensor(0.5093, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 757\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/757'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/757/person_7545.jpg            0.200195   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.625488  tensor(0.4978, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 758\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 9.1ms\n",
            "Speed: 2.5ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/758'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/758/person_7545.jpg             0.20813   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.631348  tensor(0.5044, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 759\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 10.0ms\n",
            "Speed: 5.2ms preprocess, 10.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/759'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/759/person_7545.jpg            0.214966   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0               0.61377  tensor(0.4941, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 760\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/760'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/760/person_7545.jpg            0.202026   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.609375  tensor(0.4871, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 761\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.1ms preprocess, 11.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/761'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/761/person_7545.jpg            0.196045   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.593262  tensor(0.4741, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 762\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/762'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/762/person_7545.jpg            0.178101   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.583496  tensor(0.4619, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 763\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/763'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/763/person_7545.jpg            0.179565   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0               0.57959  tensor(0.4597, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 764\n",
            "\n",
            "0: 384x640 1 person, 3 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.3ms preprocess, 13.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/764'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/764/person_7545.jpg            0.193848   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.585449  tensor(0.4680, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 765\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 traffic light, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/765'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/765/person_7545.jpg            0.185669   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.596191  tensor(0.4729, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 766\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 traffic light, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/766'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/766/person_7545.jpg            0.181396   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.599121  tensor(0.4739, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 767\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 traffic light, 12.7ms\n",
            "Speed: 2.2ms preprocess, 12.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/767'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/767/person_7545.jpg            0.176147   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.602051  tensor(0.4741, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 768\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 traffic light, 10.5ms\n",
            "Speed: 2.0ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/768'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/768/person_7545.jpg            0.175537   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.598145  tensor(0.4714, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 769\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 traffic light, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/769'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/769/person_7545.jpg            0.190063   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.590332  tensor(0.4702, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 770\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 1 traffic light, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/770'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/770/person_7545.jpg            0.186157   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.596191  tensor(0.4731, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 771\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 1 traffic light, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/771'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/771/person_7545.jpg            0.162964   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.586426  tensor(0.4592, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 772\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 1 traffic light, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/772'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/772/person_7545.jpg            0.181885   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.598633  tensor(0.4736, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 773\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/773'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/773/person_7545.jpg            0.197144   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.596191  tensor(0.4763, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 774\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 truck, 1 traffic light, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/774'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/774/person_7545.jpg            0.197876   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.597168  tensor(0.4773, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 775\n",
            "\n",
            "0: 384x640 1 person, 1 traffic light, 10.5ms\n",
            "Speed: 2.1ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/775'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/775/person_7545.jpg            0.190918   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0               0.57959  tensor(0.4631, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 776\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 1 traffic light, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/776'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7545  frames/776/person_7545.jpg            0.198486   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.594238  tensor(0.4756, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 777\n",
            "\n",
            "0: 384x640 1 truck, 1 traffic light, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 778\n",
            "\n",
            "0: 384x640 1 truck, 1 traffic light, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 779\n",
            "\n",
            "0: 384x640 1 truck, 1 traffic light, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 780\n",
            "\n",
            "0: 384x640 1 truck, 1 traffic light, 10.7ms\n",
            "Speed: 2.1ms preprocess, 10.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 781\n",
            "\n",
            "0: 384x640 1 truck, 1 traffic light, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 782\n",
            "\n",
            "0: 384x640 1 truck, 1 traffic light, 11.1ms\n",
            "Speed: 2.1ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 783\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 1 traffic light, 16.2ms\n",
            "Speed: 5.2ms preprocess, 16.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/783'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7687  frames/783/person_7687.jpg            0.173584   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.583984  tensor(0.4607, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 784\n",
            "\n",
            "0: 384x640 1 person, 1 truck, 1 traffic light, 10.4ms\n",
            "Speed: 2.2ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/784'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7687  frames/784/person_7687.jpg             0.14856   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.570801  tensor(0.4443, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 785\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 1 traffic light, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/785'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/785/person_7688.jpg            0.167480   \n",
            "0      7687  frames/785/person_7687.jpg            0.152466   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.612793  0.479248  \n",
            "0              0.576172  0.448975  \n",
            "--------------------------------------------------Frame 786\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 1 traffic light, 14.1ms\n",
            "Speed: 2.2ms preprocess, 14.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/786'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/786/person_7688.jpg            0.166992   \n",
            "0      7687  frames/786/person_7687.jpg            0.161255   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.613770  0.479736  \n",
            "0              0.593262  0.463623  \n",
            "--------------------------------------------------Frame 787\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 1 traffic light, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/787'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/787/person_7688.jpg            0.181641   \n",
            "0      7687  frames/787/person_7687.jpg            0.136841   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.594238  0.470459  \n",
            "0              0.571289  0.440918  \n",
            "--------------------------------------------------Frame 788\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 1 traffic light, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/788'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/788/person_7688.jpg            0.178223   \n",
            "0      7687  frames/788/person_7687.jpg            0.133545   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.603027  0.475586  \n",
            "0              0.556641  0.429688  \n",
            "--------------------------------------------------Frame 789\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 traffic light, 10.9ms\n",
            "Speed: 2.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/789'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/789/person_7688.jpg            0.179688   \n",
            "0      7687  frames/789/person_7687.jpg            0.161499   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.604004  0.476807  \n",
            "0              0.566895  0.445312  \n",
            "--------------------------------------------------Frame 790\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 traffic light, 10.2ms\n",
            "Speed: 2.5ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/790'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/790/person_7688.jpg            0.179688   \n",
            "2      7692  frames/790/person_7692.jpg            0.153076   \n",
            "0      7687  frames/790/person_7687.jpg            0.159546   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.595703  0.470947  \n",
            "2              0.584961  0.455322  \n",
            "0              0.578125  0.452637  \n",
            "--------------------------------------------------Frame 791\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 traffic light, 8.9ms\n",
            "Speed: 4.6ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/791'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/791/person_7688.jpg            0.174805   \n",
            "2      7692  frames/791/person_7692.jpg            0.158936   \n",
            "0      7687  frames/791/person_7687.jpg            0.155640   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.608398  0.478271  \n",
            "2              0.581543  0.454590  \n",
            "0              0.572754  0.447510  \n",
            "--------------------------------------------------Frame 792\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 traffic light, 10.9ms\n",
            "Speed: 2.3ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/792'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/792/person_7688.jpg            0.175171   \n",
            "0      7687  frames/792/person_7687.jpg            0.157471   \n",
            "2      7692  frames/792/person_7692.jpg            0.154175   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.603516  0.474854  \n",
            "0              0.572754  0.448242  \n",
            "2              0.572754  0.447266  \n",
            "--------------------------------------------------Frame 793\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 1 traffic light, 9.9ms\n",
            "Speed: 2.2ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/793'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/793/person_7688.jpg            0.174072   \n",
            "2      7692  frames/793/person_7692.jpg            0.157349   \n",
            "0      7687  frames/793/person_7687.jpg            0.160522   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.596680  0.469971  \n",
            "2              0.589355  0.459717  \n",
            "0              0.581055  0.454834  \n",
            "--------------------------------------------------Frame 794\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 traffic light, 11.5ms\n",
            "Speed: 2.3ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/794'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7688  frames/794/person_7688.jpg            0.184570   \n",
            "0      7687  frames/794/person_7687.jpg            0.166870   \n",
            "2      7692  frames/794/person_7692.jpg            0.169678   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.607422  0.480713  \n",
            "0              0.583984  0.458740  \n",
            "2              0.569824  0.449707  \n",
            "--------------------------------------------------Frame 795\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 traffic light, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/795'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7699  frames/795/person_7699.jpg            0.318604   \n",
            "1      7688  frames/795/person_7688.jpg            0.178101   \n",
            "2      7692  frames/795/person_7692.jpg            0.173706   \n",
            "0      7687  frames/795/person_7687.jpg            0.160889   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.683594  0.574219  \n",
            "1              0.595215  0.470215  \n",
            "2              0.576172  0.455566  \n",
            "0              0.565430  0.444092  \n",
            "Best matching track_id is 7699\n",
            "Best matching image path is frames/795/person_7699.jpg\n",
            "Best matching cosine similarity is 0.57421875\n",
            "--------------------------------------------------Frame 796\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 797\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 798\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 799\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 10.4ms\n",
            "Speed: 2.0ms preprocess, 10.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 800\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 13.2ms\n",
            "Speed: 2.2ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 801\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 11.0ms\n",
            "Speed: 2.1ms preprocess, 11.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 802\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 10.2ms\n",
            "Speed: 2.6ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 803\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 804\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.2ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 805\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 806\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 9.5ms\n",
            "Speed: 4.0ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 807\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 808\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 10.9ms\n",
            "Speed: 2.2ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 809\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 14.9ms\n",
            "Speed: 2.1ms preprocess, 14.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 810\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 20.4ms\n",
            "Speed: 2.3ms preprocess, 20.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 811\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.0ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 812\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 13.0ms\n",
            "Speed: 9.1ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 813\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 traffic light, 10.7ms\n",
            "Speed: 2.0ms preprocess, 10.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 814\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 traffic light, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 815\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 traffic light, 10.5ms\n",
            "Speed: 2.3ms preprocess, 10.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 816\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 11.1ms\n",
            "Speed: 2.3ms preprocess, 11.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 817\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 818\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 819\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 820\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 16.3ms\n",
            "Speed: 2.2ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 821\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.2ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 822\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 823\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 10.8ms\n",
            "Speed: 3.7ms preprocess, 10.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 824\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 11.9ms\n",
            "Speed: 2.3ms preprocess, 11.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 825\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 826\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 2 traffic lights, 12.0ms\n",
            "Speed: 3.1ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 827\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 828\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 829\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 830\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.3ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 831\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 832\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 833\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 11.0ms\n",
            "Speed: 2.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 834\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 1 traffic light, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 835\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 2 traffic lights, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 836\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 2 traffic lights, 11.7ms\n",
            "Speed: 5.2ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 837\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 2 traffic lights, 17.2ms\n",
            "Speed: 3.5ms preprocess, 17.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 838\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 3 traffic lights, 11.2ms\n",
            "Speed: 3.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 839\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 3 traffic lights, 17.0ms\n",
            "Speed: 2.4ms preprocess, 17.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 840\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 16.9ms\n",
            "Speed: 3.2ms preprocess, 16.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 841\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 15.6ms\n",
            "Speed: 2.5ms preprocess, 15.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 842\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 15.7ms\n",
            "Speed: 2.3ms preprocess, 15.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 843\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 844\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 4 traffic lights, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 845\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 4 traffic lights, 17.2ms\n",
            "Speed: 2.1ms preprocess, 17.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 846\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 4 traffic lights, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 847\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 4 traffic lights, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/847'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/847/person_7706.jpg            0.225342   \n",
            "0      7692  frames/847/person_7692.jpg            0.195679   \n",
            "2      7688  frames/847/person_7688.jpg            0.189209   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.613770  0.497314  \n",
            "0              0.601562  0.479980  \n",
            "2              0.588379  0.468750  \n",
            "--------------------------------------------------Frame 848\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 4 traffic lights, 17.1ms\n",
            "Speed: 6.4ms preprocess, 17.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/848'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/848/person_7706.jpg            0.229614   \n",
            "0      7692  frames/848/person_7692.jpg            0.199341   \n",
            "2      7688  frames/848/person_7688.jpg            0.189209   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.605469  0.492676  \n",
            "0              0.610352  0.487061  \n",
            "2              0.587891  0.468262  \n",
            "--------------------------------------------------Frame 849\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 4 traffic lights, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/849'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/849/person_7706.jpg            0.223755   \n",
            "0      7692  frames/849/person_7692.jpg            0.200562   \n",
            "2      7688  frames/849/person_7688.jpg            0.192871   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.606445  0.491699  \n",
            "0              0.603027  0.482422  \n",
            "2              0.599121  0.477295  \n",
            "--------------------------------------------------Frame 850\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 4 traffic lights, 22.3ms\n",
            "Speed: 2.3ms preprocess, 22.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/850'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/850/person_7706.jpg            0.231079   \n",
            "0      7692  frames/850/person_7692.jpg            0.204712   \n",
            "2      7688  frames/850/person_7688.jpg            0.195923   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.602539  0.491211  \n",
            "0              0.601074  0.481934  \n",
            "2              0.601074  0.479492  \n",
            "--------------------------------------------------Frame 851\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 12.7ms\n",
            "Speed: 3.6ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/851'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/851/person_7706.jpg            0.211304   \n",
            "0      7692  frames/851/person_7692.jpg            0.214355   \n",
            "2      7688  frames/851/person_7688.jpg            0.187012   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.607910  0.489014  \n",
            "0              0.591797  0.478516  \n",
            "2              0.588867  0.468262  \n",
            "--------------------------------------------------Frame 852\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 16.9ms\n",
            "Speed: 2.3ms preprocess, 16.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/852'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/852/person_7706.jpg            0.215576   \n",
            "0      7692  frames/852/person_7692.jpg            0.204590   \n",
            "2      7688  frames/852/person_7688.jpg            0.185181   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.617676  0.497070  \n",
            "0              0.595703  0.478271  \n",
            "2              0.592773  0.470703  \n",
            "--------------------------------------------------Frame 853\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 17.1ms\n",
            "Speed: 2.2ms preprocess, 17.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/853'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/853/person_7706.jpg            0.216431   \n",
            "0      7692  frames/853/person_7692.jpg            0.208374   \n",
            "2      7688  frames/853/person_7688.jpg            0.188354   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.616699  0.496582  \n",
            "0              0.594727  0.478760  \n",
            "2              0.594238  0.472656  \n",
            "--------------------------------------------------Frame 854\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 12.8ms\n",
            "Speed: 2.9ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/854'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/854/person_7706.jpg            0.227661   \n",
            "0      7692  frames/854/person_7692.jpg            0.207397   \n",
            "2      7688  frames/854/person_7688.jpg            0.190186   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.624023  0.504883  \n",
            "0              0.598633  0.481201  \n",
            "2              0.590820  0.470703  \n",
            "--------------------------------------------------Frame 855\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/855'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/855/person_7706.jpg            0.226807   \n",
            "0      7692  frames/855/person_7692.jpg            0.208862   \n",
            "2      7688  frames/855/person_7688.jpg            0.194580   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.623535  0.504395  \n",
            "0              0.600098  0.482910  \n",
            "2              0.591309  0.472168  \n",
            "--------------------------------------------------Frame 856\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/856'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7692  frames/856/person_7692.jpg            0.212158   \n",
            "1      7706  frames/856/person_7706.jpg            0.200928   \n",
            "2      7688  frames/856/person_7688.jpg            0.186279   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.591797  0.478027  \n",
            "1              0.594727  0.476562  \n",
            "2              0.585938  0.466064  \n",
            "--------------------------------------------------Frame 857\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 15.3ms\n",
            "Speed: 2.3ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/857'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/857/person_7706.jpg            0.200317   \n",
            "0      7692  frames/857/person_7692.jpg            0.211426   \n",
            "2      7688  frames/857/person_7688.jpg            0.187134   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.625977  0.498291  \n",
            "0              0.591309  0.477295  \n",
            "2              0.580078  0.462158  \n",
            "--------------------------------------------------Frame 858\n",
            "\n",
            "0: 384x640 3 persons, 4 cars, 3 traffic lights, 14.8ms\n",
            "Speed: 5.4ms preprocess, 14.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/858'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/858/person_7706.jpg            0.206299   \n",
            "0      7692  frames/858/person_7692.jpg            0.211548   \n",
            "2      7688  frames/858/person_7688.jpg            0.185303   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.628418  0.501953  \n",
            "0              0.592773  0.478516  \n",
            "2              0.583496  0.464111  \n",
            "--------------------------------------------------Frame 859\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 4 cars, 2 traffic lights, 18.9ms\n",
            "Speed: 2.7ms preprocess, 18.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/859'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/859/person_7706.jpg            0.215576   \n",
            "0      7692  frames/859/person_7692.jpg            0.204224   \n",
            "2      7688  frames/859/person_7688.jpg            0.196045   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.594727  0.480957  \n",
            "0              0.586914  0.472168  \n",
            "2              0.586914  0.469727  \n",
            "--------------------------------------------------Frame 860\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 3 traffic lights, 22.5ms\n",
            "Speed: 4.9ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/860'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/860/person_7706.jpg            0.209229   \n",
            "0      7692  frames/860/person_7692.jpg            0.203735   \n",
            "2      7688  frames/860/person_7688.jpg            0.195435   \n",
            "3      7755  frames/860/person_7755.jpg            0.127930   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.598633  0.481689  \n",
            "0              0.587402  0.472168  \n",
            "2              0.590332  0.471924  \n",
            "3              0.540527  0.416748  \n",
            "--------------------------------------------------Frame 861\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 3 traffic lights, 19.3ms\n",
            "Speed: 2.3ms preprocess, 19.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/861'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/861/person_7706.jpg            0.209717   \n",
            "0      7692  frames/861/person_7692.jpg            0.188354   \n",
            "2      7688  frames/861/person_7688.jpg            0.203003   \n",
            "3      7755  frames/861/person_7755.jpg            0.136841   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.604004  0.485840  \n",
            "0              0.603516  0.479004  \n",
            "2              0.578613  0.465820  \n",
            "3              0.548828  0.425293  \n",
            "--------------------------------------------------Frame 862\n",
            "\n",
            "0: 384x640 4 persons, 6 cars, 3 traffic lights, 15.1ms\n",
            "Speed: 3.9ms preprocess, 15.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/862'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/862/person_7706.jpg            0.188232   \n",
            "0      7692  frames/862/person_7692.jpg            0.193848   \n",
            "2      7688  frames/862/person_7688.jpg            0.200806   \n",
            "3      7755  frames/862/person_7755.jpg            0.133423   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610840  0.483887  \n",
            "0              0.594727  0.474365  \n",
            "2              0.580078  0.466309  \n",
            "3              0.548340  0.423828  \n",
            "--------------------------------------------------Frame 863\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 2 traffic lights, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/863'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/863/person_7706.jpg            0.208862   \n",
            "0      7692  frames/863/person_7692.jpg            0.180054   \n",
            "2      7688  frames/863/person_7688.jpg            0.192993   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.626953  0.501465  \n",
            "0              0.598145  0.472656  \n",
            "2              0.576172  0.461182  \n",
            "--------------------------------------------------Frame 864\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 2 traffic lights, 15.0ms\n",
            "Speed: 2.3ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/864'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/864/person_7706.jpg            0.198608   \n",
            "0      7692  frames/864/person_7692.jpg            0.190186   \n",
            "2      7688  frames/864/person_7688.jpg            0.195557   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.624512  0.496826  \n",
            "0              0.596191  0.474365  \n",
            "2              0.579590  0.464355  \n",
            "--------------------------------------------------Frame 865\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 2 traffic lights, 14.7ms\n",
            "Speed: 2.3ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/865'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/865/person_7706.jpg            0.207031   \n",
            "0      7692  frames/865/person_7692.jpg            0.184448   \n",
            "2      7688  frames/865/person_7688.jpg            0.194458   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.626953  0.500977  \n",
            "0              0.601562  0.476562  \n",
            "2              0.579102  0.463623  \n",
            "--------------------------------------------------Frame 866\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 2 traffic lights, 23.0ms\n",
            "Speed: 2.2ms preprocess, 23.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/866'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/866/person_7706.jpg            0.210693   \n",
            "0      7692  frames/866/person_7692.jpg            0.185425   \n",
            "2      7688  frames/866/person_7688.jpg            0.197266   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.624512  0.500488  \n",
            "0              0.601074  0.476318  \n",
            "2              0.577148  0.463135  \n",
            "--------------------------------------------------Frame 867\n",
            "\n",
            "0: 384x640 3 persons, 6 cars, 2 traffic lights, 13.5ms\n",
            "Speed: 3.4ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/867'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/867/person_7706.jpg            0.207764   \n",
            "0      7692  frames/867/person_7692.jpg            0.189697   \n",
            "2      7688  frames/867/person_7688.jpg            0.196655   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.630859  0.503906  \n",
            "0              0.596680  0.474609  \n",
            "2              0.584961  0.468506  \n",
            "--------------------------------------------------Frame 868\n",
            "\n",
            "0: 384x640 3 persons, 5 cars, 2 traffic lights, 18.0ms\n",
            "Speed: 2.4ms preprocess, 18.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/868'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/868/person_7706.jpg            0.218872   \n",
            "0      7692  frames/868/person_7692.jpg            0.180664   \n",
            "2      7688  frames/868/person_7688.jpg            0.184448   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.622070  0.500977  \n",
            "0              0.586426  0.464600  \n",
            "2              0.576660  0.458984  \n",
            "--------------------------------------------------Frame 869\n",
            "\n",
            "0: 384x640 3 persons, 5 cars, 2 traffic lights, 21.7ms\n",
            "Speed: 3.0ms preprocess, 21.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/869'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/869/person_7706.jpg            0.204468   \n",
            "0      7692  frames/869/person_7692.jpg            0.187988   \n",
            "2      7688  frames/869/person_7688.jpg            0.181396   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.623047  0.497314  \n",
            "0              0.595703  0.473389  \n",
            "2              0.578125  0.459229  \n",
            "--------------------------------------------------Frame 870\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 2 traffic lights, 15.2ms\n",
            "Speed: 2.2ms preprocess, 15.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/870'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/870/person_7706.jpg            0.212769   \n",
            "0      7692  frames/870/person_7692.jpg            0.178955   \n",
            "2      7688  frames/870/person_7688.jpg            0.177368   \n",
            "3      7755  frames/870/person_7755.jpg            0.118225   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.618652  0.497070  \n",
            "0              0.578613  0.458740  \n",
            "2              0.576172  0.456543  \n",
            "3              0.506836  0.390137  \n",
            "--------------------------------------------------Frame 871\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 2 traffic lights, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/871'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/871/person_7706.jpg            0.223755   \n",
            "2      7688  frames/871/person_7688.jpg            0.191650   \n",
            "0      7692  frames/871/person_7692.jpg            0.177002   \n",
            "3      7755  frames/871/person_7755.jpg            0.139404   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.593750  0.482666  \n",
            "2              0.576172  0.460938  \n",
            "0              0.567383  0.450195  \n",
            "3              0.547363  0.424805  \n",
            "--------------------------------------------------Frame 872\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 2 traffic lights, 14.1ms\n",
            "Speed: 2.2ms preprocess, 14.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/872'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/872/person_7706.jpg            0.212646   \n",
            "0      7692  frames/872/person_7692.jpg            0.185791   \n",
            "2      7688  frames/872/person_7688.jpg            0.189331   \n",
            "3      7755  frames/872/person_7755.jpg            0.127808   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.581543  0.470703  \n",
            "0              0.573242  0.457031  \n",
            "2              0.567383  0.454102  \n",
            "3              0.525391  0.406006  \n",
            "--------------------------------------------------Frame 873\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 2 traffic lights, 21.6ms\n",
            "Speed: 2.2ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/873'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/873/person_7706.jpg            0.206665   \n",
            "2      7688  frames/873/person_7688.jpg            0.181885   \n",
            "0      7692  frames/873/person_7692.jpg            0.182983   \n",
            "3      7755  frames/873/person_7755.jpg            0.144775   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.588379  0.473877  \n",
            "2              0.581055  0.461426  \n",
            "0              0.570312  0.454102  \n",
            "3              0.552734  0.430420  \n",
            "--------------------------------------------------Frame 874\n",
            "\n",
            "0: 384x640 4 persons, 5 cars, 2 traffic lights, 13.8ms\n",
            "Speed: 6.0ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/874'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/874/person_7706.jpg            0.209473   \n",
            "2      7688  frames/874/person_7688.jpg            0.183838   \n",
            "0      7692  frames/874/person_7692.jpg            0.183350   \n",
            "3      7755  frames/874/person_7755.jpg            0.140381   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.595703  0.479980  \n",
            "2              0.578613  0.460205  \n",
            "0              0.569824  0.453857  \n",
            "3              0.520996  0.406738  \n",
            "--------------------------------------------------Frame 875\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 4 persons, 4 cars, 2 traffic lights, 19.8ms\n",
            "Speed: 2.3ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/875'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/875/person_7706.jpg            0.203491   \n",
            "2      7688  frames/875/person_7688.jpg            0.192261   \n",
            "0      7692  frames/875/person_7692.jpg            0.180054   \n",
            "3      7755  frames/875/person_7755.jpg            0.143188   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.586914  0.471924  \n",
            "2              0.582031  0.465088  \n",
            "0              0.573730  0.455566  \n",
            "3              0.563477  0.437500  \n",
            "--------------------------------------------------Frame 876\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 2 traffic lights, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/876'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/876/person_7706.jpg            0.213501   \n",
            "2      7688  frames/876/person_7688.jpg            0.203003   \n",
            "0      7692  frames/876/person_7692.jpg            0.180420   \n",
            "3      7755  frames/876/person_7755.jpg            0.149902   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.598145  0.482666  \n",
            "2              0.591309  0.474609  \n",
            "0              0.565430  0.449951  \n",
            "3              0.574219  0.446777  \n",
            "--------------------------------------------------Frame 877\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 2 traffic lights, 27.8ms\n",
            "Speed: 2.3ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/877'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/877/person_7706.jpg            0.213989   \n",
            "2      7688  frames/877/person_7688.jpg            0.195801   \n",
            "0      7692  frames/877/person_7692.jpg            0.175415   \n",
            "3      7755  frames/877/person_7755.jpg            0.156738   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.595215  0.480957  \n",
            "2              0.585938  0.468994  \n",
            "0              0.566895  0.449219  \n",
            "3              0.571777  0.447266  \n",
            "--------------------------------------------------Frame 878\n",
            "\n",
            "0: 384x640 3 persons, 5 cars, 2 traffic lights, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/878'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/878/person_7706.jpg            0.220337   \n",
            "2      7688  frames/878/person_7688.jpg            0.205200   \n",
            "0      7692  frames/878/person_7692.jpg            0.185913   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.588379  0.478027  \n",
            "2              0.587891  0.473145  \n",
            "0              0.579102  0.460938  \n",
            "--------------------------------------------------Frame 879\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 2 traffic lights, 18.9ms\n",
            "Speed: 4.1ms preprocess, 18.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/879'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7767  frames/879/person_7767.jpg            0.226807   \n",
            "1      7706  frames/879/person_7706.jpg            0.221436   \n",
            "2      7688  frames/879/person_7688.jpg            0.205688   \n",
            "0      7692  frames/879/person_7692.jpg            0.187988   \n",
            "4      7768  frames/879/person_7768.jpg            0.161255   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.607910  0.493652  \n",
            "1              0.594727  0.482666  \n",
            "2              0.600098  0.481934  \n",
            "0              0.588867  0.468506  \n",
            "4              0.559570  0.439941  \n",
            "--------------------------------------------------Frame 880\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 1 traffic light, 16.0ms\n",
            "Speed: 2.1ms preprocess, 16.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/880'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/880/person_7706.jpg            0.211670   \n",
            "2      7688  frames/880/person_7688.jpg            0.205200   \n",
            "0      7692  frames/880/person_7692.jpg            0.183228   \n",
            "3      7767  frames/880/person_7767.jpg            0.206909   \n",
            "4      7768  frames/880/person_7768.jpg            0.167114   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.611816  0.491699  \n",
            "2              0.593262  0.476807  \n",
            "0              0.595215  0.471680  \n",
            "3              0.581543  0.468994  \n",
            "4              0.562988  0.444092  \n",
            "--------------------------------------------------Frame 881\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 5 persons, 5 cars, 2 traffic lights, 13.6ms\n",
            "Speed: 2.5ms preprocess, 13.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/881'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/881/person_7706.jpg            0.216675   \n",
            "3      7767  frames/881/person_7767.jpg            0.204834   \n",
            "0      7692  frames/881/person_7692.jpg            0.184082   \n",
            "2      7688  frames/881/person_7688.jpg            0.201416   \n",
            "4      7768  frames/881/person_7768.jpg            0.171997   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610352  0.492188  \n",
            "3              0.585449  0.471436  \n",
            "0              0.592773  0.470215  \n",
            "2              0.575684  0.463379  \n",
            "4              0.568359  0.449463  \n",
            "--------------------------------------------------Frame 882\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 2 traffic lights, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/882'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/882/person_7706.jpg            0.212646   \n",
            "0      7692  frames/882/person_7692.jpg            0.184326   \n",
            "2      7688  frames/882/person_7688.jpg            0.201294   \n",
            "3      7767  frames/882/person_7767.jpg            0.197266   \n",
            "4      7768  frames/882/person_7768.jpg            0.168335   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.606445  0.488281  \n",
            "0              0.593750  0.470703  \n",
            "2              0.578613  0.465332  \n",
            "3              0.580078  0.465088  \n",
            "4              0.558594  0.441650  \n",
            "--------------------------------------------------Frame 883\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 16.0ms\n",
            "Speed: 2.3ms preprocess, 16.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/883'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/883/person_7706.jpg            0.208862   \n",
            "0      7692  frames/883/person_7692.jpg            0.181641   \n",
            "2      7688  frames/883/person_7688.jpg            0.197144   \n",
            "3      7767  frames/883/person_7767.jpg            0.175049   \n",
            "4      7768  frames/883/person_7768.jpg            0.163330   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.607422  0.488037  \n",
            "0              0.590332  0.467773  \n",
            "2              0.581055  0.465820  \n",
            "3              0.586914  0.463379  \n",
            "4              0.565918  0.445312  \n",
            "--------------------------------------------------Frame 884\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 2 traffic lights, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/884'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/884/person_7706.jpg            0.213379   \n",
            "0      7692  frames/884/person_7692.jpg            0.195190   \n",
            "2      7688  frames/884/person_7688.jpg            0.191406   \n",
            "3      7767  frames/884/person_7767.jpg            0.171509   \n",
            "4      7768  frames/884/person_7768.jpg            0.164795   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.605469  0.487793  \n",
            "0              0.583008  0.466797  \n",
            "2              0.579590  0.463135  \n",
            "3              0.573730  0.453125  \n",
            "4              0.557617  0.439941  \n",
            "--------------------------------------------------Frame 885\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 12.3ms\n",
            "Speed: 2.6ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/885'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/885/person_7706.jpg            0.212891   \n",
            "3      7767  frames/885/person_7767.jpg            0.198853   \n",
            "5      7790  frames/885/person_7790.jpg            0.179810   \n",
            "2      7688  frames/885/person_7688.jpg            0.193481   \n",
            "0      7692  frames/885/person_7692.jpg            0.192261   \n",
            "4      7768  frames/885/person_7768.jpg            0.161133   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.608887  0.490234  \n",
            "3              0.582031  0.467041  \n",
            "5              0.585938  0.464111  \n",
            "2              0.575684  0.461182  \n",
            "0              0.575195  0.460205  \n",
            "4              0.558594  0.439453  \n",
            "--------------------------------------------------Frame 886\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 14.3ms\n",
            "Speed: 2.1ms preprocess, 14.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/886'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/886/person_7706.jpg            0.216064   \n",
            "5      7790  frames/886/person_7790.jpg            0.185669   \n",
            "3      7767  frames/886/person_7767.jpg            0.202637   \n",
            "0      7692  frames/886/person_7692.jpg            0.196167   \n",
            "2      7688  frames/886/person_7688.jpg            0.183838   \n",
            "4      7768  frames/886/person_7768.jpg            0.159058   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610352  0.492188  \n",
            "5              0.605957  0.479736  \n",
            "3              0.588379  0.472656  \n",
            "0              0.586914  0.469727  \n",
            "2              0.564453  0.450195  \n",
            "4              0.563477  0.442383  \n",
            "--------------------------------------------------Frame 887\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 12.3ms\n",
            "Speed: 2.0ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/887'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/887/person_7706.jpg            0.227051   \n",
            "4      7790  frames/887/person_7790.jpg            0.205078   \n",
            "0      7692  frames/887/person_7692.jpg            0.193237   \n",
            "2      7688  frames/887/person_7688.jpg            0.194824   \n",
            "3      7768  frames/887/person_7768.jpg            0.174194   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.609863  0.495117  \n",
            "4              0.602539  0.483398  \n",
            "0              0.606445  0.482422  \n",
            "2              0.576172  0.461670  \n",
            "3              0.573242  0.453613  \n",
            "--------------------------------------------------Frame 888\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 1 backpack, 11.1ms\n",
            "Speed: 2.5ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/888'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/888/person_7706.jpg            0.201416   \n",
            "4      7790  frames/888/person_7790.jpg            0.204834   \n",
            "2      7688  frames/888/person_7688.jpg            0.204590   \n",
            "0      7692  frames/888/person_7692.jpg            0.182617   \n",
            "3      7768  frames/888/person_7768.jpg            0.169922   \n",
            "5      7798  frames/888/person_7798.jpg            0.187012   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.611816  0.488770  \n",
            "4              0.595703  0.478516  \n",
            "2              0.589844  0.474121  \n",
            "0              0.592285  0.469238  \n",
            "3              0.581543  0.458008  \n",
            "5              0.550293  0.441406  \n",
            "--------------------------------------------------Frame 889\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 1 backpack, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/889'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/889/person_7706.jpg            0.211670   \n",
            "0      7692  frames/889/person_7692.jpg            0.191895   \n",
            "4      7790  frames/889/person_7790.jpg            0.194824   \n",
            "2      7688  frames/889/person_7688.jpg            0.187378   \n",
            "3      7768  frames/889/person_7768.jpg            0.170532   \n",
            "5      7798  frames/889/person_7798.jpg            0.187012   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.613281  0.492676  \n",
            "0              0.600586  0.478027  \n",
            "4              0.595703  0.475342  \n",
            "2              0.596680  0.473877  \n",
            "3              0.577148  0.455078  \n",
            "5              0.550293  0.441406  \n",
            "--------------------------------------------------Frame 890\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 1 backpack, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/890'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/890/person_7706.jpg            0.189819   \n",
            "0      7692  frames/890/person_7692.jpg            0.192871   \n",
            "4      7790  frames/890/person_7790.jpg            0.197754   \n",
            "2      7688  frames/890/person_7688.jpg            0.192261   \n",
            "3      7768  frames/890/person_7768.jpg            0.160034   \n",
            "5      7798  frames/890/person_7798.jpg            0.183472   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.606934  0.481689  \n",
            "0              0.604492  0.480957  \n",
            "4              0.598633  0.478271  \n",
            "2              0.592773  0.472656  \n",
            "3              0.577148  0.452148  \n",
            "5              0.554199  0.442871  \n",
            "--------------------------------------------------Frame 891\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 1 backpack, 20.8ms\n",
            "Speed: 3.4ms preprocess, 20.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/891'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/891/person_7706.jpg            0.205688   \n",
            "4      7790  frames/891/person_7790.jpg            0.195923   \n",
            "0      7692  frames/891/person_7692.jpg            0.184692   \n",
            "2      7688  frames/891/person_7688.jpg            0.192017   \n",
            "3      7768  frames/891/person_7768.jpg            0.161743   \n",
            "5      7798  frames/891/person_7798.jpg            0.184814   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.602051  0.483154  \n",
            "4              0.598633  0.477783  \n",
            "0              0.602051  0.476807  \n",
            "2              0.593750  0.473145  \n",
            "3              0.574707  0.450928  \n",
            "5              0.560059  0.447510  \n",
            "--------------------------------------------------Frame 892\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 2 traffic lights, 1 backpack, 11.1ms\n",
            "Speed: 2.7ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/892'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/892/person_7790.jpg            0.232300   \n",
            "1      7706  frames/892/person_7706.jpg            0.210938   \n",
            "0      7692  frames/892/person_7692.jpg            0.193115   \n",
            "2      7688  frames/892/person_7688.jpg            0.185913   \n",
            "5      7798  frames/892/person_7798.jpg            0.198364   \n",
            "3      7768  frames/892/person_7768.jpg            0.164307   \n",
            "6      7755  frames/892/person_7755.jpg            0.150757   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.602539  0.491699  \n",
            "1              0.609863  0.490234  \n",
            "0              0.589355  0.470459  \n",
            "2              0.581543  0.462891  \n",
            "5              0.557129  0.449463  \n",
            "3              0.562500  0.443115  \n",
            "6              0.556152  0.434570  \n",
            "--------------------------------------------------Frame 893\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 2 traffic lights, 1 backpack, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/893'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/893/person_7790.jpg            0.221924   \n",
            "1      7706  frames/893/person_7706.jpg            0.201538   \n",
            "0      7692  frames/893/person_7692.jpg            0.188477   \n",
            "5      7798  frames/893/person_7798.jpg            0.189209   \n",
            "2      7688  frames/893/person_7688.jpg            0.184937   \n",
            "3      7768  frames/893/person_7768.jpg            0.162109   \n",
            "6      7755  frames/893/person_7755.jpg            0.147095   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.604004  0.489502  \n",
            "1              0.605957  0.484619  \n",
            "0              0.585938  0.466797  \n",
            "5              0.576660  0.460449  \n",
            "2              0.570312  0.454590  \n",
            "3              0.572266  0.449219  \n",
            "6              0.563477  0.438721  \n",
            "--------------------------------------------------Frame 894\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 2 traffic lights, 1 backpack, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/894'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/894/person_7706.jpg            0.211670   \n",
            "4      7790  frames/894/person_7790.jpg            0.218628   \n",
            "0      7692  frames/894/person_7692.jpg            0.185303   \n",
            "5      7798  frames/894/person_7798.jpg            0.189697   \n",
            "2      7688  frames/894/person_7688.jpg            0.181152   \n",
            "6      7755  frames/894/person_7755.jpg            0.156006   \n",
            "3      7768  frames/894/person_7768.jpg            0.164551   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.612305  0.492188  \n",
            "4              0.603516  0.488037  \n",
            "0              0.591309  0.469482  \n",
            "5              0.573242  0.458252  \n",
            "2              0.574707  0.456787  \n",
            "6              0.562988  0.440918  \n",
            "3              0.555664  0.438232  \n",
            "--------------------------------------------------Frame 895\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 2 traffic lights, 1 backpack, 13.4ms\n",
            "Speed: 2.1ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/895'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/895/person_7706.jpg            0.208252   \n",
            "4      7790  frames/895/person_7790.jpg            0.221924   \n",
            "0      7692  frames/895/person_7692.jpg            0.195435   \n",
            "2      7688  frames/895/person_7688.jpg            0.186523   \n",
            "5      7798  frames/895/person_7798.jpg            0.158569   \n",
            "3      7768  frames/895/person_7768.jpg            0.163208   \n",
            "6      7755  frames/895/person_7755.jpg            0.138062   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610840  0.489990  \n",
            "4              0.601562  0.487793  \n",
            "0              0.596680  0.476318  \n",
            "2              0.566895  0.452637  \n",
            "5              0.577148  0.451660  \n",
            "3              0.548828  0.433105  \n",
            "6              0.545898  0.423584  \n",
            "--------------------------------------------------Frame 896\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 2 traffic lights, 1 backpack, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/896'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/896/person_7790.jpg            0.220581   \n",
            "1      7706  frames/896/person_7706.jpg            0.206177   \n",
            "0      7692  frames/896/person_7692.jpg            0.193481   \n",
            "2      7688  frames/896/person_7688.jpg            0.192749   \n",
            "5      7798  frames/896/person_7798.jpg            0.149292   \n",
            "3      7768  frames/896/person_7768.jpg            0.155640   \n",
            "6      7755  frames/896/person_7755.jpg            0.143921   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.605957  0.490234  \n",
            "1              0.611328  0.489746  \n",
            "0              0.597168  0.476074  \n",
            "2              0.575684  0.460938  \n",
            "5              0.572754  0.445801  \n",
            "3              0.545410  0.428467  \n",
            "6              0.548828  0.427490  \n",
            "--------------------------------------------------Frame 897\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 2 traffic lights, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/897'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/897/person_7706.jpg            0.218872   \n",
            "0      7692  frames/897/person_7692.jpg            0.199585   \n",
            "4      7790  frames/897/person_7790.jpg            0.222046   \n",
            "2      7688  frames/897/person_7688.jpg            0.186768   \n",
            "5      7798  frames/897/person_7798.jpg            0.147705   \n",
            "3      7768  frames/897/person_7768.jpg            0.158447   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.603027  0.487793  \n",
            "0              0.598633  0.478760  \n",
            "4              0.585938  0.476807  \n",
            "2              0.576172  0.459473  \n",
            "5              0.576660  0.447754  \n",
            "3              0.555176  0.436279  \n",
            "--------------------------------------------------Frame 898\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 2 traffic lights, 15.0ms\n",
            "Speed: 2.3ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/898'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "6      7826  frames/898/person_7826.jpg            0.215210   \n",
            "1      7706  frames/898/person_7706.jpg            0.226562   \n",
            "4      7790  frames/898/person_7790.jpg            0.224976   \n",
            "0      7692  frames/898/person_7692.jpg            0.190918   \n",
            "5      7798  frames/898/person_7798.jpg            0.175659   \n",
            "2      7688  frames/898/person_7688.jpg            0.175415   \n",
            "3      7768  frames/898/person_7768.jpg            0.168579   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "6              0.627441  0.503906  \n",
            "1              0.607422  0.493164  \n",
            "4              0.590332  0.480957  \n",
            "0              0.593262  0.472656  \n",
            "5              0.581055  0.459473  \n",
            "2              0.573730  0.454102  \n",
            "3              0.559570  0.442139  \n",
            "--------------------------------------------------Frame 899\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 3 traffic lights, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/899'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7790  frames/899/person_7790.jpg            0.249878   \n",
            "0      7692  frames/899/person_7692.jpg            0.191040   \n",
            "1      7706  frames/899/person_7706.jpg            0.195557   \n",
            "2      7688  frames/899/person_7688.jpg            0.187500   \n",
            "4      7798  frames/899/person_7798.jpg            0.146240   \n",
            "5      7799  frames/899/person_7799.jpg            0.161987   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.568848  0.473145  \n",
            "0              0.592773  0.472412  \n",
            "1              0.588867  0.470703  \n",
            "2              0.583008  0.464355  \n",
            "4              0.573730  0.445557  \n",
            "5              0.551758  0.434814  \n",
            "--------------------------------------------------Frame 900\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/900'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/900/person_7706.jpg            0.217773   \n",
            "3      7790  frames/900/person_7790.jpg            0.227539   \n",
            "0      7692  frames/900/person_7692.jpg            0.181396   \n",
            "2      7688  frames/900/person_7688.jpg            0.196777   \n",
            "4      7799  frames/900/person_7799.jpg            0.178345   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.604004  0.488281  \n",
            "3              0.583496  0.476562  \n",
            "0              0.591309  0.468262  \n",
            "2              0.583008  0.467285  \n",
            "4              0.559570  0.445068  \n",
            "--------------------------------------------------Frame 901\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 14.6ms\n",
            "Speed: 3.4ms preprocess, 14.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/901'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/901/person_7706.jpg            0.202759   \n",
            "3      7790  frames/901/person_7790.jpg            0.238037   \n",
            "0      7692  frames/901/person_7692.jpg            0.182617   \n",
            "2      7688  frames/901/person_7688.jpg            0.194214   \n",
            "4      7799  frames/901/person_7799.jpg            0.168823   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.589844  0.473633  \n",
            "3              0.573242  0.472656  \n",
            "0              0.589844  0.467529  \n",
            "2              0.575195  0.460938  \n",
            "4              0.557129  0.440430  \n",
            "--------------------------------------------------Frame 902\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 11.4ms\n",
            "Speed: 2.5ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/902'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/902/person_7706.jpg            0.202759   \n",
            "3      7790  frames/902/person_7790.jpg            0.238037   \n",
            "0      7692  frames/902/person_7692.jpg            0.183472   \n",
            "2      7688  frames/902/person_7688.jpg            0.193359   \n",
            "4      7799  frames/902/person_7799.jpg            0.170654   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.589844  0.473633  \n",
            "3              0.573242  0.472656  \n",
            "0              0.595215  0.471680  \n",
            "2              0.573730  0.459717  \n",
            "4              0.554199  0.439209  \n",
            "--------------------------------------------------Frame 903\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/903'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7790  frames/903/person_7790.jpg            0.234009   \n",
            "0      7692  frames/903/person_7692.jpg            0.183472   \n",
            "1      7706  frames/903/person_7706.jpg            0.199097   \n",
            "2      7688  frames/903/person_7688.jpg            0.193359   \n",
            "4      7799  frames/903/person_7799.jpg            0.176514   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.587402  0.481445  \n",
            "0              0.595215  0.471680  \n",
            "1              0.584473  0.468994  \n",
            "2              0.573730  0.459717  \n",
            "4              0.547852  0.436523  \n",
            "--------------------------------------------------Frame 904\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/904'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/904/person_7706.jpg            0.202759   \n",
            "0      7692  frames/904/person_7692.jpg            0.178955   \n",
            "2      7688  frames/904/person_7688.jpg            0.191406   \n",
            "4      7834  frames/904/person_7834.jpg            0.153320   \n",
            "3      7799  frames/904/person_7799.jpg            0.167847   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.604004  0.483643  \n",
            "0              0.598145  0.472412  \n",
            "2              0.579590  0.463135  \n",
            "4              0.584473  0.455078  \n",
            "3              0.564453  0.445312  \n",
            "--------------------------------------------------Frame 905\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/905'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7692  frames/905/person_7692.jpg            0.191040   \n",
            "1      7706  frames/905/person_7706.jpg            0.198975   \n",
            "2      7688  frames/905/person_7688.jpg            0.195312   \n",
            "4      7834  frames/905/person_7834.jpg            0.165771   \n",
            "3      7799  frames/905/person_7799.jpg            0.169434   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.603516  0.479736  \n",
            "1              0.595703  0.476562  \n",
            "2              0.575684  0.461670  \n",
            "4              0.587402  0.460938  \n",
            "3              0.546387  0.433350  \n",
            "--------------------------------------------------Frame 906\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 4 traffic lights, 18.7ms\n",
            "Speed: 2.4ms preprocess, 18.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/906'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7692  frames/906/person_7692.jpg            0.192627   \n",
            "1      7706  frames/906/person_7706.jpg            0.204224   \n",
            "4      7834  frames/906/person_7834.jpg            0.166382   \n",
            "2      7688  frames/906/person_7688.jpg            0.193848   \n",
            "3      7799  frames/906/person_7799.jpg            0.175903   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.605957  0.481934  \n",
            "1              0.594238  0.477295  \n",
            "4              0.588379  0.461914  \n",
            "2              0.571777  0.458252  \n",
            "3              0.543945  0.433594  \n",
            "--------------------------------------------------Frame 907\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 2 traffic lights, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/907'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "0      7692  frames/907/person_7692.jpg            0.174316   \n",
            "4      7834  frames/907/person_7834.jpg            0.169678   \n",
            "2      7688  frames/907/person_7688.jpg            0.201416   \n",
            "1      7706  frames/907/person_7706.jpg            0.188599   \n",
            "3      7799  frames/907/person_7799.jpg            0.178589   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.593750  0.467773  \n",
            "4              0.593750  0.466309  \n",
            "2              0.575684  0.463379  \n",
            "1              0.575195  0.459229  \n",
            "3              0.557129  0.443359  \n",
            "--------------------------------------------------Frame 908\n",
            "\n",
            "0: 384x640 5 persons, 5 cars, 2 traffic lights, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/908'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7688  frames/908/person_7688.jpg            0.202759   \n",
            "0      7692  frames/908/person_7692.jpg            0.178223   \n",
            "4      7834  frames/908/person_7834.jpg            0.174316   \n",
            "1      7706  frames/908/person_7706.jpg            0.194824   \n",
            "3      7799  frames/908/person_7799.jpg            0.180786   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.583984  0.469482  \n",
            "0              0.593750  0.468994  \n",
            "4              0.588379  0.464111  \n",
            "1              0.576660  0.461914  \n",
            "3              0.564941  0.449707  \n",
            "--------------------------------------------------Frame 909\n",
            "\n",
            "0: 384x640 6 persons, 5 cars, 2 traffic lights, 15.2ms\n",
            "Speed: 2.5ms preprocess, 15.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/909'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "5      7790  frames/909/person_7790.jpg            0.227051   \n",
            "0      7692  frames/909/person_7692.jpg            0.189575   \n",
            "2      7688  frames/909/person_7688.jpg            0.190430   \n",
            "4      7834  frames/909/person_7834.jpg            0.177490   \n",
            "1      7706  frames/909/person_7706.jpg            0.199585   \n",
            "3      7799  frames/909/person_7799.jpg            0.147705   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.595703  0.485107  \n",
            "0              0.600098  0.477051  \n",
            "2              0.594727  0.473389  \n",
            "4              0.597656  0.471680  \n",
            "1              0.587891  0.471436  \n",
            "3              0.556152  0.433594  \n",
            "--------------------------------------------------Frame 910\n",
            "\n",
            "0: 384x640 6 persons, 5 cars, 3 traffic lights, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/910'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "5      7790  frames/910/person_7790.jpg            0.220581   \n",
            "2      7688  frames/910/person_7688.jpg            0.188965   \n",
            "1      7706  frames/910/person_7706.jpg            0.201904   \n",
            "0      7692  frames/910/person_7692.jpg            0.194946   \n",
            "4      7834  frames/910/person_7834.jpg            0.151611   \n",
            "3      7799  frames/910/person_7799.jpg            0.164551   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.598633  0.485107  \n",
            "2              0.598145  0.475342  \n",
            "1              0.588379  0.472412  \n",
            "0              0.590332  0.471680  \n",
            "4              0.608887  0.471680  \n",
            "3              0.592285  0.463867  \n",
            "--------------------------------------------------Frame 911\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/911'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/911/person_7790.jpg            0.240967   \n",
            "1      7706  frames/911/person_7706.jpg            0.224731   \n",
            "3      7834  frames/911/person_7834.jpg            0.188232   \n",
            "2      7688  frames/911/person_7688.jpg            0.194580   \n",
            "0      7692  frames/911/person_7692.jpg            0.173462   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.621094  0.506836  \n",
            "1              0.602539  0.489258  \n",
            "3              0.601074  0.477051  \n",
            "2              0.593750  0.473877  \n",
            "0              0.601074  0.472656  \n",
            "--------------------------------------------------Frame 912\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/912'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/912/person_7790.jpg            0.232544   \n",
            "1      7706  frames/912/person_7706.jpg            0.230469   \n",
            "3      7834  frames/912/person_7834.jpg            0.184937   \n",
            "0      7692  frames/912/person_7692.jpg            0.174438   \n",
            "2      7688  frames/912/person_7688.jpg            0.180908   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.613281  0.499023  \n",
            "1              0.604492  0.492188  \n",
            "3              0.600098  0.475586  \n",
            "0              0.595703  0.469238  \n",
            "2              0.574219  0.456055  \n",
            "--------------------------------------------------Frame 913\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 12.7ms\n",
            "Speed: 2.6ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/913'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/913/person_7790.jpg            0.238892   \n",
            "1      7706  frames/913/person_7706.jpg            0.223877   \n",
            "3      7834  frames/913/person_7834.jpg            0.185913   \n",
            "0      7692  frames/913/person_7692.jpg            0.175049   \n",
            "2      7688  frames/913/person_7688.jpg            0.182861   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.611816  0.500000  \n",
            "1              0.606445  0.491699  \n",
            "3              0.598145  0.474609  \n",
            "0              0.600586  0.472900  \n",
            "2              0.577637  0.459229  \n",
            "--------------------------------------------------Frame 914\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/914'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/914/person_7790.jpg            0.240112   \n",
            "1      7706  frames/914/person_7706.jpg            0.222900   \n",
            "0      7692  frames/914/person_7692.jpg            0.173950   \n",
            "3      7834  frames/914/person_7834.jpg            0.183594   \n",
            "2      7688  frames/914/person_7688.jpg            0.179321   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.617676  0.504395  \n",
            "1              0.606445  0.491455  \n",
            "0              0.602539  0.474121  \n",
            "3              0.598145  0.473877  \n",
            "2              0.580566  0.460205  \n",
            "--------------------------------------------------Frame 915\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/915'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/915/person_7790.jpg            0.236694   \n",
            "1      7706  frames/915/person_7706.jpg            0.227661   \n",
            "3      7834  frames/915/person_7834.jpg            0.183838   \n",
            "2      7688  frames/915/person_7688.jpg            0.180908   \n",
            "0      7692  frames/915/person_7692.jpg            0.177246   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.614746  0.501465  \n",
            "1              0.605957  0.492432  \n",
            "3              0.601562  0.476318  \n",
            "2              0.598633  0.473145  \n",
            "0              0.589355  0.465820  \n",
            "--------------------------------------------------Frame 916\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/916'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/916/person_7790.jpg            0.256592   \n",
            "3      7834  frames/916/person_7834.jpg            0.187378   \n",
            "1      7706  frames/916/person_7706.jpg            0.211670   \n",
            "2      7688  frames/916/person_7688.jpg            0.181274   \n",
            "0      7692  frames/916/person_7692.jpg            0.189575   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.588867  0.489014  \n",
            "3              0.601562  0.477295  \n",
            "1              0.589355  0.476074  \n",
            "2              0.597656  0.472900  \n",
            "0              0.583984  0.465576  \n",
            "--------------------------------------------------Frame 917\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/917'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/917/person_7790.jpg            0.250732   \n",
            "3      7834  frames/917/person_7834.jpg            0.191162   \n",
            "1      7706  frames/917/person_7706.jpg            0.199951   \n",
            "2      7688  frames/917/person_7688.jpg            0.181519   \n",
            "0      7692  frames/917/person_7692.jpg            0.172119   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.598145  0.493896  \n",
            "3              0.598633  0.476318  \n",
            "1              0.592285  0.474609  \n",
            "2              0.598633  0.473389  \n",
            "0              0.567871  0.449219  \n",
            "--------------------------------------------------Frame 918\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/918'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7790  frames/918/person_7790.jpg            0.262695   \n",
            "3      7834  frames/918/person_7834.jpg            0.188232   \n",
            "2      7688  frames/918/person_7688.jpg            0.182617   \n",
            "1      7706  frames/918/person_7706.jpg            0.199951   \n",
            "0      7692  frames/918/person_7692.jpg            0.178101   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.579590  0.484619  \n",
            "3              0.601074  0.477051  \n",
            "2              0.601562  0.475830  \n",
            "1              0.588379  0.471924  \n",
            "0              0.562012  0.446777  \n",
            "--------------------------------------------------Frame 919\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/919'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/919/person_7706.jpg            0.202026   \n",
            "4      7790  frames/919/person_7790.jpg            0.224731   \n",
            "2      7688  frames/919/person_7688.jpg            0.196533   \n",
            "3      7834  frames/919/person_7834.jpg            0.185303   \n",
            "0      7692  frames/919/person_7692.jpg            0.204102   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.606445  0.485107  \n",
            "4              0.591309  0.481201  \n",
            "2              0.598633  0.478027  \n",
            "3              0.602539  0.477539  \n",
            "0              0.584473  0.470459  \n",
            "--------------------------------------------------Frame 920\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 13.5ms\n",
            "Speed: 2.4ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/920'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7834  frames/920/person_7834.jpg            0.185181   \n",
            "1      7706  frames/920/person_7706.jpg            0.199463   \n",
            "4      7790  frames/920/person_7790.jpg            0.215576   \n",
            "0      7692  frames/920/person_7692.jpg            0.203857   \n",
            "2      7688  frames/920/person_7688.jpg            0.188110   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.610840  0.482910  \n",
            "1              0.603027  0.481934  \n",
            "4              0.594727  0.480957  \n",
            "0              0.592773  0.476074  \n",
            "2              0.592285  0.470947  \n",
            "--------------------------------------------------Frame 921\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 14.7ms\n",
            "Speed: 2.0ms preprocess, 14.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/921'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7834  frames/921/person_7834.jpg            0.181274   \n",
            "2      7688  frames/921/person_7688.jpg            0.181030   \n",
            "1      7706  frames/921/person_7706.jpg            0.205078   \n",
            "4      7790  frames/921/person_7790.jpg            0.231689   \n",
            "0      7692  frames/921/person_7692.jpg            0.179565   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.609375  0.480957  \n",
            "2              0.604492  0.477539  \n",
            "1              0.589844  0.474365  \n",
            "4              0.570312  0.468750  \n",
            "0              0.577637  0.458252  \n",
            "--------------------------------------------------Frame 922\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 traffic light, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/922'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/922/person_7706.jpg            0.208008   \n",
            "2      7688  frames/922/person_7688.jpg            0.194824   \n",
            "3      7834  frames/922/person_7834.jpg            0.177856   \n",
            "4      7790  frames/922/person_7790.jpg            0.228027   \n",
            "5      7853  frames/922/person_7853.jpg            0.184937   \n",
            "0      7692  frames/922/person_7692.jpg            0.178101   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.604004  0.485352  \n",
            "2              0.607422  0.483643  \n",
            "3              0.612305  0.481934  \n",
            "4              0.581055  0.475098  \n",
            "5              0.593262  0.470703  \n",
            "0              0.562012  0.446777  \n",
            "--------------------------------------------------Frame 923\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/923'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/923/person_7706.jpg            0.227051   \n",
            "2      7688  frames/923/person_7688.jpg            0.180908   \n",
            "4      7857  frames/923/person_7857.jpg            0.222412   \n",
            "3      7834  frames/923/person_7834.jpg            0.173218   \n",
            "0      7692  frames/923/person_7692.jpg            0.183594   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610840  0.495605  \n",
            "2              0.628418  0.494141  \n",
            "4              0.605469  0.490479  \n",
            "3              0.613770  0.481689  \n",
            "0              0.584961  0.464600  \n",
            "--------------------------------------------------Frame 924\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 11.4ms\n",
            "Speed: 2.1ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/924'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "2      7688  frames/924/person_7688.jpg            0.184448   \n",
            "1      7706  frames/924/person_7706.jpg            0.214722   \n",
            "3      7834  frames/924/person_7834.jpg            0.174072   \n",
            "4      7857  frames/924/person_7857.jpg            0.206177   \n",
            "0      7692  frames/924/person_7692.jpg            0.180420   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.618652  0.488525  \n",
            "1              0.605469  0.488281  \n",
            "3              0.620605  0.486572  \n",
            "4              0.606934  0.486572  \n",
            "0              0.577148  0.458252  \n",
            "--------------------------------------------------Frame 925\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 14.9ms\n",
            "Speed: 2.5ms preprocess, 14.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/925'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/925/person_7706.jpg            0.228271   \n",
            "2      7688  frames/925/person_7688.jpg            0.182007   \n",
            "3      7834  frames/925/person_7834.jpg            0.179688   \n",
            "4      7857  frames/925/person_7857.jpg            0.209839   \n",
            "0      7692  frames/925/person_7692.jpg            0.167847   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.603516  0.490723  \n",
            "2              0.622070  0.490234  \n",
            "3              0.616211  0.485352  \n",
            "4              0.602051  0.484375  \n",
            "0              0.564453  0.445312  \n",
            "--------------------------------------------------Frame 926\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/926'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/926/person_7706.jpg            0.229614   \n",
            "2      7688  frames/926/person_7688.jpg            0.187012   \n",
            "3      7834  frames/926/person_7834.jpg            0.179199   \n",
            "4      7857  frames/926/person_7857.jpg            0.198242   \n",
            "0      7692  frames/926/person_7692.jpg            0.168823   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.599609  0.488525  \n",
            "2              0.614258  0.486084  \n",
            "3              0.607422  0.479004  \n",
            "4              0.595703  0.476562  \n",
            "0              0.558594  0.441895  \n",
            "--------------------------------------------------Frame 927\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 14.6ms\n",
            "Speed: 2.2ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/927'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7857  frames/927/person_7857.jpg            0.220825   \n",
            "3      7834  frames/927/person_7834.jpg            0.179077   \n",
            "1      7706  frames/927/person_7706.jpg            0.217163   \n",
            "2      7688  frames/927/person_7688.jpg            0.176514   \n",
            "0      7692  frames/927/person_7692.jpg            0.174805   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.599609  0.485840  \n",
            "3              0.616699  0.485352  \n",
            "1              0.597168  0.483154  \n",
            "2              0.613770  0.482666  \n",
            "0              0.571777  0.452637  \n",
            "--------------------------------------------------Frame 928\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 9.4ms\n",
            "Speed: 2.4ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/928'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/928/person_7706.jpg            0.214600   \n",
            "3      7834  frames/928/person_7834.jpg            0.177979   \n",
            "2      7688  frames/928/person_7688.jpg            0.190063   \n",
            "4      7857  frames/928/person_7857.jpg            0.205688   \n",
            "0      7692  frames/928/person_7692.jpg            0.187866   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.608398  0.490234  \n",
            "3              0.616699  0.485107  \n",
            "2              0.609375  0.483398  \n",
            "4              0.590820  0.475342  \n",
            "0              0.569824  0.455322  \n",
            "--------------------------------------------------Frame 929\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 13.8ms\n",
            "Speed: 2.6ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/929'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7857  frames/929/person_7857.jpg            0.216553   \n",
            "1      7706  frames/929/person_7706.jpg            0.206299   \n",
            "2      7688  frames/929/person_7688.jpg            0.193237   \n",
            "3      7834  frames/929/person_7834.jpg            0.183105   \n",
            "0      7692  frames/929/person_7692.jpg            0.185425   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.599121  0.484375  \n",
            "1              0.602539  0.483887  \n",
            "2              0.608398  0.483887  \n",
            "3              0.604004  0.477783  \n",
            "0              0.581055  0.462402  \n",
            "--------------------------------------------------Frame 930\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 11.0ms\n",
            "Speed: 7.2ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/930'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/930/person_7706.jpg            0.217041   \n",
            "2      7688  frames/930/person_7688.jpg            0.171265   \n",
            "3      7834  frames/930/person_7834.jpg            0.178223   \n",
            "4      7857  frames/930/person_7857.jpg            0.213867   \n",
            "0      7692  frames/930/person_7692.jpg            0.185547   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.604980  0.488770  \n",
            "2              0.609863  0.478516  \n",
            "3              0.599609  0.473145  \n",
            "4              0.582031  0.471680  \n",
            "0              0.593262  0.470947  \n",
            "--------------------------------------------------Frame 931\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 11.2ms\n",
            "Speed: 2.4ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/931'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7857  frames/931/person_7857.jpg            0.218262   \n",
            "1      7706  frames/931/person_7706.jpg            0.198120   \n",
            "2      7688  frames/931/person_7688.jpg            0.174927   \n",
            "3      7834  frames/931/person_7834.jpg            0.166748   \n",
            "0      7692  frames/931/person_7692.jpg            0.184204   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.600586  0.485840  \n",
            "1              0.607422  0.484863  \n",
            "2              0.606934  0.477295  \n",
            "3              0.597656  0.468506  \n",
            "0              0.579590  0.460938  \n",
            "--------------------------------------------------Frame 932\n",
            "\n",
            "0: 384x640 5 persons, 3 cars, 1 traffic light, 13.7ms\n",
            "Speed: 3.1ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/932'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7857  frames/932/person_7857.jpg            0.223389   \n",
            "1      7706  frames/932/person_7706.jpg            0.192505   \n",
            "2      7688  frames/932/person_7688.jpg            0.176514   \n",
            "3      7834  frames/932/person_7834.jpg            0.160034   \n",
            "0      7692  frames/932/person_7692.jpg            0.183472   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.598633  0.485840  \n",
            "1              0.608398  0.483398  \n",
            "2              0.610352  0.480225  \n",
            "3              0.601562  0.469238  \n",
            "0              0.574707  0.457520  \n",
            "--------------------------------------------------Frame 933\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/933'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7857  frames/933/person_7857.jpg            0.221436   \n",
            "1      7706  frames/933/person_7706.jpg            0.191040   \n",
            "3      7834  frames/933/person_7834.jpg            0.164673   \n",
            "2      7688  frames/933/person_7688.jpg            0.170898   \n",
            "0      7692  frames/933/person_7692.jpg            0.179321   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.602539  0.488281  \n",
            "1              0.612305  0.486084  \n",
            "3              0.603516  0.471680  \n",
            "2              0.598633  0.470215  \n",
            "0              0.578125  0.458496  \n",
            "--------------------------------------------------Frame 934\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/934'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/934/person_7706.jpg            0.203247   \n",
            "4      7857  frames/934/person_7857.jpg            0.219360   \n",
            "3      7834  frames/934/person_7834.jpg            0.162598   \n",
            "2      7688  frames/934/person_7688.jpg            0.166504   \n",
            "0      7692  frames/934/person_7692.jpg            0.182007   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.617188  0.493164  \n",
            "4              0.601074  0.486328  \n",
            "3              0.601562  0.469971  \n",
            "2              0.597656  0.468506  \n",
            "0              0.574219  0.456543  \n",
            "--------------------------------------------------Frame 935\n",
            "\n",
            "0: 384x640 4 persons, 4 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/935'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/935/person_7706.jpg            0.213379   \n",
            "3      7857  frames/935/person_7857.jpg            0.228271   \n",
            "2      7688  frames/935/person_7688.jpg            0.184692   \n",
            "0      7692  frames/935/person_7692.jpg            0.188721   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.632812  0.506836  \n",
            "3              0.623047  0.504395  \n",
            "2              0.603027  0.477539  \n",
            "0              0.585449  0.466553  \n",
            "--------------------------------------------------Frame 936\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/936'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/936/person_7706.jpg            0.209961   \n",
            "3      7857  frames/936/person_7857.jpg            0.222656   \n",
            "2      7688  frames/936/person_7688.jpg            0.184814   \n",
            "0      7692  frames/936/person_7692.jpg            0.188721   \n",
            "4      7865  frames/936/person_7865.jpg            0.150391   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.637207  0.508789  \n",
            "3              0.621582  0.501953  \n",
            "2              0.599609  0.475098  \n",
            "0              0.585449  0.466553  \n",
            "4              0.557617  0.435547  \n",
            "--------------------------------------------------Frame 937\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 14.8ms\n",
            "Speed: 2.2ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/937'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7857  frames/937/person_7857.jpg            0.225220   \n",
            "1      7706  frames/937/person_7706.jpg            0.207153   \n",
            "2      7688  frames/937/person_7688.jpg            0.175781   \n",
            "0      7692  frames/937/person_7692.jpg            0.187622   \n",
            "4      7865  frames/937/person_7865.jpg            0.152588   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.624023  0.504395  \n",
            "1              0.626953  0.500977  \n",
            "2              0.598633  0.471680  \n",
            "0              0.587891  0.467773  \n",
            "4              0.562012  0.438965  \n",
            "--------------------------------------------------Frame 938\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/938'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/938/person_7706.jpg            0.207275   \n",
            "3      7857  frames/938/person_7857.jpg            0.216431   \n",
            "2      7688  frames/938/person_7688.jpg            0.180298   \n",
            "0      7692  frames/938/person_7692.jpg            0.187378   \n",
            "4      7865  frames/938/person_7865.jpg            0.151611   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.630371  0.503418  \n",
            "3              0.624512  0.501953  \n",
            "2              0.598145  0.472656  \n",
            "0              0.584473  0.465332  \n",
            "4              0.562500  0.439209  \n",
            "--------------------------------------------------Frame 939\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/939'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/939/person_7706.jpg            0.207886   \n",
            "3      7857  frames/939/person_7857.jpg            0.213135   \n",
            "2      7688  frames/939/person_7688.jpg            0.178833   \n",
            "0      7692  frames/939/person_7692.jpg            0.182617   \n",
            "4      7865  frames/939/person_7865.jpg            0.150146   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.625977  0.500488  \n",
            "3              0.621582  0.499023  \n",
            "2              0.598633  0.472656  \n",
            "0              0.579102  0.459961  \n",
            "4              0.562500  0.438965  \n",
            "--------------------------------------------------Frame 940\n",
            "\n",
            "0: 384x640 5 persons, 4 cars, 1 traffic light, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/940'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7857  frames/940/person_7857.jpg            0.219360   \n",
            "1      7706  frames/940/person_7706.jpg            0.186646   \n",
            "2      7688  frames/940/person_7688.jpg            0.190186   \n",
            "0      7692  frames/940/person_7692.jpg            0.188721   \n",
            "4      7865  frames/940/person_7865.jpg            0.152710   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.623535  0.502441  \n",
            "1              0.617676  0.488281  \n",
            "2              0.599121  0.476562  \n",
            "0              0.584961  0.466064  \n",
            "4              0.564941  0.441406  \n",
            "--------------------------------------------------Frame 941\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 traffic light, 15.8ms\n",
            "Speed: 2.1ms preprocess, 15.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/941'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "5      7866  frames/941/person_7866.jpg            0.225952   \n",
            "3      7857  frames/941/person_7857.jpg            0.213135   \n",
            "1      7706  frames/941/person_7706.jpg            0.191162   \n",
            "2      7688  frames/941/person_7688.jpg            0.189087   \n",
            "0      7692  frames/941/person_7692.jpg            0.184937   \n",
            "4      7865  frames/941/person_7865.jpg            0.160156   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.617676  0.500000  \n",
            "3              0.622070  0.499512  \n",
            "1              0.616699  0.489014  \n",
            "2              0.603516  0.479004  \n",
            "0              0.595215  0.472168  \n",
            "4              0.577148  0.452148  \n",
            "--------------------------------------------------Frame 942\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 traffic light, 13.0ms\n",
            "Speed: 3.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/942'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "5      7866  frames/942/person_7866.jpg            0.229126   \n",
            "3      7857  frames/942/person_7857.jpg            0.216187   \n",
            "1      7706  frames/942/person_7706.jpg            0.188965   \n",
            "2      7688  frames/942/person_7688.jpg            0.189209   \n",
            "0      7692  frames/942/person_7692.jpg            0.184204   \n",
            "4      7865  frames/942/person_7865.jpg            0.162231   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.614746  0.499023  \n",
            "3              0.619629  0.498779  \n",
            "1              0.617676  0.489014  \n",
            "2              0.601562  0.478027  \n",
            "0              0.597168  0.473145  \n",
            "4              0.577637  0.452881  \n",
            "--------------------------------------------------Frame 943\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 traffic light, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/943'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7857  frames/943/person_7857.jpg            0.223633   \n",
            "1      7706  frames/943/person_7706.jpg            0.195190   \n",
            "2      7688  frames/943/person_7688.jpg            0.191772   \n",
            "5      7866  frames/943/person_7866.jpg            0.208618   \n",
            "0      7692  frames/943/person_7692.jpg            0.178589   \n",
            "4      7865  frames/943/person_7865.jpg            0.155396   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.617676  0.499512  \n",
            "1              0.606445  0.483154  \n",
            "2              0.606445  0.482178  \n",
            "5              0.591309  0.476318  \n",
            "0              0.583008  0.461914  \n",
            "4              0.572266  0.447266  \n",
            "--------------------------------------------------Frame 944\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 traffic light, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/944'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7857  frames/944/person_7857.jpg            0.221069   \n",
            "1      7706  frames/944/person_7706.jpg            0.193726   \n",
            "2      7688  frames/944/person_7688.jpg            0.194580   \n",
            "5      7866  frames/944/person_7866.jpg            0.216187   \n",
            "0      7692  frames/944/person_7692.jpg            0.183838   \n",
            "4      7865  frames/944/person_7865.jpg            0.165894   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.617188  0.498535  \n",
            "1              0.614746  0.488525  \n",
            "2              0.605957  0.482422  \n",
            "5              0.591309  0.478760  \n",
            "0              0.581543  0.462158  \n",
            "4              0.573730  0.451416  \n",
            "--------------------------------------------------Frame 945\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/945'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7857  frames/945/person_7857.jpg            0.222778   \n",
            "1      7706  frames/945/person_7706.jpg            0.202515   \n",
            "2      7688  frames/945/person_7688.jpg            0.182861   \n",
            "0      7692  frames/945/person_7692.jpg            0.186279   \n",
            "5      7866  frames/945/person_7866.jpg            0.185547   \n",
            "4      7865  frames/945/person_7865.jpg            0.165771   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.619141  0.500000  \n",
            "1              0.612793  0.489746  \n",
            "2              0.595703  0.471924  \n",
            "0              0.592773  0.470947  \n",
            "5              0.576660  0.459229  \n",
            "4              0.577148  0.453857  \n",
            "--------------------------------------------------Frame 946\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 1 traffic light, 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/946'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "3      7857  frames/946/person_7857.jpg            0.225586   \n",
            "1      7706  frames/946/person_7706.jpg            0.191284   \n",
            "5      7866  frames/946/person_7866.jpg            0.215210   \n",
            "2      7688  frames/946/person_7688.jpg            0.183594   \n",
            "0      7692  frames/946/person_7692.jpg            0.176758   \n",
            "4      7865  frames/946/person_7865.jpg            0.169067   \n",
            "6      7870  frames/946/person_7870.jpg            0.127808   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.614746  0.498047  \n",
            "1              0.622559  0.493164  \n",
            "5              0.587891  0.476074  \n",
            "2              0.596680  0.472900  \n",
            "0              0.579590  0.458740  \n",
            "4              0.580078  0.456787  \n",
            "6              0.543457  0.418701  \n",
            "--------------------------------------------------Frame 947\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 13.3ms\n",
            "Speed: 3.0ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/947'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/947/person_7706.jpg            0.210815   \n",
            "4      7866  frames/947/person_7866.jpg            0.191650   \n",
            "2      7688  frames/947/person_7688.jpg            0.171143   \n",
            "0      7692  frames/947/person_7692.jpg            0.196167   \n",
            "3      7865  frames/947/person_7865.jpg            0.174805   \n",
            "5      7870  frames/947/person_7870.jpg            0.135132   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.624512  0.500488  \n",
            "4              0.614746  0.487793  \n",
            "2              0.590820  0.464844  \n",
            "0              0.578613  0.463867  \n",
            "3              0.576172  0.455811  \n",
            "5              0.541992  0.419922  \n",
            "--------------------------------------------------Frame 948\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/948'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/948/person_7706.jpg            0.199585   \n",
            "6      7875  frames/948/person_7875.jpg            0.181030   \n",
            "2      7688  frames/948/person_7688.jpg            0.173462   \n",
            "4      7866  frames/948/person_7866.jpg            0.180542   \n",
            "3      7865  frames/948/person_7865.jpg            0.165283   \n",
            "0      7692  frames/948/person_7692.jpg            0.191528   \n",
            "5      7870  frames/948/person_7870.jpg            0.145020   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.620117  0.493896  \n",
            "6              0.623535  0.490723  \n",
            "2              0.606445  0.476562  \n",
            "4              0.593750  0.469727  \n",
            "3              0.593750  0.465088  \n",
            "0              0.579102  0.462646  \n",
            "5              0.535156  0.417969  \n",
            "--------------------------------------------------Frame 949\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/949'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/949/person_7706.jpg            0.187866   \n",
            "6      7875  frames/949/person_7875.jpg            0.179199   \n",
            "4      7866  frames/949/person_7866.jpg            0.184082   \n",
            "2      7688  frames/949/person_7688.jpg            0.173462   \n",
            "0      7692  frames/949/person_7692.jpg            0.190430   \n",
            "3      7865  frames/949/person_7865.jpg            0.155396   \n",
            "5      7870  frames/949/person_7870.jpg            0.143677   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.615723  0.487305  \n",
            "6              0.613281  0.482910  \n",
            "4              0.604004  0.478027  \n",
            "2              0.605469  0.475830  \n",
            "0              0.584961  0.466553  \n",
            "3              0.580566  0.453125  \n",
            "5              0.539062  0.420410  \n",
            "--------------------------------------------------Frame 950\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 10.2ms\n",
            "Speed: 6.6ms preprocess, 10.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/950'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "1      7706  frames/950/person_7706.jpg            0.182251   \n",
            "4      7866  frames/950/person_7866.jpg            0.178955   \n",
            "2      7688  frames/950/person_7688.jpg            0.194336   \n",
            "6      7875  frames/950/person_7875.jpg            0.180176   \n",
            "0      7692  frames/950/person_7692.jpg            0.193115   \n",
            "3      7865  frames/950/person_7865.jpg            0.152588   \n",
            "5      7870  frames/950/person_7870.jpg            0.130249   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.608887  0.480957  \n",
            "4              0.606445  0.478271  \n",
            "2              0.599121  0.477783  \n",
            "6              0.602051  0.475342  \n",
            "0              0.592285  0.472412  \n",
            "3              0.573730  0.447266  \n",
            "5              0.531250  0.410889  \n",
            "--------------------------------------------------Frame 951\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/951'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "6      7875  frames/951/person_7875.jpg            0.195923   \n",
            "4      7866  frames/951/person_7866.jpg            0.194458   \n",
            "1      7706  frames/951/person_7706.jpg            0.192261   \n",
            "0      7692  frames/951/person_7692.jpg            0.191040   \n",
            "2      7688  frames/951/person_7688.jpg            0.186646   \n",
            "3      7865  frames/951/person_7865.jpg            0.156616   \n",
            "5      7870  frames/951/person_7870.jpg            0.144287   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "6              0.620117  0.492920  \n",
            "4              0.614258  0.488281  \n",
            "1              0.611328  0.485596  \n",
            "0              0.589844  0.470215  \n",
            "2              0.587402  0.467041  \n",
            "3              0.580078  0.453125  \n",
            "5              0.536133  0.418457  \n",
            "--------------------------------------------------Frame 952\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/952'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "5      7875  frames/952/person_7875.jpg            0.192505   \n",
            "4      7866  frames/952/person_7866.jpg            0.189575   \n",
            "1      7706  frames/952/person_7706.jpg            0.203125   \n",
            "2      7688  frames/952/person_7688.jpg            0.191040   \n",
            "0      7692  frames/952/person_7692.jpg            0.187622   \n",
            "3      7865  frames/952/person_7865.jpg            0.163208   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.638184  0.504395  \n",
            "4              0.622070  0.492432  \n",
            "1              0.602539  0.482910  \n",
            "2              0.589355  0.469971  \n",
            "0              0.573730  0.458008  \n",
            "3              0.581055  0.455566  \n",
            "--------------------------------------------------Frame 953\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 2 backpacks, 18.7ms\n",
            "Speed: 2.5ms preprocess, 18.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/953'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "5      7875  frames/953/person_7875.jpg            0.199951   \n",
            "4      7866  frames/953/person_7866.jpg            0.190186   \n",
            "1      7706  frames/953/person_7706.jpg            0.200928   \n",
            "0      7692  frames/953/person_7692.jpg            0.188843   \n",
            "2      7688  frames/953/person_7688.jpg            0.187256   \n",
            "3      7865  frames/953/person_7865.jpg            0.157715   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.621094  0.494873  \n",
            "4              0.620605  0.491455  \n",
            "1              0.596680  0.478027  \n",
            "0              0.583984  0.465332  \n",
            "2              0.573730  0.457764  \n",
            "3              0.583008  0.455566  \n",
            "--------------------------------------------------Frame 954\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 2 backpacks, 17.3ms\n",
            "Speed: 5.2ms preprocess, 17.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/954'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7866  frames/954/person_7866.jpg            0.202393   \n",
            "5      7875  frames/954/person_7875.jpg            0.191528   \n",
            "1      7706  frames/954/person_7706.jpg            0.209717   \n",
            "0      7692  frames/954/person_7692.jpg            0.192993   \n",
            "3      7865  frames/954/person_7865.jpg            0.155884   \n",
            "2      7688  frames/954/person_7688.jpg            0.189697   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.622559  0.496582  \n",
            "5              0.612793  0.486328  \n",
            "1              0.597656  0.481445  \n",
            "0              0.587402  0.468994  \n",
            "3              0.581543  0.453613  \n",
            "2              0.563477  0.451416  \n",
            "--------------------------------------------------Frame 955\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 2 backpacks, 16.0ms\n",
            "Speed: 2.2ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/955'\n",
            "   track_id                  image_path  text_image_cos_sim  \\\n",
            "4      7866  frames/955/person_7866.jpg            0.211182   \n",
            "1      7706  frames/955/person_7706.jpg            0.206787   \n",
            "5      7875  frames/955/person_7875.jpg            0.184082   \n",
            "2      7688  frames/955/person_7688.jpg            0.175781   \n",
            "0      7692  frames/955/person_7692.jpg            0.204956   \n",
            "3      7865  frames/955/person_7865.jpg            0.153442   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.650879  0.519043  \n",
            "1              0.613770  0.491699  \n",
            "5              0.603516  0.477539  \n",
            "2              0.601074  0.473389  \n",
            "0              0.573242  0.462891  \n",
            "3              0.580078  0.452148  \n",
            "Best matching track_id is 7866\n",
            "Best matching image path is frames/955/person_7866.jpg\n",
            "Best matching cosine similarity is 0.51904296875\n",
            "--------------------------------------------------Frame 956\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 2 backpacks, 17.7ms\n",
            "Speed: 5.4ms preprocess, 17.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 957\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 958\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 1 traffic light, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 959\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 4 persons, 1 car, 1 traffic light, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 960\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 28.0ms\n",
            "Speed: 2.1ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 961\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 12.9ms\n",
            "Speed: 3.0ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 962\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 traffic lights, 13.3ms\n",
            "Speed: 1.7ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 963\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 2 traffic lights, 14.1ms\n",
            "Speed: 2.3ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 964\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 12.6ms\n",
            "Speed: 3.4ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 965\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 966\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 967\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 24.6ms\n",
            "Speed: 2.4ms preprocess, 24.6ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 968\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 16.5ms\n",
            "Speed: 2.3ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 969\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 22.9ms\n",
            "Speed: 2.2ms preprocess, 22.9ms inference, 8.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 970\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 traffic lights, 15.4ms\n",
            "Speed: 2.3ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 971\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 972\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 12.6ms\n",
            "Speed: 2.7ms preprocess, 12.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 973\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 974\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 975\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 11.8ms\n",
            "Speed: 2.3ms preprocess, 11.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 976\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 truck, 1 traffic light, 12.2ms\n",
            "Speed: 2.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 977\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 truck, 1 traffic light, 12.1ms\n",
            "Speed: 2.3ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 978\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 truck, 1 traffic light, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 979\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 truck, 1 traffic light, 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 980\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 truck, 1 traffic light, 16.6ms\n",
            "Speed: 2.4ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 981\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 11.7ms\n",
            "Speed: 2.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 982\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 983\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 984\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 985\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 12.1ms\n",
            "Speed: 2.0ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 986\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 12.7ms\n",
            "Speed: 2.1ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 987\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 15.7ms\n",
            "Speed: 2.7ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 988\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 18.8ms\n",
            "Speed: 2.2ms preprocess, 18.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 989\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 traffic lights, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 990\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 traffic lights, 16.3ms\n",
            "Speed: 2.3ms preprocess, 16.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 991\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 12.1ms\n",
            "Speed: 2.1ms preprocess, 12.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 992\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 993\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 14.2ms\n",
            "Speed: 2.1ms preprocess, 14.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 994\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 2 traffic lights, 13.9ms\n",
            "Speed: 2.6ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 995\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 traffic light, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 996\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 13.2ms\n",
            "Speed: 2.3ms preprocess, 13.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 997\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 998\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 14.0ms\n",
            "Speed: 2.5ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 999\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1000\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 traffic light, 25.5ms\n",
            "Speed: 2.3ms preprocess, 25.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1001\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 19.4ms\n",
            "Speed: 2.3ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1002\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 18.1ms\n",
            "Speed: 2.4ms preprocess, 18.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1003\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 17.3ms\n",
            "Speed: 2.1ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1004\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 13.7ms\n",
            "Speed: 3.4ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1005\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 traffic light, 13.5ms\n",
            "Speed: 4.1ms preprocess, 13.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1006\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 traffic light, 19.2ms\n",
            "Speed: 2.1ms preprocess, 19.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1007\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 14.0ms\n",
            "Speed: 2.0ms preprocess, 14.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1008\n",
            "\n",
            "0: 384x640 6 persons, 1 truck, 1 traffic light, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1009\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 1 traffic light, 13.7ms\n",
            "Speed: 2.1ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1010\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 1 traffic light, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1011\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 1 traffic light, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1012\n",
            "\n",
            "0: 384x640 5 persons, 1 traffic light, 12.0ms\n",
            "Speed: 2.4ms preprocess, 12.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1012'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      7940  frames/1012/person_7940.jpg            0.204834   \n",
            "0      7706  frames/1012/person_7706.jpg            0.211670   \n",
            "2      7933  frames/1012/person_7933.jpg            0.175537   \n",
            "3      7949  frames/1012/person_7949.jpg            0.185547   \n",
            "1      7865  frames/1012/person_7865.jpg            0.145142   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.619629  0.495361  \n",
            "0              0.601074  0.484131  \n",
            "2              0.611816  0.480957  \n",
            "3              0.601562  0.476807  \n",
            "1              0.541992  0.422852  \n",
            "--------------------------------------------------Frame 1013\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 traffic light, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1013'"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      7940  frames/1013/person_7940.jpg            0.205566   \n",
            "3      7949  frames/1013/person_7949.jpg            0.202881   \n",
            "0      7706  frames/1013/person_7706.jpg            0.206177   \n",
            "5      7964  frames/1013/person_7964.jpg            0.213257   \n",
            "2      7933  frames/1013/person_7933.jpg            0.186768   \n",
            "6      7965  frames/1013/person_7965.jpg            0.193237   \n",
            "7      7967  frames/1013/person_7967.jpg            0.204956   \n",
            "1      7865  frames/1013/person_7865.jpg            0.163208   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.625977  0.500000  \n",
            "3              0.617188  0.492920  \n",
            "0              0.614258  0.491699  \n",
            "5              0.607422  0.489258  \n",
            "2              0.613770  0.485840  \n",
            "6              0.597656  0.476562  \n",
            "7              0.554688  0.449707  \n",
            "1              0.555664  0.437988  \n",
            "--------------------------------------------------Frame 1014\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 traffic light, 23.1ms\n",
            "Speed: 5.5ms preprocess, 23.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1014'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      7940  frames/1014/person_7940.jpg            0.205322   \n",
            "3      7949  frames/1014/person_7949.jpg            0.200806   \n",
            "0      7706  frames/1014/person_7706.jpg            0.201782   \n",
            "2      7933  frames/1014/person_7933.jpg            0.189575   \n",
            "5      7964  frames/1014/person_7964.jpg            0.202271   \n",
            "6      7965  frames/1014/person_7965.jpg            0.192993   \n",
            "7      7967  frames/1014/person_7967.jpg            0.217163   \n",
            "1      7865  frames/1014/person_7865.jpg            0.164185   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.628906  0.501953  \n",
            "3              0.621582  0.495361  \n",
            "0              0.616699  0.492188  \n",
            "2              0.618164  0.489502  \n",
            "5              0.600098  0.480957  \n",
            "6              0.594727  0.474121  \n",
            "7              0.538574  0.442139  \n",
            "1              0.553223  0.436523  \n",
            "--------------------------------------------------Frame 1015\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 traffic light, 18.5ms\n",
            "Speed: 2.3ms preprocess, 18.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1015'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7949  frames/1015/person_7949.jpg            0.199707   \n",
            "4      7940  frames/1015/person_7940.jpg            0.192139   \n",
            "0      7706  frames/1015/person_7706.jpg            0.212769   \n",
            "5      7965  frames/1015/person_7965.jpg            0.187500   \n",
            "2      7933  frames/1015/person_7933.jpg            0.181152   \n",
            "6      7967  frames/1015/person_7967.jpg            0.213989   \n",
            "7      7754  frames/1015/person_7754.jpg            0.167480   \n",
            "1      7865  frames/1015/person_7865.jpg            0.150391   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.635742  0.504883  \n",
            "4              0.629395  0.498291  \n",
            "0              0.607910  0.489258  \n",
            "5              0.605469  0.479980  \n",
            "2              0.605469  0.478271  \n",
            "6              0.576660  0.467773  \n",
            "7              0.585938  0.460449  \n",
            "1              0.555176  0.433838  \n",
            "--------------------------------------------------Frame 1016\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 traffic light, 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1016'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7949  frames/1016/person_7949.jpg            0.209595   \n",
            "0      7706  frames/1016/person_7706.jpg            0.222168   \n",
            "2      7933  frames/1016/person_7933.jpg            0.191650   \n",
            "4      7940  frames/1016/person_7940.jpg            0.184814   \n",
            "5      7965  frames/1016/person_7965.jpg            0.179199   \n",
            "6      7967  frames/1016/person_7967.jpg            0.209717   \n",
            "7      7945  frames/1016/person_7945.jpg            0.180664   \n",
            "1      7865  frames/1016/person_7865.jpg            0.163208   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.624512  0.500000  \n",
            "0              0.607422  0.491943  \n",
            "2              0.616211  0.488770  \n",
            "4              0.614746  0.485840  \n",
            "5              0.598145  0.472412  \n",
            "6              0.565918  0.459229  \n",
            "7              0.568848  0.452393  \n",
            "1              0.566895  0.445801  \n",
            "--------------------------------------------------Frame 1017\n",
            "\n",
            "0: 384x640 7 persons, 1 traffic light, 21.1ms\n",
            "Speed: 2.4ms preprocess, 21.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1017'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7949  frames/1017/person_7949.jpg            0.194824   \n",
            "0      7706  frames/1017/person_7706.jpg            0.212646   \n",
            "2      7933  frames/1017/person_7933.jpg            0.184814   \n",
            "4      7965  frames/1017/person_7965.jpg            0.193604   \n",
            "5      7967  frames/1017/person_7967.jpg            0.195190   \n",
            "1      7865  frames/1017/person_7865.jpg            0.174683   \n",
            "6      7945  frames/1017/person_7945.jpg            0.172119   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.635254  0.502930  \n",
            "0              0.625488  0.501465  \n",
            "2              0.629395  0.496094  \n",
            "4              0.599609  0.477783  \n",
            "5              0.585449  0.468506  \n",
            "1              0.590332  0.465820  \n",
            "6              0.581055  0.458496  \n",
            "--------------------------------------------------Frame 1018\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 19.0ms\n",
            "Speed: 2.3ms preprocess, 19.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1018'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "8      7975  frames/1018/person_7975.jpg            0.281006   \n",
            "3      7949  frames/1018/person_7949.jpg            0.199951   \n",
            "2      7933  frames/1018/person_7933.jpg            0.196411   \n",
            "0      7706  frames/1018/person_7706.jpg            0.212402   \n",
            "7      7974  frames/1018/person_7974.jpg            0.207520   \n",
            "4      7965  frames/1018/person_7965.jpg            0.192383   \n",
            "1      7865  frames/1018/person_7865.jpg            0.191406   \n",
            "5      7967  frames/1018/person_7967.jpg            0.191650   \n",
            "6      7945  frames/1018/person_7945.jpg            0.166748   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "8              0.761230  0.617188  \n",
            "3              0.632324  0.502441  \n",
            "2              0.624512  0.496094  \n",
            "0              0.616699  0.495361  \n",
            "7              0.596680  0.479980  \n",
            "4              0.599609  0.477295  \n",
            "1              0.599609  0.477051  \n",
            "5              0.569336  0.456055  \n",
            "6              0.576172  0.453369  \n",
            "Best matching track_id is 7975\n",
            "Best matching image path is frames/1018/person_7975.jpg\n",
            "Best matching cosine similarity is 0.6171875\n",
            "--------------------------------------------------Frame 1019\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 7 persons, 14.1ms\n",
            "Speed: 2.2ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1020\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 16.1ms\n",
            "Speed: 2.2ms preprocess, 16.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1021\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 15.3ms\n",
            "Speed: 2.0ms preprocess, 15.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1022\n",
            "\n",
            "0: 384x640 9 persons, 2 traffic lights, 10.6ms\n",
            "Speed: 2.1ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1023\n",
            "\n",
            "0: 384x640 9 persons, 2 traffic lights, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1024\n",
            "\n",
            "0: 384x640 7 persons, 1 traffic light, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1024'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      7933  frames/1024/person_7933.jpg            0.194092   \n",
            "0      7865  frames/1024/person_7865.jpg            0.190552   \n",
            "3      7974  frames/1024/person_7974.jpg            0.170166   \n",
            "6      7963  frames/1024/person_7963.jpg            0.180542   \n",
            "5      7940  frames/1024/person_7940.jpg            0.198608   \n",
            "4      7981  frames/1024/person_7981.jpg            0.188965   \n",
            "2      7967  frames/1024/person_7967.jpg            0.217285   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.624512  0.495605  \n",
            "0              0.614746  0.487549  \n",
            "3              0.619629  0.484863  \n",
            "6              0.611328  0.482178  \n",
            "5              0.597656  0.478027  \n",
            "4              0.594238  0.472656  \n",
            "2              0.572266  0.465820  \n",
            "--------------------------------------------------Frame 1025\n",
            "\n",
            "0: 384x640 8 persons, 1 traffic light, 14.0ms\n",
            "Speed: 2.2ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1025'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7974  frames/1025/person_7974.jpg            0.180420   \n",
            "6      7963  frames/1025/person_7963.jpg            0.179565   \n",
            "7      7986  frames/1025/person_7986.jpg            0.221436   \n",
            "0      7865  frames/1025/person_7865.jpg            0.192139   \n",
            "2      7967  frames/1025/person_7967.jpg            0.200684   \n",
            "1      7933  frames/1025/person_7933.jpg            0.192383   \n",
            "4      7981  frames/1025/person_7981.jpg            0.197510   \n",
            "5      7940  frames/1025/person_7940.jpg            0.185059   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.627441  0.493408  \n",
            "6              0.627930  0.493408  \n",
            "7              0.598633  0.485352  \n",
            "0              0.604980  0.481201  \n",
            "2              0.597656  0.478760  \n",
            "1              0.601074  0.478271  \n",
            "4              0.584961  0.468750  \n",
            "5              0.584473  0.464600  \n",
            "--------------------------------------------------Frame 1026\n",
            "\n",
            "0: 384x640 9 persons, 1 traffic light, 14.8ms\n",
            "Speed: 2.1ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1026'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "7      7988  frames/1026/person_7988.jpg            0.234985   \n",
            "0      7865  frames/1026/person_7865.jpg            0.206299   \n",
            "3      7974  frames/1026/person_7974.jpg            0.186401   \n",
            "6      7986  frames/1026/person_7986.jpg            0.221802   \n",
            "4      7981  frames/1026/person_7981.jpg            0.195923   \n",
            "1      7933  frames/1026/person_7933.jpg            0.182617   \n",
            "2      7967  frames/1026/person_7967.jpg            0.209595   \n",
            "8      7706  frames/1026/person_7706.jpg            0.147461   \n",
            "5      7940  frames/1026/person_7940.jpg            0.174072   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "7              0.634766  0.514648  \n",
            "0              0.618164  0.494629  \n",
            "3              0.616699  0.487549  \n",
            "6              0.597168  0.484375  \n",
            "4              0.592285  0.473389  \n",
            "1              0.592285  0.469238  \n",
            "2              0.577637  0.467285  \n",
            "8              0.595215  0.460938  \n",
            "5              0.577637  0.456543  \n",
            "--------------------------------------------------Frame 1027\n",
            "\n",
            "0: 384x640 8 persons, 1 traffic light, 12.7ms\n",
            "Speed: 3.2ms preprocess, 12.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1027'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7974  frames/1027/person_7974.jpg            0.193359   \n",
            "5      7940  frames/1027/person_7940.jpg            0.200073   \n",
            "0      7865  frames/1027/person_7865.jpg            0.183960   \n",
            "1      7933  frames/1027/person_7933.jpg            0.183105   \n",
            "7      7706  frames/1027/person_7706.jpg            0.179810   \n",
            "6      7986  frames/1027/person_7986.jpg            0.211670   \n",
            "4      7981  frames/1027/person_7981.jpg            0.204102   \n",
            "2      7967  frames/1027/person_7967.jpg            0.217896   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.626953  0.497070  \n",
            "5              0.622070  0.495605  \n",
            "0              0.619629  0.489014  \n",
            "1              0.618164  0.487549  \n",
            "7              0.611816  0.482178  \n",
            "6              0.597656  0.481934  \n",
            "4              0.598145  0.479980  \n",
            "2              0.561523  0.458496  \n",
            "--------------------------------------------------Frame 1028\n",
            "\n",
            "0: 384x640 8 persons, 2 traffic lights, 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1028'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "5      7940  frames/1028/person_7940.jpg            0.198730   \n",
            "0      7865  frames/1028/person_7865.jpg            0.186279   \n",
            "7      7706  frames/1028/person_7706.jpg            0.185425   \n",
            "4      7981  frames/1028/person_7981.jpg            0.198364   \n",
            "1      7933  frames/1028/person_7933.jpg            0.188721   \n",
            "6      7986  frames/1028/person_7986.jpg            0.206543   \n",
            "3      7974  frames/1028/person_7974.jpg            0.179321   \n",
            "2      7967  frames/1028/person_7967.jpg            0.230591   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.619629  0.493408  \n",
            "0              0.616699  0.487549  \n",
            "7              0.616699  0.487305  \n",
            "4              0.602539  0.481445  \n",
            "1              0.605957  0.480713  \n",
            "6              0.590332  0.475342  \n",
            "3              0.597168  0.471680  \n",
            "2              0.567383  0.466309  \n",
            "--------------------------------------------------Frame 1029\n",
            "\n",
            "0: 384x640 5 persons, 1 traffic light, 14.6ms\n",
            "Speed: 2.2ms preprocess, 14.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1029'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      7975  frames/1029/person_7975.jpg            0.216431   \n",
            "0      7933  frames/1029/person_7933.jpg            0.174072   \n",
            "2      7974  frames/1029/person_7974.jpg            0.199707   \n",
            "1      7967  frames/1029/person_7967.jpg            0.192139   \n",
            "3      7981  frames/1029/person_7981.jpg            0.187622   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.616699  0.496582  \n",
            "0              0.628906  0.492432  \n",
            "2              0.618164  0.492432  \n",
            "1              0.574219  0.459473  \n",
            "3              0.568848  0.454590  \n",
            "--------------------------------------------------Frame 1030\n",
            "\n",
            "0: 384x640 6 persons, 1 traffic light, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1030'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      7975  frames/1030/person_7975.jpg            0.215210   \n",
            "0      7933  frames/1030/person_7933.jpg            0.181885   \n",
            "5      7986  frames/1030/person_7986.jpg            0.209106   \n",
            "3      7981  frames/1030/person_7981.jpg            0.187866   \n",
            "1      7967  frames/1030/person_7967.jpg            0.188843   \n",
            "2      7974  frames/1030/person_7974.jpg            0.166382   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.624023  0.501465  \n",
            "0              0.631348  0.496582  \n",
            "5              0.610352  0.489990  \n",
            "3              0.595703  0.473389  \n",
            "1              0.583984  0.465332  \n",
            "2              0.584473  0.458984  \n",
            "--------------------------------------------------Frame 1031\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1031'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      7940  frames/1031/person_7940.jpg            0.215698   \n",
            "1      7986  frames/1031/person_7986.jpg            0.178955   \n",
            "0      7967  frames/1031/person_7967.jpg            0.173950   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.640625  0.513184  \n",
            "1              0.608887  0.479980  \n",
            "0              0.584473  0.461426  \n",
            "--------------------------------------------------Frame 1032\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1032'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "6      7940  frames/1032/person_7940.jpg            0.204834   \n",
            "5      8005  frames/1032/person_8005.jpg            0.201050   \n",
            "1      7986  frames/1032/person_7986.jpg            0.208618   \n",
            "4      8004  frames/1032/person_8004.jpg            0.209595   \n",
            "3      8003  frames/1032/person_8003.jpg            0.219360   \n",
            "2      8002  frames/1032/person_8002.jpg            0.168091   \n",
            "0      7967  frames/1032/person_7967.jpg            0.187012   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "6              0.622559  0.497314  \n",
            "5              0.621582  0.495361  \n",
            "1              0.618164  0.495117  \n",
            "4              0.602051  0.484375  \n",
            "3              0.592773  0.480957  \n",
            "2              0.594727  0.466797  \n",
            "0              0.581055  0.462891  \n",
            "--------------------------------------------------Frame 1033\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1033'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "6      7940  frames/1033/person_7940.jpg            0.222046   \n",
            "5      8005  frames/1033/person_8005.jpg            0.201294   \n",
            "0      7967  frames/1033/person_7967.jpg            0.199097   \n",
            "3      8003  frames/1033/person_8003.jpg            0.220337   \n",
            "1      7986  frames/1033/person_7986.jpg            0.197388   \n",
            "4      8004  frames/1033/person_8004.jpg            0.195923   \n",
            "2      8002  frames/1033/person_8002.jpg            0.168335   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "6              0.618164  0.499268  \n",
            "5              0.620117  0.494385  \n",
            "0              0.598145  0.478516  \n",
            "3              0.588867  0.478271  \n",
            "1              0.596680  0.477051  \n",
            "4              0.597168  0.476807  \n",
            "2              0.591309  0.464355  \n",
            "--------------------------------------------------Frame 1034\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1034'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "5      8005  frames/1034/person_8005.jpg            0.202759   \n",
            "1      7986  frames/1034/person_7986.jpg            0.207275   \n",
            "6      7940  frames/1034/person_7940.jpg            0.213989   \n",
            "0      7967  frames/1034/person_7967.jpg            0.198975   \n",
            "3      8003  frames/1034/person_8003.jpg            0.218384   \n",
            "4      8004  frames/1034/person_8004.jpg            0.192261   \n",
            "2      8002  frames/1034/person_8002.jpg            0.171021   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.614258  0.490723  \n",
            "1              0.602051  0.483643  \n",
            "6              0.597656  0.482666  \n",
            "0              0.596191  0.477051  \n",
            "3              0.586426  0.475830  \n",
            "4              0.590820  0.471191  \n",
            "2              0.595703  0.468262  \n",
            "--------------------------------------------------Frame 1035\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 traffic light, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1035'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "6      7940  frames/1035/person_7940.jpg            0.231201   \n",
            "5      8005  frames/1035/person_8005.jpg            0.198975   \n",
            "1      7986  frames/1035/person_7986.jpg            0.209717   \n",
            "3      8003  frames/1035/person_8003.jpg            0.217529   \n",
            "4      8004  frames/1035/person_8004.jpg            0.194946   \n",
            "0      7967  frames/1035/person_7967.jpg            0.197754   \n",
            "2      8002  frames/1035/person_8002.jpg            0.167603   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "6              0.629395  0.509766  \n",
            "5              0.615723  0.490723  \n",
            "1              0.604492  0.486084  \n",
            "3              0.591309  0.479004  \n",
            "4              0.587891  0.470215  \n",
            "0              0.583496  0.467773  \n",
            "2              0.585938  0.460449  \n",
            "--------------------------------------------------Frame 1036\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1036'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      7986  frames/1036/person_7986.jpg            0.194336   \n",
            "4      7940  frames/1036/person_7940.jpg            0.211792   \n",
            "2      8003  frames/1036/person_8003.jpg            0.226562   \n",
            "3      8005  frames/1036/person_8005.jpg            0.177612   \n",
            "0      7967  frames/1036/person_7967.jpg            0.187378   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.639160  0.505859  \n",
            "4              0.623535  0.500000  \n",
            "2              0.608398  0.493652  \n",
            "3              0.616211  0.484619  \n",
            "0              0.602539  0.478027  \n",
            "--------------------------------------------------Frame 1037\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 motorcycle, 1 traffic light, 14.1ms\n",
            "Speed: 2.2ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1037'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8003  frames/1037/person_8003.jpg            0.229736   \n",
            "4      7940  frames/1037/person_7940.jpg            0.208740   \n",
            "1      7986  frames/1037/person_7986.jpg            0.200562   \n",
            "3      8005  frames/1037/person_8005.jpg            0.188599   \n",
            "0      7967  frames/1037/person_7967.jpg            0.191772   \n",
            "5      8006  frames/1037/person_8006.jpg            0.124756   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.612305  0.497559  \n",
            "4              0.619629  0.496582  \n",
            "1              0.621582  0.495117  \n",
            "3              0.614746  0.487061  \n",
            "0              0.583496  0.466064  \n",
            "5              0.566406  0.433838  \n",
            "--------------------------------------------------Frame 1038\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 motorcycle, 1 traffic light, 12.8ms\n",
            "Speed: 7.2ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1038'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      7940  frames/1038/person_7940.jpg            0.222046   \n",
            "1      7986  frames/1038/person_7986.jpg            0.204712   \n",
            "2      8003  frames/1038/person_8003.jpg            0.236816   \n",
            "3      8005  frames/1038/person_8005.jpg            0.186890   \n",
            "6      8012  frames/1038/person_8012.jpg            0.181152   \n",
            "0      7967  frames/1038/person_7967.jpg            0.197144   \n",
            "5      8006  frames/1038/person_8006.jpg            0.124573   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.640625  0.515137  \n",
            "1              0.627441  0.500488  \n",
            "2              0.613281  0.500000  \n",
            "3              0.619141  0.489502  \n",
            "6              0.599609  0.474121  \n",
            "0              0.583496  0.467529  \n",
            "5              0.564941  0.432861  \n",
            "--------------------------------------------------Frame 1039\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 traffic light, 14.9ms\n",
            "Speed: 2.1ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1039'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7940  frames/1039/person_7940.jpg            0.245728   \n",
            "1      7986  frames/1039/person_7986.jpg            0.212891   \n",
            "2      8003  frames/1039/person_8003.jpg            0.233276   \n",
            "0      7967  frames/1039/person_7967.jpg            0.190552   \n",
            "5      8008  frames/1039/person_8008.jpg            0.179932   \n",
            "6      8012  frames/1039/person_8012.jpg            0.173706   \n",
            "4      8006  frames/1039/person_8006.jpg            0.135498   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.646973  0.526367  \n",
            "1              0.622559  0.499512  \n",
            "2              0.609863  0.497070  \n",
            "0              0.582520  0.464844  \n",
            "5              0.581543  0.460938  \n",
            "6              0.571289  0.452148  \n",
            "4              0.553711  0.428223  \n",
            "--------------------------------------------------Frame 1040\n",
            "\n",
            "0: 384x640 9 persons, 2 cars, 1 traffic light, 15.7ms\n",
            "Speed: 2.5ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1040'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      7940  frames/1040/person_7940.jpg            0.259033   \n",
            "1      7986  frames/1040/person_7986.jpg            0.195679   \n",
            "2      8003  frames/1040/person_8003.jpg            0.233032   \n",
            "5      8008  frames/1040/person_8008.jpg            0.169556   \n",
            "0      7967  frames/1040/person_7967.jpg            0.201416   \n",
            "6      8012  frames/1040/person_8012.jpg            0.177856   \n",
            "7      8015  frames/1040/person_8015.jpg            0.165405   \n",
            "8      8016  frames/1040/person_8016.jpg            0.139893   \n",
            "4      8006  frames/1040/person_8006.jpg            0.133789   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.665527  0.543457  \n",
            "1              0.623047  0.494629  \n",
            "2              0.602051  0.491211  \n",
            "5              0.580566  0.457275  \n",
            "0              0.566406  0.457031  \n",
            "6              0.576660  0.457031  \n",
            "7              0.572754  0.450439  \n",
            "8              0.570312  0.441162  \n",
            "4              0.558105  0.430664  \n",
            "Best matching track_id is 7940\n",
            "Best matching image path is frames/1040/person_7940.jpg\n",
            "Best matching cosine similarity is 0.54345703125\n",
            "--------------------------------------------------Frame 1041\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 traffic light, 13.0ms\n",
            "Speed: 2.6ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1042\n",
            "\n",
            "0: 384x640 6 persons, 4 cars, 1 motorcycle, 1 traffic light, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1043\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 11.5ms\n",
            "Speed: 2.1ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1043'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8003  frames/1043/person_8003.jpg            0.204956   \n",
            "0      7967  frames/1043/person_7967.jpg            0.176636   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.635742  0.506348  \n",
            "0              0.576660  0.456543  \n",
            "--------------------------------------------------Frame 1044\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1044'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8003  frames/1044/person_8003.jpg            0.227783   \n",
            "2      8027  frames/1044/person_8027.jpg            0.226318   \n",
            "0      7967  frames/1044/person_7967.jpg            0.182495   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.625488  0.505859  \n",
            "2              0.610352  0.495117  \n",
            "0              0.584961  0.464111  \n",
            "--------------------------------------------------Frame 1045\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 16.3ms\n",
            "Speed: 2.5ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1045'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8027  frames/1045/person_8027.jpg            0.223633   \n",
            "1      8003  frames/1045/person_8003.jpg            0.200806   \n",
            "0      7967  frames/1045/person_7967.jpg            0.176880   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.612793  0.496094  \n",
            "1              0.616699  0.491943  \n",
            "0              0.556641  0.442627  \n",
            "--------------------------------------------------Frame 1046\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1046'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8027  frames/1046/person_8027.jpg            0.216431   \n",
            "1      8003  frames/1046/person_8003.jpg            0.207642   \n",
            "0      7967  frames/1046/person_7967.jpg            0.191895   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.617676  0.497314  \n",
            "1              0.618164  0.494873  \n",
            "0              0.571289  0.457520  \n",
            "--------------------------------------------------Frame 1047\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 12.6ms\n",
            "Speed: 5.8ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1047'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8027  frames/1047/person_8027.jpg            0.224243   \n",
            "3      8031  frames/1047/person_8031.jpg            0.233765   \n",
            "1      8003  frames/1047/person_8003.jpg            0.206665   \n",
            "0      7967  frames/1047/person_7967.jpg            0.192993   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.614746  0.497559  \n",
            "3              0.608887  0.496338  \n",
            "1              0.611816  0.490234  \n",
            "0              0.568359  0.455811  \n",
            "--------------------------------------------------Frame 1048\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1048'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8003  frames/1048/person_8003.jpg            0.202026   \n",
            "1      8027  frames/1048/person_8027.jpg            0.209961   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.622559  0.496338  \n",
            "1              0.598145  0.481689  \n",
            "--------------------------------------------------Frame 1049\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1049'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "5      8035  frames/1049/person_8035.jpg            0.224243   \n",
            "3      8033  frames/1049/person_8033.jpg            0.238647   \n",
            "0      8003  frames/1049/person_8003.jpg            0.207031   \n",
            "4      8034  frames/1049/person_8034.jpg            0.172363   \n",
            "2      8032  frames/1049/person_8032.jpg            0.191406   \n",
            "1      8027  frames/1049/person_8027.jpg            0.210693   \n",
            "6      8036  frames/1049/person_8036.jpg            0.185669   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.687500  0.548340  \n",
            "3              0.620117  0.505859  \n",
            "0              0.616699  0.493652  \n",
            "4              0.618652  0.484863  \n",
            "2              0.610352  0.484619  \n",
            "1              0.601562  0.484375  \n",
            "6              0.571777  0.455811  \n",
            "Best matching track_id is 8035\n",
            "Best matching image path is frames/1049/person_8035.jpg\n",
            "Best matching cosine similarity is 0.54833984375\n",
            "--------------------------------------------------Frame 1050\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 15.1ms\n",
            "Speed: 2.5ms preprocess, 15.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1051\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1051'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8003  frames/1051/person_8003.jpg            0.196167   \n",
            "1      8032  frames/1051/person_8032.jpg            0.172363   \n",
            "2      8004  frames/1051/person_8004.jpg            0.205078   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.614746  0.489258  \n",
            "1              0.624512  0.489014  \n",
            "2              0.604492  0.484619  \n",
            "--------------------------------------------------Frame 1052\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 1 car, 15.6ms\n",
            "Speed: 2.2ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1052'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8003  frames/1052/person_8003.jpg            0.207642   \n",
            "1      8032  frames/1052/person_8032.jpg            0.173828   \n",
            "2      8004  frames/1052/person_8004.jpg            0.213379   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.626953  0.501465  \n",
            "1              0.604492  0.475342  \n",
            "2              0.587402  0.475098  \n",
            "--------------------------------------------------Frame 1053\n",
            "\n",
            "0: 384x640 2 persons, 11.4ms\n",
            "Speed: 2.2ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1053'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      7933  frames/1053/person_7933.jpg            0.238403   \n",
            "0      8003  frames/1053/person_8003.jpg            0.194458   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.691406  0.555664  \n",
            "0              0.606445  0.482910  \n",
            "Best matching track_id is 7933\n",
            "Best matching image path is frames/1053/person_7933.jpg\n",
            "Best matching cosine similarity is 0.5556640625\n",
            "--------------------------------------------------Frame 1054\n",
            "\n",
            "0: 384x640 4 persons, 11.3ms\n",
            "Speed: 2.2ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1055\n",
            "\n",
            "0: 384x640 1 person, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 1056\n",
            "\n",
            "0: 384x640 3 persons, 12.6ms\n",
            "Speed: 2.0ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1057\n",
            "\n",
            "0: 384x640 3 persons, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1058\n",
            "\n",
            "0: 384x640 3 persons, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1059\n",
            "\n",
            "0: 384x640 3 persons, 13.9ms\n",
            "Speed: 2.3ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1060\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.4ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1061\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1062\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1063\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1064\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 backpack, 15.8ms\n",
            "Speed: 2.2ms preprocess, 15.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1065\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 backpack, 12.4ms\n",
            "Speed: 2.3ms preprocess, 12.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1066\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 motorcycle, 1 traffic light, 1 backpack, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1067\n",
            "\n",
            "0: 384x640 2 persons, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1067'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8060  frames/1067/person_8060.jpg            0.258057   \n",
            "1      8021  frames/1067/person_8021.jpg            0.180176   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.706543  0.572266  \n",
            "1              0.637695  0.500488  \n",
            "Best matching track_id is 8060\n",
            "Best matching image path is frames/1067/person_8060.jpg\n",
            "Best matching cosine similarity is 0.572265625\n",
            "--------------------------------------------------Frame 1068\n",
            "\n",
            "0: 384x640 5 persons, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1069\n",
            "\n",
            "0: 384x640 5 persons, 10.8ms\n",
            "Speed: 2.2ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1070\n",
            "\n",
            "0: 384x640 6 persons, 13.5ms\n",
            "Speed: 2.1ms preprocess, 13.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1071\n",
            "\n",
            "0: 384x640 6 persons, 15.5ms\n",
            "Speed: 2.3ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1072\n",
            "\n",
            "0: 384x640 5 persons, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1072'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      8032  frames/1072/person_8032.jpg            0.265625   \n",
            "1      8021  frames/1072/person_8021.jpg            0.203125   \n",
            "2      8073  frames/1072/person_8073.jpg            0.184570   \n",
            "3      7967  frames/1072/person_7967.jpg            0.168213   \n",
            "0      8065  frames/1072/person_8065.jpg            0.185791   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.772461  0.620117  \n",
            "1              0.624512  0.498291  \n",
            "2              0.604980  0.479004  \n",
            "3              0.592773  0.465576  \n",
            "0              0.581055  0.462402  \n",
            "Best matching track_id is 8032\n",
            "Best matching image path is frames/1072/person_8032.jpg\n",
            "Best matching cosine similarity is 0.6201171875\n",
            "--------------------------------------------------Frame 1073\n",
            "\n",
            "0: 384x640 6 persons, 12.8ms\n",
            "Speed: 4.4ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1074\n",
            "\n",
            "0: 384x640 8 persons, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1075\n",
            "\n",
            "0: 384x640 5 persons, 12.9ms\n",
            "Speed: 2.0ms preprocess, 12.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1075'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "4      8061  frames/1075/person_8061.jpg            0.232422   \n",
            "0      8021  frames/1075/person_8021.jpg            0.216064   \n",
            "2      8034  frames/1075/person_8034.jpg            0.186157   \n",
            "3      8046  frames/1075/person_8046.jpg            0.189331   \n",
            "1      8015  frames/1075/person_8015.jpg            0.171143   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "4              0.732910  0.583008  \n",
            "0              0.617676  0.497070  \n",
            "2              0.606445  0.480469  \n",
            "3              0.589844  0.469727  \n",
            "1              0.572266  0.451904  \n",
            "Best matching track_id is 8061\n",
            "Best matching image path is frames/1075/person_8061.jpg\n",
            "Best matching cosine similarity is 0.5830078125\n",
            "--------------------------------------------------Frame 1076\n",
            "\n",
            "0: 384x640 6 persons, 16.6ms\n",
            "Speed: 2.3ms preprocess, 16.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1077\n",
            "\n",
            "0: 384x640 2 persons, 10.8ms\n",
            "Speed: 4.4ms preprocess, 10.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1078\n",
            "\n",
            "0: 384x640 7 persons, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1079\n",
            "\n",
            "0: 384x640 5 persons, 1 truck, 1 tv, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1080\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 2 persons, 1 truck, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1080'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8113  frames/1080/person_8113.jpg            0.210327   \n",
            "0      8111  frames/1080/person_8111.jpg            0.202637   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.608887  0.489258  \n",
            "0              0.611816  0.489014  \n",
            "--------------------------------------------------Frame 1081\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1081'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8111  frames/1081/person_8111.jpg            0.204224   \n",
            "1      8113  frames/1081/person_8113.jpg            0.212769   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.616211  0.492676  \n",
            "1              0.611328  0.491699  \n",
            "--------------------------------------------------Frame 1082\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 15.3ms\n",
            "Speed: 2.5ms preprocess, 15.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1082'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8113  frames/1082/person_8113.jpg            0.212769   \n",
            "0      8111  frames/1082/person_8111.jpg            0.204834   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.611328  0.491699  \n",
            "0              0.613770  0.491211  \n",
            "--------------------------------------------------Frame 1083\n",
            "\n",
            "0: 384x640 2 persons, 1 truck, 9.1ms\n",
            "Speed: 2.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1083'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8111  frames/1083/person_8111.jpg            0.206177   \n",
            "1      8113  frames/1083/person_8113.jpg            0.211914   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.615234  0.492432  \n",
            "1              0.610840  0.491211  \n",
            "--------------------------------------------------Frame 1084\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 tv, 12.6ms\n",
            "Speed: 2.6ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1085\n",
            "\n",
            "0: 384x640 1 car, 15.3ms\n",
            "Speed: 2.1ms preprocess, 15.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1086\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 1 car, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1087\n",
            "\n",
            "0: 384x640 7 persons, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1088\n",
            "\n",
            "0: 384x640 1 person, 12.2ms\n",
            "Speed: 2.4ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1088'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8119  frames/1088/person_8119.jpg            0.157471   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.576172  tensor(0.4507, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 1089\n",
            "\n",
            "0: 384x640 4 persons, 1 motorcycle, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1090\n",
            "\n",
            "0: 384x640 2 persons, 1 motorcycle, 15.0ms\n",
            "Speed: 2.1ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1090'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8123  frames/1090/person_8123.jpg            0.180908   \n",
            "0      8122  frames/1090/person_8122.jpg            0.184082   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.619141  0.487549  \n",
            "0              0.595703  0.472168  \n",
            "--------------------------------------------------Frame 1091\n",
            "\n",
            "0: 384x640 1 person, 1 car, 1 cat, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1091'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8046  frames/1091/person_8046.jpg            0.192993   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.640625  tensor(0.5063, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 1092\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 cat, 13.2ms\n",
            "Speed: 2.0ms preprocess, 13.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1092'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8046  frames/1092/person_8046.jpg            0.195190   \n",
            "0      8125  frames/1092/person_8125.jpg            0.179443   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.634277  0.502441  \n",
            "0              0.612793  0.482910  \n",
            "--------------------------------------------------Frame 1093\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 cat, 12.2ms\n",
            "Speed: 2.0ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1093'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8046  frames/1093/person_8046.jpg            0.187622   \n",
            "0      8125  frames/1093/person_8125.jpg            0.178711   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.638672  0.503418  \n",
            "0              0.611816  0.481934  \n",
            "--------------------------------------------------Frame 1094\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 cat, 11.1ms\n",
            "Speed: 2.6ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1094'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8046  frames/1094/person_8046.jpg            0.192871   \n",
            "0      8125  frames/1094/person_8125.jpg            0.179077   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.632812  0.500977  \n",
            "0              0.611328  0.481689  \n",
            "--------------------------------------------------Frame 1095\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 motorcycle, 1 cat, 14.3ms\n",
            "Speed: 2.2ms preprocess, 14.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1095'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8046  frames/1095/person_8046.jpg            0.195801   \n",
            "0      8125  frames/1095/person_8125.jpg            0.181030   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.633789  0.502441  \n",
            "0              0.612305  0.482910  \n",
            "--------------------------------------------------Frame 1096\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 12.5ms\n",
            "Speed: 2.6ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1096'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8046  frames/1096/person_8046.jpg            0.203369   \n",
            "0      8125  frames/1096/person_8125.jpg            0.166382   \n",
            "3      8061  frames/1096/person_8061.jpg            0.183960   \n",
            "2      8119  frames/1096/person_8119.jpg            0.165649   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610840  0.488525  \n",
            "0              0.603516  0.472168  \n",
            "3              0.566406  0.451660  \n",
            "2              0.559082  0.440918  \n",
            "--------------------------------------------------Frame 1097\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 11.3ms\n",
            "Speed: 2.6ms preprocess, 11.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1097'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8125  frames/1097/person_8125.jpg            0.173462   \n",
            "1      8046  frames/1097/person_8046.jpg            0.201294   \n",
            "3      8061  frames/1097/person_8061.jpg            0.194580   \n",
            "2      8119  frames/1097/person_8119.jpg            0.163330   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.604492  0.475098  \n",
            "1              0.582031  0.467773  \n",
            "3              0.569336  0.456787  \n",
            "2              0.546387  0.431641  \n",
            "--------------------------------------------------Frame 1098\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 16.0ms\n",
            "Speed: 2.2ms preprocess, 16.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1098'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8125  frames/1098/person_8125.jpg            0.184448   \n",
            "1      8046  frames/1098/person_8046.jpg            0.200928   \n",
            "3      8061  frames/1098/person_8061.jpg            0.199585   \n",
            "2      8119  frames/1098/person_8119.jpg            0.168091   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.611816  0.483643  \n",
            "1              0.590820  0.473877  \n",
            "3              0.582031  0.467285  \n",
            "2              0.534668  0.424805  \n",
            "--------------------------------------------------Frame 1099\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1099'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8061  frames/1099/person_8061.jpg            0.218506   \n",
            "0      8119  frames/1099/person_8119.jpg            0.163818   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.613281  0.494629  \n",
            "0              0.522949  0.415039  \n",
            "--------------------------------------------------Frame 1100\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 15.1ms\n",
            "Speed: 2.2ms preprocess, 15.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1100'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8137  frames/1100/person_8137.jpg            0.218140   \n",
            "1      8061  frames/1100/person_8061.jpg            0.220215   \n",
            "0      8119  frames/1100/person_8119.jpg            0.151367   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.631836  0.507812  \n",
            "1              0.611328  0.494141  \n",
            "0              0.490723  0.388916  \n",
            "--------------------------------------------------Frame 1101\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 12.6ms\n",
            "Speed: 2.2ms preprocess, 12.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1101'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8137  frames/1101/person_8137.jpg            0.225952   \n",
            "1      8061  frames/1101/person_8061.jpg            0.217285   \n",
            "0      8119  frames/1101/person_8119.jpg            0.155762   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.628906  0.507812  \n",
            "1              0.608398  0.490967  \n",
            "0              0.522949  0.412598  \n",
            "--------------------------------------------------Frame 1102\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 19.9ms\n",
            "Speed: 2.4ms preprocess, 19.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1102'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8137  frames/1102/person_8137.jpg            0.220093   \n",
            "1      8061  frames/1102/person_8061.jpg            0.213135   \n",
            "0      8119  frames/1102/person_8119.jpg            0.151001   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.633301  0.509277  \n",
            "1              0.598633  0.482910  \n",
            "0              0.514160  0.405273  \n",
            "--------------------------------------------------Frame 1103\n",
            "\n",
            "0: 384x640 2 persons, 10.6ms\n",
            "Speed: 2.2ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1103'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8104  frames/1103/person_8104.jpg            0.207642   \n",
            "0      8061  frames/1103/person_8061.jpg            0.222168   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.626465  0.500977  \n",
            "0              0.590332  0.479980  \n",
            "--------------------------------------------------Frame 1104\n",
            "\n",
            "0: 384x640 5 persons, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1104'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1104/person_8061.jpg            0.218628   \n",
            "3      8140  frames/1104/person_8140.jpg            0.208740   \n",
            "4      8104  frames/1104/person_8104.jpg            0.199219   \n",
            "1      8138  frames/1104/person_8138.jpg            0.188843   \n",
            "2      8139  frames/1104/person_8139.jpg            0.177979   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.613281  0.494873  \n",
            "3              0.615234  0.493164  \n",
            "4              0.613281  0.489014  \n",
            "1              0.599121  0.476074  \n",
            "2              0.600586  0.473877  \n",
            "--------------------------------------------------Frame 1105\n",
            "\n",
            "0: 384x640 6 persons, 11.9ms\n",
            "Speed: 2.1ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1105'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "5      8142  frames/1105/person_8142.jpg            0.241821   \n",
            "4      8104  frames/1105/person_8104.jpg            0.201172   \n",
            "3      8140  frames/1105/person_8140.jpg            0.208862   \n",
            "0      8061  frames/1105/person_8061.jpg            0.207397   \n",
            "1      8138  frames/1105/person_8138.jpg            0.189331   \n",
            "2      8139  frames/1105/person_8139.jpg            0.178833   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.624512  0.509766  \n",
            "4              0.623047  0.496338  \n",
            "3              0.618652  0.495850  \n",
            "0              0.607422  0.487549  \n",
            "1              0.597656  0.475342  \n",
            "2              0.601074  0.474365  \n",
            "--------------------------------------------------Frame 1106\n",
            "\n",
            "0: 384x640 6 persons, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1106'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "5      8142  frames/1106/person_8142.jpg            0.241577   \n",
            "4      8104  frames/1106/person_8104.jpg            0.214600   \n",
            "0      8061  frames/1106/person_8061.jpg            0.216553   \n",
            "3      8140  frames/1106/person_8140.jpg            0.201294   \n",
            "1      8138  frames/1106/person_8138.jpg            0.188599   \n",
            "2      8139  frames/1106/person_8139.jpg            0.182129   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.625000  0.509766  \n",
            "4              0.629883  0.505371  \n",
            "0              0.611816  0.493164  \n",
            "3              0.616699  0.491943  \n",
            "1              0.598633  0.475586  \n",
            "2              0.597168  0.472656  \n",
            "--------------------------------------------------Frame 1107\n",
            "\n",
            "0: 384x640 6 persons, 10.9ms\n",
            "Speed: 6.0ms preprocess, 10.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1107'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "5      8142  frames/1107/person_8142.jpg            0.242554   \n",
            "0      8061  frames/1107/person_8061.jpg            0.219482   \n",
            "3      8140  frames/1107/person_8140.jpg            0.202881   \n",
            "4      8104  frames/1107/person_8104.jpg            0.203857   \n",
            "2      8139  frames/1107/person_8139.jpg            0.180908   \n",
            "1      8138  frames/1107/person_8138.jpg            0.188232   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "5              0.625977  0.510742  \n",
            "0              0.617676  0.498291  \n",
            "3              0.617188  0.492920  \n",
            "4              0.614258  0.491211  \n",
            "2              0.606934  0.479004  \n",
            "1              0.599121  0.475830  \n",
            "--------------------------------------------------Frame 1108\n",
            "\n",
            "0: 384x640 3 persons, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1108'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8104  frames/1108/person_8104.jpg            0.217041   \n",
            "0      8061  frames/1108/person_8061.jpg            0.214844   \n",
            "1      8139  frames/1108/person_8139.jpg            0.167236   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.622070  0.500488  \n",
            "0              0.598145  0.483154  \n",
            "1              0.608398  0.476074  \n",
            "--------------------------------------------------Frame 1109\n",
            "\n",
            "0: 384x640 4 persons, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1109'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8104  frames/1109/person_8104.jpg            0.195312   \n",
            "0      8061  frames/1109/person_8061.jpg            0.212036   \n",
            "1      8139  frames/1109/person_8139.jpg            0.175781   \n",
            "3      8146  frames/1109/person_8146.jpg            0.196899   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.609375  0.485107  \n",
            "0              0.589844  0.476562  \n",
            "1              0.604980  0.476318  \n",
            "3              0.581055  0.465820  \n",
            "--------------------------------------------------Frame 1110\n",
            "\n",
            "0: 384x640 4 persons, 14.3ms\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1110'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8104  frames/1110/person_8104.jpg            0.205322   \n",
            "0      8061  frames/1110/person_8061.jpg            0.219116   \n",
            "3      8146  frames/1110/person_8146.jpg            0.204834   \n",
            "1      8139  frames/1110/person_8139.jpg            0.181641   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.609375  0.488037  \n",
            "0              0.600098  0.485840  \n",
            "3              0.595703  0.478516  \n",
            "1              0.604980  0.478027  \n",
            "--------------------------------------------------Frame 1111\n",
            "\n",
            "0: 384x640 2 persons, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1111'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1111/person_8061.jpg            0.229370   \n",
            "1      8139  frames/1111/person_8139.jpg            0.172974   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.626465  0.507324  \n",
            "1              0.608887  0.478027  \n",
            "--------------------------------------------------Frame 1112\n",
            "\n",
            "0: 384x640 4 persons, 12.9ms\n",
            "Speed: 2.2ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1112'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1112/person_8061.jpg            0.225952   \n",
            "2      8147  frames/1112/person_8147.jpg            0.206177   \n",
            "3      8148  frames/1112/person_8148.jpg            0.202637   \n",
            "1      8139  frames/1112/person_8139.jpg            0.183838   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.613770  0.497559  \n",
            "2              0.611328  0.489746  \n",
            "3              0.605957  0.484863  \n",
            "1              0.607910  0.480713  \n",
            "--------------------------------------------------Frame 1113\n",
            "\n",
            "0: 384x640 3 persons, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1113'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1113/person_8061.jpg            0.257324   \n",
            "1      8139  frames/1113/person_8139.jpg            0.186279   \n",
            "2      8147  frames/1113/person_8147.jpg            0.187012   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.618164  0.509766  \n",
            "1              0.615234  0.486572  \n",
            "2              0.583984  0.464844  \n",
            "--------------------------------------------------Frame 1114\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 10.2ms\n",
            "Speed: 2.2ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1114'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1114/person_8061.jpg            0.242920   \n",
            "3      8149  frames/1114/person_8149.jpg            0.200684   \n",
            "1      8139  frames/1114/person_8139.jpg            0.189819   \n",
            "2      8147  frames/1114/person_8147.jpg            0.185547   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.609863  0.500000  \n",
            "3              0.616211  0.491699  \n",
            "1              0.605957  0.480957  \n",
            "2              0.600586  0.476074  \n",
            "--------------------------------------------------Frame 1115\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 11.2ms\n",
            "Speed: 2.6ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1115'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1115/person_8061.jpg            0.207886   \n",
            "1      8137  frames/1115/person_8137.jpg            0.210815   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.615234  0.493164  \n",
            "1              0.610352  0.490479  \n",
            "--------------------------------------------------Frame 1116\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1116'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1116/person_8061.jpg            0.208862   \n",
            "3      8137  frames/1116/person_8137.jpg            0.211304   \n",
            "1      8156  frames/1116/person_8156.jpg            0.195801   \n",
            "2      8157  frames/1116/person_8157.jpg            0.178345   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.627930  0.501953  \n",
            "3              0.606445  0.488037  \n",
            "1              0.608887  0.485107  \n",
            "2              0.610352  0.480713  \n",
            "--------------------------------------------------Frame 1117\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1117'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8137  frames/1117/person_8137.jpg            0.221558   \n",
            "0      8061  frames/1117/person_8061.jpg            0.201782   \n",
            "2      8157  frames/1117/person_8157.jpg            0.179321   \n",
            "1      8156  frames/1117/person_8156.jpg            0.192749   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.603027  0.488525  \n",
            "0              0.608887  0.486816  \n",
            "2              0.612305  0.482422  \n",
            "1              0.599609  0.477539  \n",
            "--------------------------------------------------Frame 1118\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 17.9ms\n",
            "Speed: 2.1ms preprocess, 17.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1118'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1118/person_8061.jpg            0.214111   \n",
            "3      8137  frames/1118/person_8137.jpg            0.220459   \n",
            "2      8157  frames/1118/person_8157.jpg            0.177734   \n",
            "1      8156  frames/1118/person_8156.jpg            0.200562   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.629395  0.504883  \n",
            "3              0.600098  0.486328  \n",
            "2              0.609863  0.480225  \n",
            "1              0.599609  0.479980  \n",
            "--------------------------------------------------Frame 1119\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 18.8ms\n",
            "Speed: 2.1ms preprocess, 18.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1119'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1119/person_8061.jpg            0.218750   \n",
            "3      8137  frames/1119/person_8137.jpg            0.221313   \n",
            "2      8157  frames/1119/person_8157.jpg            0.179688   \n",
            "1      8156  frames/1119/person_8156.jpg            0.197754   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.629883  0.506348  \n",
            "3              0.607910  0.491943  \n",
            "2              0.609375  0.480469  \n",
            "1              0.601074  0.479980  \n",
            "--------------------------------------------------Frame 1120\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 motorcycle, 16.3ms\n",
            "Speed: 6.6ms preprocess, 16.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1120'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8157  frames/1120/person_8157.jpg            0.184448   \n",
            "0      8061  frames/1120/person_8061.jpg            0.210205   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.606445  0.479980  \n",
            "0              0.583496  0.471436  \n",
            "--------------------------------------------------Frame 1121\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 motorcycle, 16.2ms\n",
            "Speed: 2.1ms preprocess, 16.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1121'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8166  frames/1121/person_8166.jpg            0.188599   \n",
            "1      8157  frames/1121/person_8157.jpg            0.189941   \n",
            "0      8061  frames/1121/person_8061.jpg            0.204224   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.622070  0.492188  \n",
            "1              0.598145  0.475586  \n",
            "0              0.574219  0.463135  \n",
            "--------------------------------------------------Frame 1122\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 motorcycle, 13.3ms\n",
            "Speed: 2.4ms preprocess, 13.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1122'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8166  frames/1122/person_8166.jpg            0.189575   \n",
            "1      8157  frames/1122/person_8157.jpg            0.191650   \n",
            "0      8061  frames/1122/person_8061.jpg            0.195923   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.622070  0.492432  \n",
            "1              0.611328  0.485352  \n",
            "0              0.574707  0.461182  \n",
            "--------------------------------------------------Frame 1123\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 motorcycle, 16.6ms\n",
            "Speed: 5.2ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1123'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8166  frames/1123/person_8166.jpg            0.194214   \n",
            "0      8061  frames/1123/person_8061.jpg            0.222046   \n",
            "1      8157  frames/1123/person_8157.jpg            0.189941   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.622559  0.494141  \n",
            "0              0.593750  0.482178  \n",
            "1              0.580566  0.463379  \n",
            "--------------------------------------------------Frame 1124\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 6 persons, 2 cars, 1 motorcycle, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1124'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8166  frames/1124/person_8166.jpg            0.195801   \n",
            "5      8169  frames/1124/person_8169.jpg            0.199951   \n",
            "0      8061  frames/1124/person_8061.jpg            0.220825   \n",
            "4      8168  frames/1124/person_8168.jpg            0.195679   \n",
            "1      8157  frames/1124/person_8157.jpg            0.180786   \n",
            "3      8167  frames/1124/person_8167.jpg            0.160156   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.616699  0.490479  \n",
            "5              0.607422  0.485352  \n",
            "0              0.590332  0.479492  \n",
            "4              0.600098  0.479004  \n",
            "1              0.580078  0.460205  \n",
            "3              0.548828  0.432373  \n",
            "--------------------------------------------------Frame 1125\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 15.8ms\n",
            "Speed: 2.5ms preprocess, 15.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1125'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1125/person_8061.jpg            0.195312   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.629883  tensor(0.4995, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 1126\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 4 persons, 2 cars, 17.6ms\n",
            "Speed: 3.5ms preprocess, 17.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1126'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8061  frames/1126/person_8061.jpg            0.197510   \n",
            "3      8172  frames/1126/person_8172.jpg            0.199341   \n",
            "2      8171  frames/1126/person_8171.jpg            0.186646   \n",
            "1      8170  frames/1126/person_8170.jpg            0.166626   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.620605  0.493652  \n",
            "3              0.619629  0.493652  \n",
            "2              0.613281  0.485107  \n",
            "1              0.610840  0.477539  \n",
            "--------------------------------------------------Frame 1127\n",
            "\n",
            "0: 384x640 3 cars, 12.5ms\n",
            "Speed: 2.0ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1128\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 parking meter, 17.0ms\n",
            "Speed: 2.2ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1128'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8176  frames/1128/person_8176.jpg            0.192261   \n",
            "0      8175  frames/1128/person_8175.jpg            0.188232   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.617676  0.489990  \n",
            "0              0.602051  0.477783  \n",
            "--------------------------------------------------Frame 1129\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 parking meter, 17.1ms\n",
            "Speed: 2.2ms preprocess, 17.1ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1129'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8176  frames/1129/person_8176.jpg            0.193848   \n",
            "0      8175  frames/1129/person_8175.jpg            0.179810   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.620117  0.492188  \n",
            "0              0.606445  0.478516  \n",
            "--------------------------------------------------Frame 1130\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 2 persons, 3 cars, 1 parking meter, 15.5ms\n",
            "Speed: 3.3ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1130'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8176  frames/1130/person_8176.jpg            0.194336   \n",
            "0      8175  frames/1130/person_8175.jpg            0.177246   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.620605  0.492676  \n",
            "0              0.600586  0.473633  \n",
            "--------------------------------------------------Frame 1131\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 parking meter, 23.8ms\n",
            "Speed: 2.4ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1131'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8176  frames/1131/person_8176.jpg            0.192505   \n",
            "0      8175  frames/1131/person_8175.jpg            0.175049   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.617676  0.490234  \n",
            "0              0.600098  0.472656  \n",
            "--------------------------------------------------Frame 1132\n",
            "\n",
            "0: 384x640 2 persons, 3 cars, 1 parking meter, 12.0ms\n",
            "Speed: 3.0ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1132'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8176  frames/1132/person_8176.jpg            0.192383   \n",
            "0      8175  frames/1132/person_8175.jpg            0.156128   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.590820  0.471191  \n",
            "0              0.577637  0.451172  \n",
            "--------------------------------------------------Frame 1133\n",
            "\n",
            "0: 384x640 3 persons, 3 cars, 1 parking meter, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1133'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8183  frames/1133/person_8183.jpg            0.195312   \n",
            "1      8176  frames/1133/person_8176.jpg            0.193237   \n",
            "0      8175  frames/1133/person_8175.jpg            0.159424   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.614258  0.488525  \n",
            "1              0.602539  0.479980  \n",
            "0              0.593750  0.463379  \n",
            "--------------------------------------------------Frame 1134\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 3 cars, 1 parking meter, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1134'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8183  frames/1134/person_8183.jpg            0.194946   \n",
            "1      8176  frames/1134/person_8176.jpg            0.193481   \n",
            "0      8175  frames/1134/person_8175.jpg            0.156982   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.614746  0.488770  \n",
            "1              0.599609  0.477783  \n",
            "0              0.602539  0.468994  \n",
            "--------------------------------------------------Frame 1135\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 14.2ms\n",
            "Speed: 2.3ms preprocess, 14.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1135'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8183  frames/1135/person_8183.jpg            0.197266   \n",
            "0      8175  frames/1135/person_8175.jpg            0.173218   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.614746  0.489502  \n",
            "0              0.578613  0.457031  \n",
            "--------------------------------------------------Frame 1136\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 2 cars, 1 parking meter, 17.0ms\n",
            "Speed: 2.3ms preprocess, 17.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1136'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8183  frames/1136/person_8183.jpg            0.195312   \n",
            "2      8184  frames/1136/person_8184.jpg            0.194336   \n",
            "0      8175  frames/1136/person_8175.jpg            0.154907   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.627930  0.498047  \n",
            "2              0.606934  0.483154  \n",
            "0              0.569824  0.445312  \n",
            "--------------------------------------------------Frame 1137\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 parking meter, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1137'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8175  frames/1137/person_8175.jpg            0.173462   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.577148  tensor(0.4561, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 1138\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 3 persons, 2 cars, 1 parking meter, 20.2ms\n",
            "Speed: 2.1ms preprocess, 20.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1138'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8187  frames/1138/person_8187.jpg            0.199707   \n",
            "0      8175  frames/1138/person_8175.jpg            0.185181   \n",
            "2      8188  frames/1138/person_8188.jpg            0.201660   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.618164  0.492432  \n",
            "0              0.605469  0.479492  \n",
            "2              0.573730  0.462158  \n",
            "--------------------------------------------------Frame 1139\n",
            "\n",
            "0: 384x640 1 car, 40.3ms\n",
            "Speed: 2.6ms preprocess, 40.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1140\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1140'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8190  frames/1140/person_8190.jpg            0.208862   \n",
            "0      8189  frames/1140/person_8189.jpg            0.161011   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.612793  0.491699  \n",
            "0              0.572754  0.449219  \n",
            "--------------------------------------------------Frame 1141\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1141'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8190  frames/1141/person_8190.jpg            0.208984   \n",
            "0      8189  frames/1141/person_8189.jpg            0.156250   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.612793  0.491699  \n",
            "0              0.567871  0.444336  \n",
            "--------------------------------------------------Frame 1142\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 14.1ms\n",
            "Speed: 2.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1142'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8190  frames/1142/person_8190.jpg            0.207764   \n",
            "0      8189  frames/1142/person_8189.jpg            0.156250   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1               0.61084  0.489746  \n",
            "0               0.57373  0.448486  \n",
            "--------------------------------------------------Frame 1143\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1143'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8190  frames/1143/person_8190.jpg            0.207764   \n",
            "0      8189  frames/1143/person_8189.jpg            0.156738   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.610840  0.489746  \n",
            "0              0.574219  0.448975  \n",
            "--------------------------------------------------Frame 1144\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1144'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8190  frames/1144/person_8190.jpg            0.201904   \n",
            "0      8189  frames/1144/person_8189.jpg            0.187988   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.603516  0.482910  \n",
            "0              0.585938  0.466553  \n",
            "--------------------------------------------------Frame 1145\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 parking meter, 16.4ms\n",
            "Speed: 2.3ms preprocess, 16.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1145'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8199  frames/1145/person_8199.jpg            0.211548   \n",
            "1      8190  frames/1145/person_8190.jpg            0.192261   \n",
            "2      8198  frames/1145/person_8198.jpg            0.210449   \n",
            "0      8189  frames/1145/person_8189.jpg            0.160645   \n",
            "4      8200  frames/1145/person_8200.jpg            0.161377   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.605469  0.487305  \n",
            "1              0.612793  0.486572  \n",
            "2              0.597168  0.480957  \n",
            "0              0.574219  0.449951  \n",
            "4              0.504395  0.401367  \n",
            "--------------------------------------------------Frame 1146\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 parking meter, 13.4ms\n",
            "Speed: 2.3ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1146'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8199  frames/1146/person_8199.jpg            0.212769   \n",
            "1      8190  frames/1146/person_8190.jpg            0.199097   \n",
            "2      8198  frames/1146/person_8198.jpg            0.210938   \n",
            "0      8189  frames/1146/person_8189.jpg            0.179565   \n",
            "4      8200  frames/1146/person_8200.jpg            0.161377   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.606934  0.488770  \n",
            "1              0.608887  0.486084  \n",
            "2              0.598633  0.482178  \n",
            "0              0.597656  0.472412  \n",
            "4              0.503906  0.401123  \n",
            "--------------------------------------------------Frame 1147\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 parking meter, 14.4ms\n",
            "Speed: 3.7ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1147'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8198  frames/1147/person_8198.jpg            0.205933   \n",
            "0      8189  frames/1147/person_8189.jpg            0.173096   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.607422  0.487061  \n",
            "0              0.576172  0.455322  \n",
            "--------------------------------------------------Frame 1148\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 1 truck, 1 parking meter, 14.2ms\n",
            "Speed: 2.4ms preprocess, 14.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1148'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8198  frames/1148/person_8198.jpg            0.202637   \n",
            "0      8189  frames/1148/person_8189.jpg            0.154053   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.607422  0.486084  \n",
            "0              0.561035  0.438965  \n",
            "--------------------------------------------------Frame 1149\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 truck, 1 parking meter, 14.4ms\n",
            "Speed: 2.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1149'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8198  frames/1149/person_8198.jpg            0.209839   \n",
            "0      8189  frames/1149/person_8189.jpg            0.147461   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.627441  0.501953  \n",
            "0              0.544922  0.425537  \n",
            "--------------------------------------------------Frame 1150\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 truck, 1 parking meter, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1150'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8198  frames/1150/person_8198.jpg            0.199097   \n",
            "0      8189  frames/1150/person_8189.jpg            0.148193   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.625977  0.498047  \n",
            "0              0.568848  0.442627  \n",
            "--------------------------------------------------Frame 1151\n",
            "\n",
            "0: 384x640 3 cars, 15.0ms\n",
            "Speed: 2.7ms preprocess, 15.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1152\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1152'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8198  frames/1152/person_8198.jpg            0.195312   \n",
            "2      8205  frames/1152/person_8205.jpg            0.177246   \n",
            "0      8203  frames/1152/person_8203.jpg            0.200195   \n",
            "1      8204  frames/1152/person_8204.jpg            0.172974   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.639160  0.505859  \n",
            "2              0.625000  0.490723  \n",
            "0              0.608887  0.486328  \n",
            "1              0.594238  0.467773  \n",
            "--------------------------------------------------Frame 1153\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 4 persons, 3 cars, 15.3ms\n",
            "Speed: 2.8ms preprocess, 15.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1153'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8198  frames/1153/person_8198.jpg            0.211182   \n",
            "2      8205  frames/1153/person_8205.jpg            0.176514   \n",
            "0      8203  frames/1153/person_8203.jpg            0.198242   \n",
            "1      8204  frames/1153/person_8204.jpg            0.169189   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.641602  0.512695  \n",
            "2              0.625000  0.490479  \n",
            "0              0.607422  0.484863  \n",
            "1              0.592773  0.465820  \n",
            "--------------------------------------------------Frame 1154\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1154'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8198  frames/1154/person_8198.jpg            0.205566   \n",
            "0      8203  frames/1154/person_8203.jpg            0.207275   \n",
            "2      8205  frames/1154/person_8205.jpg            0.178345   \n",
            "1      8204  frames/1154/person_8204.jpg            0.180908   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.647461  0.514648  \n",
            "0              0.609375  0.488770  \n",
            "2              0.621582  0.488525  \n",
            "1              0.607422  0.479492  \n",
            "--------------------------------------------------Frame 1155\n",
            "\n",
            "0: 384x640 4 persons, 3 cars, 14.1ms\n",
            "Speed: 2.4ms preprocess, 14.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1155'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8198  frames/1155/person_8198.jpg            0.208008   \n",
            "0      8203  frames/1155/person_8203.jpg            0.204224   \n",
            "2      8205  frames/1155/person_8205.jpg            0.174683   \n",
            "1      8204  frames/1155/person_8204.jpg            0.179810   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.639648  0.510254  \n",
            "0              0.607910  0.486816  \n",
            "2              0.613770  0.482178  \n",
            "1              0.607910  0.479492  \n",
            "--------------------------------------------------Frame 1156\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 14.9ms\n",
            "Speed: 2.3ms preprocess, 14.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1156'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8198  frames/1156/person_8198.jpg            0.215820   \n",
            "1      8205  frames/1156/person_8205.jpg            0.200195   \n",
            "0      8203  frames/1156/person_8203.jpg            0.175903   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.618164  0.497314  \n",
            "1              0.613770  0.489746  \n",
            "0              0.600586  0.473145  \n",
            "--------------------------------------------------Frame 1157\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 parking meter, 14.0ms\n",
            "Speed: 2.1ms preprocess, 14.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1157'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8205  frames/1157/person_8205.jpg            0.203613   \n",
            "2      8198  frames/1157/person_8198.jpg            0.190186   \n",
            "0      8203  frames/1157/person_8203.jpg            0.173340   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.625977  0.499268  \n",
            "2              0.622070  0.492676  \n",
            "0              0.592773  0.467041  \n",
            "--------------------------------------------------Frame 1158\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 parking meter, 19.7ms\n",
            "Speed: 2.3ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1158'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8208  frames/1158/person_8208.jpg            0.188477   \n",
            "2      8198  frames/1158/person_8198.jpg            0.203369   \n",
            "1      8205  frames/1158/person_8205.jpg            0.194458   \n",
            "0      8203  frames/1158/person_8203.jpg            0.175659   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.625488  0.494385  \n",
            "2              0.613770  0.490723  \n",
            "1              0.606445  0.482910  \n",
            "0              0.603027  0.474854  \n",
            "--------------------------------------------------Frame 1159\n",
            "\n",
            "0: 384x640 1 person, 2 cars, 1 parking meter, 13.2ms\n",
            "Speed: 2.5ms preprocess, 13.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1159'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8198  frames/1159/person_8198.jpg            0.208496   \n",
            "\n",
            "   target_image_cos_sim                              cos_sim  \n",
            "0              0.624023  tensor(0.4993, dtype=torch.float16)  \n",
            "--------------------------------------------------Frame 1160\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 12.2ms\n",
            "Speed: 2.5ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1160'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8198  frames/1160/person_8198.jpg            0.202393   \n",
            "1      8211  frames/1160/person_8211.jpg            0.192505   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.622070  0.496338  \n",
            "1              0.619141  0.491211  \n",
            "--------------------------------------------------Frame 1161\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 1 parking meter, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1161'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8198  frames/1161/person_8198.jpg            0.189209   \n",
            "1      8211  frames/1161/person_8211.jpg            0.191040   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.610840  0.484375  \n",
            "1              0.597656  0.475830  \n",
            "--------------------------------------------------Frame 1162\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 parking meter, 21.2ms\n",
            "Speed: 2.2ms preprocess, 21.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1162'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8215  frames/1162/person_8215.jpg            0.279541   \n",
            "1      8211  frames/1162/person_8211.jpg            0.190796   \n",
            "0      8198  frames/1162/person_8198.jpg            0.185913   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.732910  0.597168  \n",
            "1              0.610352  0.484375  \n",
            "0              0.594727  0.472168  \n",
            "Best matching track_id is 8215\n",
            "Best matching image path is frames/1162/person_8215.jpg\n",
            "Best matching cosine similarity is 0.59716796875\n",
            "--------------------------------------------------Frame 1163\n",
            "\n",
            "0: 384x640 2 persons, 2 cars, 13.4ms\n",
            "Speed: 2.6ms preprocess, 13.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1164\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 14.8ms\n",
            "Speed: 2.3ms preprocess, 14.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1165\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 13.0ms\n",
            "Speed: 1.9ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1166\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1167\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: 384x640 5 persons, 2 cars, 12.8ms\n",
            "Speed: 2.3ms preprocess, 12.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1168\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1169\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 17.6ms\n",
            "Speed: 2.2ms preprocess, 17.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1170\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.3ms\n",
            "Speed: 2.3ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1171\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 14.0ms\n",
            "Speed: 2.4ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1172\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 3 trucks, 20.8ms\n",
            "Speed: 2.3ms preprocess, 20.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1173\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 3 trucks, 13.2ms\n",
            "Speed: 2.7ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1174\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 4 trucks, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1175\n",
            "\n",
            "0: 384x640 1 person, 1 car, 2 trucks, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1176\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 4 trucks, 13.5ms\n",
            "Speed: 2.3ms preprocess, 13.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1177\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 5 trucks, 14.1ms\n",
            "Speed: 2.5ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1178\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 5 trucks, 14.6ms\n",
            "Speed: 2.3ms preprocess, 14.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1179\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 5 trucks, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1180\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 4 trucks, 11.7ms\n",
            "Speed: 2.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1181\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 4 trucks, 13.7ms\n",
            "Speed: 2.3ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1182\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 4 trucks, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1183\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 2 trucks, 12.4ms\n",
            "Speed: 2.2ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1184\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 5 trucks, 16.3ms\n",
            "Speed: 2.4ms preprocess, 16.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1185\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 4 trucks, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1186\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 4 trucks, 12.5ms\n",
            "Speed: 2.4ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1187\n",
            "\n",
            "0: 384x640 1 person, 1 car, 3 trucks, 12.5ms\n",
            "Speed: 2.9ms preprocess, 12.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1188\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 3 trucks, 12.5ms\n",
            "Speed: 2.2ms preprocess, 12.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1189\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 3 trucks, 13.0ms\n",
            "Speed: 3.2ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1190\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 3 trucks, 14.1ms\n",
            "Speed: 3.0ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1191\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 3 trucks, 13.8ms\n",
            "Speed: 2.3ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1192\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 3 trucks, 13.2ms\n",
            "Speed: 2.4ms preprocess, 13.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1193\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 3 trucks, 12.1ms\n",
            "Speed: 2.4ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1194\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 3 trucks, 15.4ms\n",
            "Speed: 2.6ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1195\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1196\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 2 trucks, 16.8ms\n",
            "Speed: 2.3ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1197\n",
            "\n",
            "0: 384x640 2 persons, 3 trucks, 14.9ms\n",
            "Speed: 2.2ms preprocess, 14.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1197'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8261  frames/1197/person_8261.jpg            0.196533   \n",
            "0      8254  frames/1197/person_8254.jpg            0.186279   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.621094  0.493652  \n",
            "0              0.577148  0.459961  \n",
            "--------------------------------------------------Frame 1198\n",
            "\n",
            "0: 384x640 3 persons, 3 trucks, 16.4ms\n",
            "Speed: 2.8ms preprocess, 16.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1198'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8261  frames/1198/person_8261.jpg            0.191772   \n",
            "2      8266  frames/1198/person_8266.jpg            0.196777   \n",
            "0      8254  frames/1198/person_8254.jpg            0.184204   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.620605  0.491943  \n",
            "2              0.613770  0.488770  \n",
            "0              0.590332  0.468506  \n",
            "--------------------------------------------------Frame 1199\n",
            "\n",
            "0: 384x640 2 persons, 3 trucks, 21.6ms\n",
            "Speed: 3.2ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1199'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8261  frames/1199/person_8261.jpg            0.187988   \n",
            "1      8266  frames/1199/person_8266.jpg            0.171021   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.624512  0.493652  \n",
            "1              0.611816  0.479492  \n",
            "--------------------------------------------------Frame 1200\n",
            "\n",
            "0: 384x640 4 persons, 3 trucks, 14.4ms\n",
            "Speed: 2.3ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1200'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8267  frames/1200/person_8267.jpg            0.191528   \n",
            "3      8268  frames/1200/person_8268.jpg            0.179077   \n",
            "1      8266  frames/1200/person_8266.jpg            0.187012   \n",
            "0      8261  frames/1200/person_8261.jpg            0.170532   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.630371  0.498535  \n",
            "3              0.625977  0.491943  \n",
            "1              0.618164  0.488770  \n",
            "0              0.609863  0.478027  \n",
            "--------------------------------------------------Frame 1201\n",
            "\n",
            "0: 384x640 3 persons, 3 trucks, 16.8ms\n",
            "Speed: 2.7ms preprocess, 16.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1201'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8267  frames/1201/person_8267.jpg            0.187134   \n",
            "2      8268  frames/1201/person_8268.jpg            0.177979   \n",
            "0      8261  frames/1201/person_8261.jpg            0.171509   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.637695  0.502441  \n",
            "2              0.628906  0.493652  \n",
            "0              0.603516  0.473877  \n",
            "--------------------------------------------------Frame 1202\n",
            "\n",
            "0: 384x640 4 persons, 3 trucks, 12.2ms\n",
            "Speed: 2.1ms preprocess, 12.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1202'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8270  frames/1202/person_8270.jpg            0.186157   \n",
            "1      8267  frames/1202/person_8267.jpg            0.179077   \n",
            "2      8268  frames/1202/person_8268.jpg            0.175537   \n",
            "0      8261  frames/1202/person_8261.jpg            0.173584   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.633789  0.499512  \n",
            "1              0.629883  0.494629  \n",
            "2              0.627930  0.492188  \n",
            "0              0.607910  0.477539  \n",
            "--------------------------------------------------Frame 1203\n",
            "\n",
            "0: 384x640 4 persons, 3 trucks, 15.7ms\n",
            "Speed: 3.4ms preprocess, 15.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1203'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8270  frames/1203/person_8270.jpg            0.186157   \n",
            "1      8267  frames/1203/person_8267.jpg            0.181519   \n",
            "2      8268  frames/1203/person_8268.jpg            0.176147   \n",
            "0      8261  frames/1203/person_8261.jpg            0.175537   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.633789  0.499512  \n",
            "1              0.630859  0.496094  \n",
            "2              0.625488  0.490723  \n",
            "0              0.603516  0.475098  \n",
            "--------------------------------------------------Frame 1204\n",
            "\n",
            "0: 384x640 3 persons, 2 trucks, 13.4ms\n",
            "Speed: 2.7ms preprocess, 13.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1204'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1204/person_8267.jpg            0.197998   \n",
            "2      8270  frames/1204/person_8270.jpg            0.195557   \n",
            "1      8268  frames/1204/person_8268.jpg            0.179565   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.627441  0.498535  \n",
            "2              0.625977  0.496826  \n",
            "1              0.613770  0.483643  \n",
            "--------------------------------------------------Frame 1205\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 2 trucks, 13.8ms\n",
            "Speed: 2.7ms preprocess, 13.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1205'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1205/person_8267.jpg            0.197266   \n",
            "2      8270  frames/1205/person_8270.jpg            0.190796   \n",
            "1      8268  frames/1205/person_8268.jpg            0.162476   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.631348  0.500977  \n",
            "2              0.618652  0.490234  \n",
            "1              0.612793  0.477783  \n",
            "--------------------------------------------------Frame 1206\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 2 trucks, 16.1ms\n",
            "Speed: 2.6ms preprocess, 16.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1206'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1206/person_8267.jpg            0.199463   \n",
            "2      8270  frames/1206/person_8270.jpg            0.191162   \n",
            "1      8268  frames/1206/person_8268.jpg            0.174561   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.625000  0.497314  \n",
            "2              0.626465  0.495850  \n",
            "1              0.628418  0.492188  \n",
            "--------------------------------------------------Frame 1207\n",
            "\n",
            "0: 384x640 2 persons, 1 car, 2 trucks, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1207'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1207/person_8267.jpg            0.207397   \n",
            "1      8270  frames/1207/person_8270.jpg            0.166138   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.625977  0.500488  \n",
            "1              0.609375  0.476318  \n",
            "--------------------------------------------------Frame 1208\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 2 trucks, 10.9ms\n",
            "Speed: 8.5ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1208'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1208/person_8267.jpg            0.201782   \n",
            "1      8270  frames/1208/person_8270.jpg            0.188110   \n",
            "2      8276  frames/1208/person_8276.jpg            0.142944   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.627441  0.499756  \n",
            "1              0.625000  0.493896  \n",
            "2              0.581055  0.449707  \n",
            "--------------------------------------------------Frame 1209\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 12.5ms\n",
            "Speed: 2.7ms preprocess, 12.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1209'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1209/person_8267.jpg            0.201538   \n",
            "1      8270  frames/1209/person_8270.jpg            0.162476   \n",
            "2      8276  frames/1209/person_8276.jpg            0.142456   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.628906  0.500488  \n",
            "1              0.596191  0.466064  \n",
            "2              0.575684  0.445801  \n",
            "--------------------------------------------------Frame 1210\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 1 truck, 16.6ms\n",
            "Speed: 2.5ms preprocess, 16.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1210'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1210/person_8267.jpg            0.192749   \n",
            "2      8276  frames/1210/person_8276.jpg            0.169189   \n",
            "1      8270  frames/1210/person_8270.jpg            0.180908   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.629395  0.498535  \n",
            "2              0.625488  0.488525  \n",
            "1              0.600586  0.474609  \n",
            "--------------------------------------------------Frame 1211\n",
            "\n",
            "0: 384x640 3 persons, 1 car, 1 truck, 14.5ms\n",
            "Speed: 2.6ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1211'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "2      8276  frames/1211/person_8276.jpg            0.168945   \n",
            "1      8270  frames/1211/person_8270.jpg            0.174927   \n",
            "0      8267  frames/1211/person_8267.jpg            0.180908   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "2              0.616211  0.482178  \n",
            "1              0.602539  0.474365  \n",
            "0              0.596680  0.471924  \n",
            "--------------------------------------------------Frame 1212\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 trucks, 13.0ms\n",
            "Speed: 2.2ms preprocess, 13.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1212'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1212/person_8267.jpg            0.180664   \n",
            "3      8280  frames/1212/person_8280.jpg            0.211060   \n",
            "2      8276  frames/1212/person_8276.jpg            0.166260   \n",
            "1      8270  frames/1212/person_8270.jpg            0.168457   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.616699  0.485840  \n",
            "3              0.603516  0.485596  \n",
            "2              0.613770  0.479492  \n",
            "1              0.605957  0.474609  \n",
            "--------------------------------------------------Frame 1213\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 trucks, 12.7ms\n",
            "Speed: 2.5ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1213'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "1      8270  frames/1213/person_8270.jpg            0.163452   \n",
            "3      8280  frames/1213/person_8280.jpg            0.216187   \n",
            "0      8267  frames/1213/person_8267.jpg            0.180786   \n",
            "2      8276  frames/1213/person_8276.jpg            0.166260   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "1              0.619629  0.482910  \n",
            "3              0.595703  0.481934  \n",
            "0              0.607422  0.479492  \n",
            "2              0.607910  0.475342  \n",
            "--------------------------------------------------Frame 1214\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 trucks, 12.4ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1214'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1214/person_8267.jpg            0.193237   \n",
            "3      8280  frames/1214/person_8280.jpg            0.225708   \n",
            "2      8276  frames/1214/person_8276.jpg            0.182617   \n",
            "1      8270  frames/1214/person_8270.jpg            0.167603   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.625000  0.495605  \n",
            "3              0.607910  0.493164  \n",
            "2              0.619629  0.488525  \n",
            "1              0.606445  0.474854  \n",
            "--------------------------------------------------Frame 1215\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 2 trucks, 15.5ms\n",
            "Speed: 5.6ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created new directory: 'frames/1215'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "0      8267  frames/1215/person_8267.jpg            0.196899   \n",
            "1      8270  frames/1215/person_8270.jpg            0.178223   \n",
            "3      8280  frames/1215/person_8280.jpg            0.213501   \n",
            "2      8276  frames/1215/person_8276.jpg            0.175171   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "0              0.622070  0.494629  \n",
            "1              0.621582  0.488525  \n",
            "3              0.599121  0.483398  \n",
            "2              0.614258  0.482422  \n",
            "--------------------------------------------------Frame 1216\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 11.7ms\n",
            "Speed: 2.7ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Created new directory: 'frames/1216'\n",
            "   track_id                   image_path  text_image_cos_sim  \\\n",
            "3      8280  frames/1216/person_8280.jpg            0.300293   \n",
            "0      8267  frames/1216/person_8267.jpg            0.185181   \n",
            "2      8276  frames/1216/person_8276.jpg            0.174683   \n",
            "1      8270  frames/1216/person_8270.jpg            0.155396   \n",
            "\n",
            "   target_image_cos_sim   cos_sim  \n",
            "3              0.661133  0.552734  \n",
            "0              0.625488  0.493164  \n",
            "2              0.621094  0.487305  \n",
            "1              0.591797  0.460938  \n",
            "Best matching track_id is 8280\n",
            "Best matching image path is frames/1216/person_8280.jpg\n",
            "Best matching cosine similarity is 0.552734375\n",
            "--------------------------------------------------Frame 1217\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: overflow encountered in cast\n",
            "  has_large_values = (abs_vals > 1e6).any()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------Frame 1218\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 12.9ms\n",
            "Speed: 2.3ms preprocess, 12.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1219\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 12.6ms\n",
            "Speed: 2.3ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1220\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 19.2ms\n",
            "Speed: 2.3ms preprocess, 19.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1221\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 11.9ms\n",
            "Speed: 2.2ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1222\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 17.3ms\n",
            "Speed: 2.5ms preprocess, 17.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1223\n",
            "\n",
            "0: 384x640 3 persons, 2 cars, 17.9ms\n",
            "Speed: 3.0ms preprocess, 17.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1224\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 14.5ms\n",
            "Speed: 2.4ms preprocess, 14.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1225\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 12.0ms\n",
            "Speed: 2.3ms preprocess, 12.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1226\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 1 truck, 13.3ms\n",
            "Speed: 2.3ms preprocess, 13.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1227\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 2 trucks, 13.7ms\n",
            "Speed: 2.4ms preprocess, 13.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1228\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 2 trucks, 14.5ms\n",
            "Speed: 2.2ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1229\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 20.8ms\n",
            "Speed: 2.3ms preprocess, 20.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1230\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1231\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 12.4ms\n",
            "Speed: 2.1ms preprocess, 12.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1232\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 13.4ms\n",
            "Speed: 2.2ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1233\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 15.7ms\n",
            "Speed: 2.2ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1234\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 10.6ms\n",
            "Speed: 2.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1235\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 2 trucks, 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1236\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1237\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 3 trucks, 13.0ms\n",
            "Speed: 2.3ms preprocess, 13.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1238\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 3 trucks, 13.6ms\n",
            "Speed: 2.4ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1239\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 3 trucks, 14.8ms\n",
            "Speed: 2.4ms preprocess, 14.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1240\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 2 trucks, 15.3ms\n",
            "Speed: 2.6ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1241\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 2 trucks, 20.0ms\n",
            "Speed: 2.4ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1242\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 2 trucks, 22.4ms\n",
            "Speed: 2.3ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1243\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 2 trucks, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1244\n",
            "\n",
            "0: 384x640 8 persons, 2 cars, 2 trucks, 11.7ms\n",
            "Speed: 2.8ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1245\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 motorcycle, 2 trucks, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1246\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 motorcycle, 2 trucks, 13.8ms\n",
            "Speed: 2.2ms preprocess, 13.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1247\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 1 truck, 11.6ms\n",
            "Speed: 2.2ms preprocess, 11.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1248\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 truck, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1249\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 truck, 12.0ms\n",
            "Speed: 2.5ms preprocess, 12.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1250\n",
            "\n",
            "0: 384x640 7 persons, 1 car, 1 truck, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1251\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 14.7ms\n",
            "Speed: 2.4ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1252\n",
            "\n",
            "0: 384x640 7 persons, 1 truck, 13.3ms\n",
            "Speed: 2.2ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1253\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 1 bench, 13.6ms\n",
            "Speed: 2.1ms preprocess, 13.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1254\n",
            "\n",
            "0: 384x640 8 persons, 1 car, 1 truck, 1 bench, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1255\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 bench, 14.0ms\n",
            "Speed: 2.3ms preprocess, 14.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1256\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 1 bench, 15.4ms\n",
            "Speed: 2.2ms preprocess, 15.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1257\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 13.1ms\n",
            "Speed: 2.1ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1258\n",
            "\n",
            "0: 384x640 7 persons, 4 cars, 1 truck, 1 handbag, 14.7ms\n",
            "Speed: 2.2ms preprocess, 14.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1259\n",
            "\n",
            "0: 384x640 4 persons, 1 car, 1 truck, 18.2ms\n",
            "Speed: 2.7ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1260\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 1 truck, 12.6ms\n",
            "Speed: 2.5ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1261\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1262\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1263\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 16.9ms\n",
            "Speed: 2.3ms preprocess, 16.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1264\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 13.3ms\n",
            "Speed: 2.1ms preprocess, 13.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1265\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1266\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 20.6ms\n",
            "Speed: 2.3ms preprocess, 20.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1267\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 13.1ms\n",
            "Speed: 2.3ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1268\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 1 truck, 13.7ms\n",
            "Speed: 2.2ms preprocess, 13.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1269\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 truck, 15.8ms\n",
            "Speed: 2.9ms preprocess, 15.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1270\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 truck, 20.4ms\n",
            "Speed: 2.3ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1271\n",
            "\n",
            "0: 384x640 6 persons, 3 cars, 1 truck, 13.0ms\n",
            "Speed: 2.1ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1272\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 1 truck, 12.8ms\n",
            "Speed: 2.2ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1273\n",
            "\n",
            "0: 384x640 7 persons, 3 cars, 1 truck, 14.3ms\n",
            "Speed: 2.1ms preprocess, 14.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1274\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1275\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 15.6ms\n",
            "Speed: 2.1ms preprocess, 15.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1276\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 13.0ms\n",
            "Speed: 2.9ms preprocess, 13.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1277\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1278\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 14.2ms\n",
            "Speed: 2.2ms preprocess, 14.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1279\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1280\n",
            "\n",
            "0: 384x640 7 persons, 2 cars, 1 truck, 14.6ms\n",
            "Speed: 2.4ms preprocess, 14.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1281\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1282\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 13.0ms\n",
            "Speed: 2.4ms preprocess, 13.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1283\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 19.6ms\n",
            "Speed: 2.1ms preprocess, 19.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1284\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 2 trucks, 15.8ms\n",
            "Speed: 2.3ms preprocess, 15.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1285\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 1 truck, 33.9ms\n",
            "Speed: 2.3ms preprocess, 33.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1286\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 26.1ms\n",
            "Speed: 3.7ms preprocess, 26.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1287\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 1 handbag, 17.8ms\n",
            "Speed: 2.3ms preprocess, 17.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1288\n",
            "\n",
            "0: 384x640 5 persons, 2 cars, 18.6ms\n",
            "Speed: 2.2ms preprocess, 18.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1289\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 16.2ms\n",
            "Speed: 2.2ms preprocess, 16.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1290\n",
            "\n",
            "0: 384x640 6 persons, 2 cars, 15.3ms\n",
            "Speed: 2.2ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1291\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.2ms\n",
            "Speed: 2.3ms preprocess, 12.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1292\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 14.4ms\n",
            "Speed: 2.4ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1293\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 11.9ms\n",
            "Speed: 2.4ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1294\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.7ms\n",
            "Speed: 2.3ms preprocess, 12.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1295\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 20.9ms\n",
            "Speed: 2.4ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1296\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 14.5ms\n",
            "Speed: 2.3ms preprocess, 14.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1297\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.3ms\n",
            "Speed: 2.2ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1298\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 12.5ms\n",
            "Speed: 2.1ms preprocess, 12.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1299\n",
            "\n",
            "0: 384x640 4 persons, 2 cars, 16.6ms\n",
            "Speed: 2.2ms preprocess, 16.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1300\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 13.0ms\n",
            "Speed: 2.0ms preprocess, 13.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1301\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 17.0ms\n",
            "Speed: 2.1ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1302\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 13.6ms\n",
            "Speed: 2.2ms preprocess, 13.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1303\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 16.1ms\n",
            "Speed: 2.1ms preprocess, 16.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1304\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 12.9ms\n",
            "Speed: 2.1ms preprocess, 12.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1305\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 13.1ms\n",
            "Speed: 2.2ms preprocess, 13.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1306\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 17.9ms\n",
            "Speed: 3.2ms preprocess, 17.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1307\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 18.4ms\n",
            "Speed: 3.9ms preprocess, 18.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1308\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 17.5ms\n",
            "Speed: 2.2ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1309\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 11.9ms\n",
            "Speed: 3.7ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1310\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 11.8ms\n",
            "Speed: 2.0ms preprocess, 11.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1311\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 20.5ms\n",
            "Speed: 2.2ms preprocess, 20.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1312\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 13.9ms\n",
            "Speed: 2.2ms preprocess, 13.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1313\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 13.2ms\n",
            "Speed: 2.1ms preprocess, 13.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1314\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 12.3ms\n",
            "Speed: 5.2ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1315\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 12.7ms\n",
            "Speed: 2.9ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1316\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 14.8ms\n",
            "Speed: 3.9ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1317\n",
            "\n",
            "0: 384x640 5 persons, 1 car, 15.9ms\n",
            "Speed: 2.2ms preprocess, 15.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1318\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 12.1ms\n",
            "Speed: 2.9ms preprocess, 12.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1319\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 12.6ms\n",
            "Speed: 2.1ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1320\n",
            "\n",
            "0: 384x640 6 persons, 1 car, 24.5ms\n",
            "Speed: 7.0ms preprocess, 24.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "--------------------------------------------------Frame 1321\n",
            "Target Tracking completed. Processed video has been saved!\n"
          ]
        }
      ]
    }
  ]
}